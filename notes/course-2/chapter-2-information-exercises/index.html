<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chapter 2 - Information Exercises | Kenneth Zhang </title> <meta name="author" content="Kenneth Zhang"> <meta name="description" content="Exercises for Chapter 2 - Information and Conditioning."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kennethzhangml.github.io/notes/course-2/chapter-2-information-exercises/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kenneth</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Chapter 2 - Information Exercises</h1> <p class="post-description">Exercises for Chapter 2 - Information and Conditioning.</p> </header> <article> <p><strong>Exercise 2.1</strong> We want to show that if $X$ is measurable with respect to the trivial $\sigma$-algebra $\mathcal{F}_0 = {\emptyset, \Omega}$, then $X$ is constant.</p> <p>Since $X$ is measurable with respect to $\mathcal{F}_0$, this means that for any Borel set $B \subseteq \mathbb{R}$, the preimage $X^{-1}(B) \in \mathcal{F}_0$. This implies that the only possible measurable sets are $\emptyset$ and $\Omega$.</p> <p>Since $X^{-1}(B)$ must be either $\emptyset$ or $\Omega$, there exists a single real number $c$ such that:</p> \[X(\omega) = c, \quad \forall \omega \in \Omega.\] <p>Thus, $X$ is constant and not random, meaning it is <strong>degenerate</strong>.</p> <p><strong>Exercise 2.2</strong> (i) The random variable $X$ is defined by:</p> \[X = \begin{cases} 1, &amp; \text{if } S_2 = 4, \\ 0, &amp; \text{if } S_2 \neq 4. \end{cases}\] <p>From the problem statement, $S_2(HH) = 16$, $S_2(HT) = S_2(TH) = 4$, and $S_2(TT) = 1$. This means that $X=1$ for ${HT, TH}$ and $X=0$ for ${HH, TT}$. The $\sigma$-algebra generated by $X$ is:</p> \[\sigma(X) = \{\emptyset, \{HT, TH\}, \{HH, TT\}, \Omega\}.\] <p>(ii) The stock price $S_1$ takes values $S_1(HH) = 8$, $S_1(HT) = 8$, $S_1(TH) = 2$, $S_1(TT) = 2$. So the level sets of $S_1$ form the $\sigma$-algebra:</p> \[\sigma(S_1) = \{\emptyset, \{HH, HT\}, \{TH, TT\}, \Omega\}.\] <p>(iii) To check independence under $\tilde{\mathbb{P}}$, we verify that for any $A \in \sigma(X)$ and $B \in \sigma(S_1)$,</p> \[\tilde{\mathbb{P}}(A \cap B) = \tilde{\mathbb{P}}(A) \tilde{\mathbb{P}}(B).\] <p>Consider $A = {HT, TH}$ (where $X=1$) and $B = {HH, HT}$ (where $S_1 = 8$):</p> \[\tilde{\mathbb{P}}(A) = \tilde{\mathbb{P}}(\{HT, TH\}) = \frac{1}{4} + \frac{1}{4} = \frac{1}{2},\] \[\tilde{\mathbb{P}}(B) = \tilde{\mathbb{P}}(\{HH, HT\}) = \frac{1}{4} + \frac{1}{4} = \frac{1}{2}.\] <p>The intersection $A \cap B = {HT}$, so:</p> \[\tilde{\mathbb{P}}(A \cap B) = \tilde{\mathbb{P}}(\{HT\}) = \frac{1}{4}.\] <p>Since</p> \[\tilde{\mathbb{P}}(A \cap B) = \tilde{\mathbb{P}}(A) \tilde{\mathbb{P}}(B) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4},\] <p>$X$ and $S_1$ are independent under $\tilde{\mathbb{P}}$.</p> <p>(iv) Under $\mathbb{P}$, we check the same independence condition.</p> \[\mathbb{P}(A) = \mathbb{P}(\{HT, TH\}) = \frac{2}{9} + \frac{2}{9} = \frac{4}{9},\] \[\mathbb{P}(B) = \mathbb{P}(\{HH, HT\}) = \frac{4}{9} + \frac{2}{9} = \frac{6}{9}.\] <p>The intersection $A \cap B = {HT}$, so:</p> \[\mathbb{P}(A \cap B) = \mathbb{P}(\{HT\}) = \frac{2}{9}.\] <p>However,</p> \[\mathbb{P}(A) \mathbb{P}(B) = \frac{4}{9} \times \frac{6}{9} = \frac{24}{81} = \frac{8}{27} \neq \frac{2}{9}.\] <p>Since $\mathbb{P}(A \cap B) \neq \mathbb{P}(A) \mathbb{P}(B)$, $X$ and $S_1$ are not independent under $\mathbb{P}$.</p> <p>(v) We are given that under $\mathbb{P}$,</p> \[\mathbb{P}(S_1 = 8) = \frac{2}{3}, \quad \mathbb{P}(S_1 = 2) = \frac{1}{3}.\] <p>However, if we are told that $X = 1$, this means that we are restricting to the event where $S_2 = 4$, which happens for ${HT, TH}$. We must then compute the conditional probabilities of $S_1$ given $X=1$. From the problem setup:</p> <ul> <li>$S_1(HT) = 8$, $S_1(TH) = 2$.</li> <li>$\mathbb{P}(HT) = \frac{2}{9}$, $\mathbb{P}(TH) = \frac{2}{9}$. Since $X=1$ corresponds to ${HT, TH}$, we normalize:</li> </ul> \[\mathbb{P}(S_1 = 8 \mid X = 1) = \frac{\mathbb{P}(HT)}{\mathbb{P}(HT) + \mathbb{P}(TH)} = \frac{\frac{2}{9}}{\frac{4}{9}} = \frac{1}{2}.\] <p>Similarly,</p> \[\mathbb{P}(S_1 = 2 \mid X = 1) = \frac{\mathbb{P}(TH)}{\mathbb{P}(HT) + \mathbb{P}(TH)} = \frac{\frac{2}{9}}{\frac{4}{9}} = \frac{1}{2}.\] <p>Thus, knowing that $X=1$ changes our estimate of the distribution of $S_1$ from:</p> \[\mathbb{P}(S_1 = 8) = \frac{2}{3}, \quad \mathbb{P}(S_1 = 2) = \frac{1}{3}\] \[\mathbb{P}(S_1 = 8 \mid X=1) = \frac{1}{2}, \quad \mathbb{P}(S_1 = 2 \mid X=1) = \frac{1}{2}.\] <p><strong>Exercise 2.3</strong> Since $X$ and $Y$ are standard normal, we have:</p> \[\mathbb{E}[X] = 0, \quad \mathbb{E}[Y] = 0, \quad \text{Var}(X) = 1, \quad \text{Var}(Y) = 1.\] <p>Using linearity of expectation,</p> \[\mathbb{E}[V] = \mathbb{E}[X \cos \theta + Y \sin \theta] = \cos \theta \mathbb{E}[X] + \sin \theta \mathbb{E}[Y] = 0.\] <p>Similarly,</p> \[\mathbb{E}[W] = \mathbb{E}[-X \sin \theta + Y \cos \theta] = -\sin \theta \mathbb{E}[X] + \cos \theta \mathbb{E}[Y] = 0.\] <p>Now, compute the variances:</p> \[\begin{align*} \text{Var}(V) &amp;= \text{Var}(X \cos \theta + Y \sin \theta) \\ &amp;= \cos^2 \theta \text{Var}(X) + \sin^2 \theta \text{Var}(Y) + 2\cos \theta \sin \theta \text{Cov}(X,Y). \end{align*}\] <p>Since $X$ and $Y$ are independent, $\text{Cov}(X, Y) = 0$, so:</p> \[\text{Var}(V) = \cos^2 \theta + \sin^2 \theta = 1.\] <p>Similarly, for $W$:</p> \[\begin{align*} \text{Var}(W) &amp;= \text{Var}(-X \sin \theta + Y \cos \theta) \\ &amp;= \sin^2 \theta \text{Var}(X) + \cos^2 \theta \text{Var}(Y) - 2\sin \theta \cos \theta \text{Cov}(X,Y) = 1. \end{align*}\] <p>Thus, both $V$ and $W$ are standard normal. To check independence, we compute the covariance:</p> \[\begin{align*} \text{Cov}(V, W) &amp;= \text{Cov}(X \cos \theta + Y \sin \theta, -X \sin \theta + Y \cos \theta) \\ &amp;= -\cos \theta \sin \theta \text{Var}(X) + \sin \theta \cos \theta \text{Var}(Y) \\ &amp;\quad + (\cos \theta \cos \theta - \sin \theta \sin \theta) \text{Cov}(X, Y). \end{align*}\] <p>Since $X$ and $Y$ are independent, $\text{Cov}(X, Y) = 0$, so:</p> \[\text{Cov}(V, W) = -\cos \theta \sin \theta + \sin \theta \cos \theta = 0.\] <p>Since $V$ and $W$ are jointly normal and uncorrelated, they are independent.</p> <p><strong>Exercise 2.4</strong> (i) We compute the joint moment-generating function (MGF) of $(X, Y)$. Given that $Y = XZ$ and that $Z$ takes values $\pm 1$ with equal probability, we have:</p> \[\mathbb{E}[e^{uX + vY}] = \mathbb{E}[e^{uX + vXZ}].\] <p>Since $Z$ is independent of $X$, we condition on $Z$:</p> \[\mathbb{E}[e^{uX + vXZ}] = \frac{1}{2} \mathbb{E}[e^{uX + vX}] + \frac{1}{2} \mathbb{E}[e^{uX - vX}].\] <p>Factor out the terms:</p> \[= \frac{1}{2} \mathbb{E}[e^{(u+v)X}] + \frac{1}{2} \mathbb{E}[e^{(u-v)X}].\] <p>Using the MGF of a standard normal variable, $\mathbb{E}[e^{tX}] = e^{\frac{1}{2} t^2}$, we get:</p> \[= \frac{1}{2} e^{\frac{1}{2} (u+v)^2} + \frac{1}{2} e^{\frac{1}{2} (u-v)^2}.\] <p>Expanding the squares:</p> \[= \frac{1}{2} e^{\frac{1}{2} (u^2 + 2uv + v^2)} + \frac{1}{2} e^{\frac{1}{2} (u^2 - 2uv + v^2)}.\] <p>Factor out the common term:</p> \[= e^{\frac{1}{2} (u^2 + v^2)} \cdot \frac{e^{uv} + e^{-uv}}{2}.\] <p>Since $\frac{e^{uv} + e^{-uv}}{2} = \cosh(uv)$, we obtain the final result:</p> \[\mathbb{E}[e^{uX + vY}] = e^{\frac{1}{2} (u^2 + v^2)} \cdot \cosh(uv).\] <p>(ii) To find $\mathbb{E}[e^{vY}]$, set $u = 0$ in the joint MGF:</p> \[\mathbb{E}[e^{vY}] = e^{\frac{1}{2} v^2} \cdot \frac{e^0 + e^0}{2} = e^{\frac{1}{2} v^2}.\] <p>This is the MGF of a standard normal variable, so $Y$ is standard normal.</p> <p>(iii) If $X$ and $Y$ were independent, their joint MGF would factor as the product of their individual MGFs:</p> \[\mathbb{E}[e^{uX+vY}] = \mathbb{E}[e^{uX}] \mathbb{E}[e^{vY}].\] <p>We check:</p> \[\begin{align*} \mathbb{E}[e^{uX}] \mathbb{E}[e^{vY}] &amp;= e^{\frac{1}{2} u^2} \cdot e^{\frac{1}{2} v^2} = e^{\frac{1}{2} (u^2 + v^2)}. \end{align*}\] <p>Comparing with the joint MGF:</p> \[\mathbb{E}[e^{uX + vY}] = e^{\frac{1}{2} (u^2 + v^2)} \cosh(uv).\] <p>Since $\cosh(uv) \neq 1$ for $uv \neq 0$, the joint MGF is not the product of the individual MGFs, proving that $X$ and $Y$ are not independent.</p> <p><strong>Exercise 2.5</strong> To find the marginal density of $X$, integrate out $y$:</p> \[f_X(x) = \int_{- |x|}^{\infty} f_{X,Y}(x,y) dy.\] <p>Substituting $f_{X,Y}(x,y)$:</p> \[f_X(x) = \int_{- |x|}^{\infty} \frac{2|x|+y}{\sqrt{2\pi}} \exp \left(-\frac{(2|x|+y)^2}{2} \right) dy.\] <table> <tbody> <tr> <td>Let $u = 2</td> <td>x</td> <td>+ y$, so $du = dy$, and changing limits, $y = -</td> <td>x</td> <td>$ corresponds to $u =</td> <td>x</td> <td>$:</td> </tr> </tbody> </table> \[f_X(x) = \int_{|x|}^{\infty} \frac{u}{\sqrt{2\pi}} e^{-u^2/2} du.\] <p>Using the known result for the standard normal density,</p> \[f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}.\] <p>Thus, $X \sim \mathcal{N}(0,1)$. A similar calculation shows $Y \sim \mathcal{N}(0,1)$. We compute:</p> \[\mathbb{E}[XY] = \int_{-\infty}^{\infty} \int_{-|x|}^{\infty} xy f_{X,Y}(x,y) dy dx.\] <p>Since $f_{X,Y}(x,y)$ is symmetric in $x$ and $y$ (odd function in $x$ or $y$), the integral evaluates to zero:</p> \[\mathbb{E}[XY] = 0.\] <p>Since $\mathbb{E}[X] = \mathbb{E}[Y] = 0$, we conclude:</p> \[\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X] \mathbb{E}[Y] = 0.\] <p>Thus, $X$ and $Y$ are uncorrelated. If $X$ and $Y$ were independent, we would have $f_{X,Y}(x,y) = f_X(x) f_Y(y)$. However, from the given form of $f_{X,Y}(x,y)$, we see that the density depends on $x$ and $y$ in a way that does not factor as a product of functions in $x$ and $y$. This dependence implies $X$ and $Y$ are not independent.</p> <p><strong>Exercise 2.6</strong> (i) List the sets in $\sigma(X)$ The $\sigma$-algebra $\sigma(X)$ consists of all sets that can be distinguished by $X$. Since $X$ takes only two values, we partition $\Omega$ based on those values:</p> \[\sigma(X) = \{ \emptyset, \Omega, \{a,b\}, \{c,d\} \}.\] <p>This follows because $X(a) = X(b) = 1$ and $X(c) = X(d) = -1$, so $\sigma(X)$ is generated by the partition ${ {a,b}, {c,d} }$.</p> <p>(ii) Determine $\mathbb{E}[Y|X]$ We compute $\mathbb{E}[Y | X]$ by conditioning on the sets in $\sigma(X)$:</p> <ul> <li>If $X = 1$ (i.e., $\omega \in {a, b}$),</li> </ul> \[\mathbb{E}[Y | X = 1] = \mathbb{E}[Y | \{a,b\}] = \frac{\mathbb{P}(a) Y(a) + \mathbb{P}(b) Y(b)}{\mathbb{P}(a) + \mathbb{P}(b)}\] \[= \frac{\frac{1}{6} (1) + \frac{1}{3} (-1)}{\frac{1}{6} + \frac{1}{3}} = \frac{\frac{1}{6} - \frac{2}{6}}{\frac{3}{6}} = -\frac{1}{3}.\] <ul> <li>If $X = -1$ (i.e., $\omega \in {c, d}$),</li> </ul> \[\mathbb{E}[Y | X = -1] = \mathbb{E}[Y | \{c,d\}] = \frac{\mathbb{P}(c) Y(c) + \mathbb{P}(d) Y(d)}{\mathbb{P}(c) + \mathbb{P}(d)}\] \[= \frac{\frac{1}{4} (1) + \frac{1}{4} (-1)}{\frac{1}{4} + \frac{1}{4}} = 0.\] <p>Thus,</p> \[\mathbb{E}[Y | X] = \begin{cases} - \frac{1}{3}, &amp; X = 1, \\ 0, &amp; X = -1. \end{cases}\] <p>We verify the partial-averaging property:</p> \[\mathbb{E}[\mathbb{E}[Y | X]] = \mathbb{E} \left[ -\frac{1}{3} 1 \cdot \mathbb{P}(\{a, b\}) + 0 \cdot \mathbb{P}(\{c,d\}) \right] = -\frac{1}{3} \times \frac{1}{2} + 0 \times \frac{1}{2} = 0.\] <p>Since $\mathbb{E}[Y] = 0$, the property holds.</p> <p>(iii) Determine $\mathbb{E}[Z|X]$ Since $Z = X + Y$, we use linearity of conditional expectation:</p> \[\mathbb{E}[Z | X] = \mathbb{E}[X | X] + \mathbb{E}[Y | X] = X + \mathbb{E}[Y | X].\] <table> <tbody> <tr> <td>Thus, using our previous result for $\mathbb{E}[Y</td> <td>X]$:</td> </tr> </tbody> </table> \[\mathbb{E}[Z | X] = \begin{cases} 1 - \frac{1}{3} = \frac{2}{3}, &amp; X = 1, \\ -1 + 0 = -1, &amp; X = -1. \end{cases}\] <p>Again, verifying the partial-averaging property:</p> \[\mathbb{E}[\mathbb{E}[Z | X]] = \mathbb{E} \left[ \frac{2}{3} \mathbb{I}_{X=1} - 1 \mathbb{I}_{X=-1} \right] = \frac{2}{3} \times \frac{1}{2} + (-1) \times \frac{1}{2} = 0.\] <p>Since $\mathbb{E}[Z] = 0$, the property holds.</p> <table> <tbody> <tr> <td>(iv) Compute $\mathbb{E}[Z</td> <td>X] - \mathbb{E}[Y</td> <td>X]$ and explain why $\mathbb{E}[X</td> <td>X] = X$</td> </tr> <tr> <td>From part (iii), we already have $\mathbb{E}[Z</td> <td>X] = X + \mathbb{E}[Y</td> <td>X]$, so:</td> <td> </td> </tr> </tbody> </table> \[\mathbb{E}[Z | X] - \mathbb{E}[Y | X] = X + \mathbb{E}[Y | X] - \mathbb{E}[Y | X] = X.\] <table> <tbody> <tr> <td>This follows directly from the fact that $\mathbb{E}[X</td> <td>X] = X$ (since conditioning on $X$ provides no new information about $X$).</td> </tr> </tbody> </table> <p><strong>Exercise 2.7</strong> We are given an integrable random variable $Y$ and a sub-$\sigma$-algebra $\mathcal{G}$. The best estimate of $Y$ given $\mathcal{G}$ is $\mathbb{E}[Y | \mathcal{G}]$, and we define the error term as:</p> \[\text{Err} = Y - \mathbb{E}[Y | \mathcal{G}].\] <p>We want to show that for any other $\mathcal{G}$-measurable estimate $X$, we have:</p> \[\text{Var}(\text{Err}) \leq \text{Var}(Y - X).\] <p>Define $\mu = \mathbb{E}[Y - X]$. The variance of $Y - X$ can be rewritten as:</p> \[\mathbb{E}[(Y - X - \mu)^2] = \mathbb{E} \left( (Y - \mathbb{E}[Y | \mathcal{G}]) + (\mathbb{E}[Y | \mathcal{G}] - X - \mu) \right)^2.\] <p>Expanding the square, we get:</p> \[\mathbb{E}[(Y - X - \mu)^2] = \mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}])^2] + \mathbb{E}[(\mathbb{E}[Y | \mathcal{G}] - X - \mu)^2] + 2\mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}])(\mathbb{E}[Y | \mathcal{G}] - X - \mu)].\] <p>Using the tower property of conditional expectation:</p> \[\mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}]) | \mathcal{G}] = 0.\] <table> <tbody> <tr> <td>Since $\mathbb{E}[Y</td> <td>\mathcal{G}] - X - \mu$ is $\mathcal{G}$-measurable, we take expectations:</td> </tr> </tbody> </table> \[\mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}])(\mathbb{E}[Y | \mathcal{G}] - X - \mu)] = \mathbb{E}[\mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}]) | \mathcal{G}] (\mathbb{E}[Y | \mathcal{G}] - X - \mu)] = 0.\] <p>Thus, the variance simplifies to:</p> \[\mathbb{E}[(Y - X - \mu)^2] = \mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}])^2] + \mathbb{E}[(\mathbb{E}[Y | \mathcal{G}] - X - \mu)^2].\] <p>Since variance is non-negative, we conclude:</p> \[\text{Var}(\text{Err}) = \mathbb{E}[(Y - \mathbb{E}[Y | \mathcal{G}])^2] \leq \mathbb{E}[(Y - X)^2] = \text{Var}(Y - X).\] <table> <tbody> <tr> <td>Thus, $\mathbb{E}[Y</td> <td>\mathcal{G}]$ minimizes the variance of the error, proving the result.</td> </tr> </tbody> </table> <p><strong>Exercise 2.8</strong> We are given integrable random variables $X$ and $Y$ on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. We decompose $Y$ into two components:</p> \[Y = Y_1 + Y_2,\] <p>where</p> \[Y_1 = \mathbb{E}[Y | X]\] <p>is $\sigma(X)$-measurable, and</p> \[Y_2 = Y - \mathbb{E}[Y | X]\] <p>is the residual component. We want to show that $Y_2$ and $X$ are uncorrelated and, more generally, that $Y_2$ is uncorrelated with any $\sigma(X)$-measurable random variable. The covariance between $Y_2$ and $X$ is given by:</p> \[\text{Cov}(Y_2, X) = \mathbb{E}[Y_2 X] - \mathbb{E}[Y_2] \mathbb{E}[X].\] <table> <tbody> <tr> <td>Since $Y_2 = Y - \mathbb{E}[Y</td> <td>X]$, we substitute:</td> </tr> </tbody> </table> \[\mathbb{E}[Y_2 X] = \mathbb{E}[(Y - \mathbb{E}[Y | X]) X].\] <p>Using the linearity of expectation:</p> \[\mathbb{E}[Y_2 X] = \mathbb{E}[Y X] - \mathbb{E}[\mathbb{E}[Y | X] X].\] <p>By the tower property of conditional expectation:</p> \[\mathbb{E}[\mathbb{E}[Y | X] X] = \mathbb{E}[\mathbb{E}[Y X | X]] = \mathbb{E}[Y X].\] <p>Thus,</p> \[\mathbb{E}[Y_2 X] = \mathbb{E}[Y X] - \mathbb{E}[Y X] = 0.\] <p>Since $\mathbb{E}[Y_2] = 0$ by construction, we conclude:</p> \[\text{Cov}(Y_2, X) = 0.\] <p>Thus, $Y_2$ and $X$ are uncorrelated. Let $Z$ be any $\sigma(X)$-measurable random variable. We compute:</p> \[\mathbb{E}[Y_2 Z] = \mathbb{E}[(Y - \mathbb{E}[Y | X]) Z].\] <p>Since $Z$ is $\sigma(X)$-measurable, we write:</p> \[\mathbb{E}[Y_2 Z] = \mathbb{E}[\mathbb{E}[(Y - \mathbb{E}[Y | X]) Z | X]].\] <table> <tbody> <tr> <td>Since $\mathbb{E}[Y</td> <td>X]$ is the best $\sigma(X)$-measurable approximation of $Y$, we have:</td> </tr> </tbody> </table> \[\mathbb{E}[(Y - \mathbb{E}[Y | X]) | X] = 0.\] <p>Thus, for any $\sigma(X)$-measurable $Z$,</p> \[\mathbb{E}[Y_2 Z] = 0.\] <p>This shows that $Y_2$ is uncorrelated with every $\sigma(X)$-measurable random variable.</p> <p><strong>Exercise 2.9</strong> (i) Example where $\sigma(f(X))$ is strictly smaller than $\sigma(X)$</p> <p>Let the probability space be:</p> \[\Omega = \{ \omega_1, \omega_2, \omega_3, \omega_4 \},\] <p>with the power set $\mathcal{F} = 2^{\Omega}$ as the $\sigma$-algebra and a uniform probability measure $\mathbb{P}$ assigning probability $\frac{1}{4}$ to each outcome.</p> <p>Define a random variable $X: \Omega \to \mathbb{R}$ by:</p> \[X(\omega_1) = 1, \quad X(\omega_2) = 2, \quad X(\omega_3) = 3, \quad X(\omega_4) = 4.\] <p>The $\sigma$-algebra generated by $X$, denoted $\sigma(X)$, is:</p> \[\sigma(X) = \{ \emptyset, \Omega, \{ \omega_1 \}, \{ \omega_2 \}, \{ \omega_3 \}, \{ \omega_4 \}, \{ \omega_1, \omega_2 \}, \{ \omega_3, \omega_4 \} \}.\] <p>Now, define a function $f: \mathbb{R} \to \mathbb{R}$ such that:</p> \[f(X) = \begin{cases} a, &amp; X = 1 \text{ or } 2, \\ b, &amp; X = 3 \text{ or } 4. \end{cases}\] <p>The $\sigma$-algebra generated by $f(X)$ is:</p> \[\sigma(f(X)) = \{ \emptyset, \Omega, \{ \omega_1, \omega_2 \}, \{ \omega_3, \omega_4 \} \}.\] <p>Since $\sigma(f(X))$ is a proper subset of $\sigma(X)$, it is strictly smaller.</p> <p>(ii) Can $\sigma(f(X))$ ever be strictly larger than $\sigma(X)$?</p> <p>No, the $\sigma$-algebra generated by $f(X)$ can never be strictly larger than $\sigma(X)$.</p> <p>By definition, $\sigma(f(X))$ consists of all subsets of $\Omega$ that can be expressed in terms of $f(X)$, while $\sigma(X)$ consists of all subsets expressible in terms of $X$. Since $f(X)$ is a function of $X$, every event in $\sigma(f(X))$ is already in $\sigma(X)$. That is:</p> \[\sigma(f(X)) \subseteq \sigma(X).\] <p>Thus, $\sigma(f(X))$ can either be equal to $\sigma(X)$ (if $f$ is injective on the range of $X$) or strictly smaller but never larger.</p> <p><strong>Exercise 2.10</strong> To show that $\mathbb{E}[Y|X] = g(X)$, we verify the partial-averaging property. First, recall the definition of conditional expectation:</p> \[\mathbb{E}[Y|X = x] = g(x) = \int_{-\infty}^{\infty} y f_{Y|X}(y|x) dy.\] <p>By definition of the conditional density:</p> \[f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)}.\] <p>Thus, we rewrite:</p> \[g(x) = \int_{-\infty}^{\infty} y \frac{f_{X,Y}(x,y)}{f_X(x)} dy.\] <p>To confirm that $\mathbb{E}[Y|X] = g(X)$, we check the partial-averaging property: For any $\sigma(X)$-measurable function $h(X)$, we must show:</p> \[\int_A g(X) d\mathbb{P} = \int_A Y d\mathbb{P}.\] <p>Expanding both integrals:</p> \[\begin{align*} \int_A g(X) d\mathbb{P} &amp;= \int_A \left( \int_{-\infty}^{\infty} y f_{Y|X}(y|X) dy \right) d\mathbb{P} \\ &amp;= \int_A \int_{-\infty}^{\infty} y f_{Y|X}(y|X) dy d\mathbb{P}. \end{align*}\] <p>Using Fubini’s theorem:</p> \[\begin{align*} \int_A g(X) d\mathbb{P} &amp;= \int_{-\infty}^{\infty} y \left( \int_A f_{Y|X}(y|X) d\mathbb{P} \right) dy. \end{align*}\] <p>By the definition of conditional expectation:</p> \[\int_A f_{Y|X}(y|X) d\mathbb{P} = \int_A f_{X,Y}(X,y) d\mathbb{P}.\] <p>Thus,</p> \[\begin{align*} \int_A g(X) d\mathbb{P} &amp;= \int_{-\infty}^{\infty} y \left( \int_A f_{X,Y}(X,y) d\mathbb{P} \right) dy \\ &amp;= \int_A Y d\mathbb{P}. \end{align*}\] <table> <tbody> <tr> <td>This verifies that $\mathbb{E}[Y</td> <td>X] = g(X)$, completing the proof.</td> </tr> </tbody> </table> <p><strong>Exercise 2.11</strong> (i) Existence of a function $g$ such that $W = g(X)$</p> <p>Since $W$ is $\sigma(X)$-measurable, by definition, there exists a function $g: \mathbb{R} \to \mathbb{R}$ such that:</p> \[W = g(X).\] <p>To construct $g(X)$, consider that every set in $\sigma(X)$ is of the form ${X \in B}$ for some Borel set $B \subset \mathbb{R}$. We analyze this in steps:</p> <ol> <li> <strong>Step 1: Indicator Functions</strong><br> Suppose $W$ is an indicator function of such a set $B$:</li> </ol> \[W = \mathbb{1}_{B}(X).\] <p>Then we can simply define:</p> \[g(x) = \mathbb{1}_{B}(x),\] <p>which satisfies $W = g(X)$.</p> <ol> <li> <strong>Step 2: Simple Functions</strong><br> If $W$ is a simple function, it can be written as:</li> </ol> \[W = \sum_{i=1}^{n} c_i \mathbb{1}_{B_i}(X).\] <p>Defining:</p> \[g(x) = \sum_{i=1}^{n} c_i \mathbb{1}_{B_i}(x),\] <p>again ensures $W = g(X)$.</p> <ol> <li> <strong>Step 3: General Nonnegative Functions</strong><br> More generally, any nonnegative $\sigma(X)$-measurable function $W$ can be approximated by a sequence of simple functions $W_n$ that converge to $W$. Since each $W_n$ has a corresponding function $g_n(x)$, we define:</li> </ol> \[g(x) = \lim_{n \to \infty} g_n(x).\] <p>By the standard construction of measurable functions, this function satisfies $W = g(X)$. Thus, there exists a function $g$ such that $W = g(X)$, as required.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kenneth Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"},svg:{scale:1.1,minScale:.8,matchFontHeight:!1}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-notes",title:"notes",description:"Personal-study notes for quant-finance related learning materials",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"notes-stochastic-calculus-for-finance-i",title:"Stochastic Calculus for Finance I",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance I",section:"Notes",handler:()=>{window.location.href="/notes/course-1/"}},{id:"notes-stochastic-calculus-for-finance-ii",title:"Stochastic Calculus for Finance II",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance II",section:"Notes",handler:()=>{window.location.href="/notes/course-2/"}},{id:"notes-chapter-1-no-arbitrage-pricing-model",title:"Chapter 1 - No-Arbitrage Pricing Model",description:"Notes on the No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-no-arbitrage/"}},{id:"notes-chapter-1-exercises",title:"Chapter 1 Exercises",description:"Exercises for Chapter 1 - No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-exercises/"}},{id:"notes-chapter-2-exercises",title:"Chapter 2 Exercises",description:"Exercises for Chapter 2 - Probability Theory on Coin Toss Space.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-exercises/"}},{id:"notes-chapter-2-probability-theory-on-coin-toss-space",title:"Chapter 2 - Probability Theory on Coin Toss Space",description:"Notes on probability theory applied to coin toss spaces.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-probability/"}},{id:"notes-chapter-3-state-prices",title:"Chapter 3 - State Prices",description:"Notes on State Prices in financial models.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-state-prices/"}},{id:"notes-chapter-3-exercises",title:"Chapter 3 Exercises",description:"Exercises for Chapter 3 - State Prices.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-exercises/"}},{id:"notes-chapter-4-american-derivative-securities",title:"Chapter 4 - American Derivative Securities",description:"Notes on American derivative securities and their valuation.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-4-american-derivatives/"}},{id:"notes-chapter-1-general-probability-theory",title:"Chapter 1 - General Probability Theory",description:"Notes on general probability theory and foundational concepts.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-general-probability/"}},{id:"notes-chapter-1-probability-exercises",title:"Chapter 1 - Probability Exercises",description:"Exercises for Chapter 1 - General Probability Theory.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-probability-exercises/"}},{id:"notes-chapter-2-information-exercises",title:"Chapter 2 - Information Exercises",description:"Exercises for Chapter 2 - Information and Conditioning.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-exercises/"}},{id:"notes-chapter-2-information-and-conditioning",title:"Chapter 2 - Information and Conditioning",description:"Notes on information theory and conditional probability.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-conditioning/"}},{id:"notes-chapter-3-brownian-motion-exercises",title:"Chapter 3 - Brownian Motion Exercises",description:"Exercises for Chapter 3 - Brownian Motion.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion-exercises/"}},{id:"notes-chapter-3-brownian-motion",title:"Chapter 3 - Brownian Motion",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion/"}},{id:"notes-chapter-4-stochastic-calculus",title:"Chapter 4 - Stochastic Calculus",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-stochastic-calculus/"}},{id:"projects-the-lagging-indicator-chronicles-a-tale-of-policies-playing-catch-up",title:"The Lagging Indicator Chronicles \u2013 A Tale of Policies Playing Catch-Up",description:"Lag time between state-level policy interventions and change points in COVID-19 outcomes in the United States. Read more at ![this article](https://www.cell.com/patterns/fulltext/S2666-3899(21)00149-5).",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-pm2-5-and-the-great-regulatory-vanishing-act-when-pollution-took-a-free-pass",title:"PM2.5 and the Great Regulatory Vanishing Act - When Pollution Took a Free...",description:"An introduction to the statistical models used to assess the impact of EPA rollbacks on air quality in California. https://enveurope.springeropen.com/articles/10.1186/s12302-021-00489-9",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> </body> </html>
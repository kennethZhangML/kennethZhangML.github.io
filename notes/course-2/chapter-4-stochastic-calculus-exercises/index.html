<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chapter 4 - Stochastic Calculus Exercises | Kenneth Zhang </title> <meta name="author" content="Kenneth Zhang"> <meta name="description" content="Notes on Stochastic Calculus and its applications."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kennethzhangml.github.io/notes/course-2/chapter-4-stochastic-calculus-exercises/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kenneth</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Chapter 4 - Stochastic Calculus Exercises</h1> <p class="post-description">Notes on Stochastic Calculus and its applications.</p> </header> <article> <p><strong>Exercise 4.1</strong><br> Suppose $M(t)$, $0 \leq t \leq T$, is a martingale with respect to some filtration $\mathcal{F}(t)$, and let $\Delta(t)$ be a simple predictable process adapted to $\mathcal{F}(t)$ on a partition $\Pi = {t_0, t_1, \ldots, t_n}$.</p> <p>Define the stochastic integral process:</p> \[I(t) = \sum_{j=0}^{k-1} \Delta(t_j)[M(t_{j+1}) - M(t_j)] + \Delta(t_k)[M(t) - M(t_k)], \quad \text{for } t \in [t_k, t_{k+1}).\] <p>We aim to show that $I(t)$ is a martingale.</p> <p>Since $\Delta(t_j)$ is $\mathcal{F}(t_j)$-measurable and constant on each subinterval $[t_j, t_{j+1})$, and $M(t)$ is adapted, each summand $\Delta(t_j)[M(t_{j+1}) - M(t_j)]$ and $\Delta(t_k)[M(t) - M(t_k)]$ is $\mathcal{F}(t_{j+1})$-measurable, hence adapted. $M(t)$ is integrable by assumption, and since $\Delta(t_j)$ is simple and bounded, each term is integrable. Therefore, $I(t)$ is integrable and adapted.</p> <p>To check the martingale property, let $s &lt; t$, and suppose $s \in [t_m, t_{m+1})$, $t \in [t_k, t_{k+1})$ with $m &lt; k$. We write:</p> \[I(t) = \sum_{j=0}^{k-1} \Delta(t_j)[M(t_{j+1}) - M(t_j)] + \Delta(t_k)[M(t) - M(t_k)]\] <p>and break it as:</p> \[\begin{align*} I(t) = \sum_{j=0}^{m-1} \Delta(t_j)[M(t_{j+1}) - M(t_j)] + \Delta(t_m)[M(s) - M(t_m)] \\+ \sum_{j=m}^{k-1} \Delta(t_j)[M(t_{j+1}) - M(t_j)] + \Delta(t_k)[M(t) - M(t_k)]. \end{align*}\] <p>Take conditional expectation with respect to $\mathcal{F}(s)$. Since $M(t)$ is a martingale:</p> <ul> <li>For $t_j \geq s$, $\mathbb{E}[M(t_{j+1}) - M(t_j) \mid \mathcal{F}(s)] = 0$,</li> <li>$\Delta(t_j)$ is $\mathcal{F}(t_j)$-measurable and $t_j \leq s$, so it’s constant under $\mathbb{E}[\cdot \mid \mathcal{F}(s)]$.</li> </ul> <p>Therefore,</p> \[\mathbb{E}[I(t) \mid \mathcal{F}(s)] = \sum_{j=0}^{m-1} \Delta(t_j)[M(t_{j+1}) - M(t_j)] + \Delta(t_m)[M(s) - M(t_m)] = I(s).\] <p>This shows that $I(t)$ satisfies the martingale property:</p> \[\mathbb{E}[I(t) \mid \mathcal{F}(s)] = I(s), \quad \forall 0 \leq s &lt; t \leq T.\] <p>Hence, $I(t)$ is a martingale.</p> <p><strong>Exercise 4.2</strong><br> Let $W(t)$, $0 \leq t \leq T$, be a Brownian motion with associated filtration $\mathcal{F}(t)$. Let $\Delta(t)$ be a <strong>nonrandom</strong> simple process: there exists a partition $\Pi = {t_0, t_1, \ldots, t_n}$ of $[0,T]$ such that $\Delta(t) = \Delta(t_j)$ on $[t_j, t_{j+1})$, and each $\Delta(t_j)$ is a deterministic constant.</p> <p>For $t \in [t_k, t_{k+1})$, define the stochastic integral:</p> \[I(t) = \sum_{j=0}^{k-1} \Delta(t_j)[W(t_{j+1}) - W(t_j)] + \Delta(t_k)[W(t) - W(t_k)].\] <p><strong>(i)</strong> Show that whenever $0 \leq s &lt; t \leq T$, the increment $I(t) - I(s)$ is independent of $\mathcal{F}(s)$.</p> <p>If $s$ is not a partition point, insert $s$ into the partition as $t_k = s$ and set $\Delta(s) = \Delta(t_{k-1})$ to preserve the constant value of $\Delta$ over the interval. Do the same for $t$ if needed.</p> <p>Now both $s$ and $t$ are partition points. Then:</p> \[I(t) - I(s) = \sum_{j=k}^{l-1} \Delta(t_j)[W(t_{j+1}) - W(t_j)] + \Delta(t_l)[W(t) - W(t_l)],\] <p>where $s = t_k$ and $t \in [t_l, t_{l+1})$.</p> <p>Each Brownian increment $W(t_{j+1}) - W(t_j)$ and $W(t) - W(t_l)$ is independent of $\mathcal{F}(s)$ because Brownian motion has independent increments and $t_j \geq s$ for all terms in the sum.</p> <p>Therefore, $I(t) - I(s)$ depends only on Brownian motion after time $s$ and is thus independent of $\mathcal{F}(s)$.</p> <p><strong>(ii)</strong> Show that whenever $0 \leq s &lt; t \leq T$, the increment $I(t) - I(s)$ is a normally distributed random variable with mean zero and variance $\int_s^t \Delta^2(u) \, du$.</p> <p>From (i), we know:</p> \[I(t) - I(s) = \sum_{j=k}^{l-1} \Delta(t_j)[W(t_{j+1}) - W(t_j)] + \Delta(t_l)[W(t) - W(t_l)],\] <p>where $s = t_k$, $t \in [t_l, t_{l+1})$.</p> <p>Each $W(t_{j+1}) - W(t_j)$ is independent and distributed as $\mathcal{N}(0, t_{j+1} - t_j)$, and $\Delta(t_j)$ is constant.</p> <p>Hence, each term $\Delta(t_j)[W(t_{j+1}) - W(t_j)] \sim \mathcal{N}(0, \Delta^2(t_j)(t_{j+1} - t_j))$, and all terms are independent.</p> <p>The sum of independent normal variables is normal, so $I(t) - I(s) \sim \mathcal{N}(0, \sum \Delta^2(t_j)(t_{j+1} - t_j))$.</p> <p>This sum is exactly:</p> \[\int_s^t \Delta^2(u) \, du.\] <p><strong>(iii)</strong> Use (i) and (ii) to show that $I(t)$, $0 \leq t \leq T$, is a martingale.</p> <p>From (i), $I(t) - I(s)$ is independent of $\mathcal{F}(s)$, and from (ii), $\mathbb{E}[I(t) - I(s)] = 0$.</p> <p>Therefore,</p> \[\mathbb{E}[I(t) \mid \mathcal{F}(s)] = \mathbb{E}[I(s) + (I(t) - I(s)) \mid \mathcal{F}(s)] = I(s).\] <p>So $I(t)$ satisfies the martingale property and is therefore a martingale.</p> <p><strong>(iv)</strong> Show that $I^2(t) - \int_0^t \Delta^2(u) \, du$, $0 \leq t \leq T$, is a martingale.</p> <p>From (ii), the variance of the increment is:</p> \[\text{Var}(I(t) - I(s)) = \int_s^t \Delta^2(u) \, du.\] <p>Using the Itô isometry and properties of Brownian motion:</p> \[\mathbb{E}[I^2(t) - I^2(s) \mid \mathcal{F}(s)] = \mathbb{E}[(I(t) - I(s))^2 \mid \mathcal{F}(s)] = \int_s^t \Delta^2(u) \, du.\] <p>Therefore:</p> \[\mathbb{E}[I^2(t) \mid \mathcal{F}(s)] = I^2(s) + \int_s^t \Delta^2(u) \, du,\] <p>which implies:</p> \[\mathbb{E}\left[I^2(t) - \int_0^t \Delta^2(u) \, du \mid \mathcal{F}(s)\right] = I^2(s) - \int_0^s \Delta^2(u) \, du.\] <p>So the process $I^2(t) - \int_0^t \Delta^2(u) \, du$ is a martingale.</p> <p><strong>Exercise 4.3</strong><br> We now consider the case where $\Delta(t)$ is a simple <strong>random</strong> process. Let $t_0 = 0$, $t_1 = s$, and $t_2 = t$. Suppose $\Delta(0)$ is nonrandom, but $\Delta(s) = W(s)$ is <strong>random</strong> and $\mathcal{F}(s)$-measurable. Let</p> \[I(t) = \sum_{j=0}^{1} \Delta(t_j)[W(t_{j+1}) - W(t_j)] = \Delta(0)[W(s) - W(0)] + \Delta(s)[W(t) - W(s)].\] <p>We evaluate the truth of the following assertions:</p> <p><strong>(i)</strong> $I(t) - I(s)$ is independent of $\mathcal{F}(s)$.</p> <p>We compute:</p> \[I(t) - I(s) = \Delta(s)[W(t) - W(s)].\] <p>While $W(t) - W(s)$ is independent of $\mathcal{F}(s)$ by the independent increments property of Brownian motion, $\Delta(s) = W(s)$ is $\mathcal{F}(s)$-measurable. Therefore, the product $\Delta(s)[W(t) - W(s)]$ <strong>depends</strong> on $\mathcal{F}(s)$ through $\Delta(s)$.</p> <p>Hence, $I(t) - I(s)$ is <strong>not</strong> independent of $\mathcal{F}(s)$.</p> <p><strong>False</strong>.</p> <p><strong>(ii)</strong> $I(t) - I(s)$ is normally distributed.</p> <p>Recall:</p> \[I(t) - I(s) = \Delta(s)[W(t) - W(s)] = W(s)[W(t) - W(s)].\] <p>$W(s)$ and $W(t) - W(s)$ are independent, but $I(t) - I(s)$ is the <strong>product</strong> of two independent normal variables. The product of two independent normals is <strong>not</strong> normally distributed.</p> <p>To confirm, check the fourth moment:</p> <ul> <li>$\mathbb{E}[(I(t) - I(s))^4] \neq 3 \cdot \left( \text{Var}(I(t) - I(s)) \right)^2$.</li> </ul> <p>Hence, $I(t) - I(s)$ is <strong>not</strong> normally distributed.</p> <p><strong>False</strong>.</p> <p><strong>(iii)</strong> $\mathbb{E}[I(t) \mid \mathcal{F}(s)] = I(s)$.</p> <p>We have:</p> \[I(t) = I(s) + \Delta(s)[W(t) - W(s)] = I(s) + W(s)[W(t) - W(s)].\] <p>Then:</p> \[\mathbb{E}[I(t) \mid \mathcal{F}(s)] = I(s) + W(s)\cdot \mathbb{E}[W(t) - W(s) \mid \mathcal{F}(s)].\] <p>Since $W(t) - W(s)$ is independent of $\mathcal{F}(s)$ and has mean zero:</p> \[\mathbb{E}[I(t) \mid \mathcal{F}(s)] = I(s).\] <p><strong>True</strong>.</p> <p><strong>(iv)</strong></p> \[\mathbb{E}\left[ I^2(t) - \int_0^t \Delta^2(u) \, du \,\middle|\, \mathcal{F}(s) \right] = I^2(s) - \int_0^s \Delta^2(u) \, du.\] <p>We expand:</p> \[I^2(t) = \left( I(s) + \Delta(s)[W(t) - W(s)] \right)^2 = I^2(s) + 2 I(s)\Delta(s)[W(t) - W(s)] + \Delta^2(s)[W(t) - W(s)]^2.\] <p>Take expectation conditional on $\mathcal{F}(s)$:</p> <ul> <li>$\mathbb{E}[W(t) - W(s) \mid \mathcal{F}(s)] = 0$,</li> <li>$\mathbb{E}[(W(t) - W(s))^2 \mid \mathcal{F}(s)] = t - s$.</li> </ul> <p>So:</p> \[\mathbb{E}[I^2(t) \mid \mathcal{F}(s)] = I^2(s) + \Delta^2(s)(t - s),\] <p>and</p> \[\int_0^t \Delta^2(u) \, du = \int_0^s \Delta^2(u) \, du + \int_s^t \Delta^2(u) \, du = \int_0^s \Delta^2(u) \, du + \Delta^2(s)(t - s).\] <p>Therefore:</p> \[\mathbb{E}\left[ I^2(t) - \int_0^t \Delta^2(u) \, du \,\middle|\, \mathcal{F}(s) \right] = I^2(s) - \int_0^s \Delta^2(u) \, du.\] <p><strong>True</strong>.</p> <p><strong>Exercise 4.4 (Stratonovich integral)</strong><br> Let $W(t)$, $t \geq 0$, be a Brownian motion. Let $T &gt; 0$ and let $\Pi = {t_0, t_1, \ldots, t_n}$ be a partition of $[0, T]$ with $0 = t_0 &lt; t_1 &lt; \cdots &lt; t_n = T$. For each $j$, define the midpoint:</p> \[t_j^* = \frac{t_j + t_{j+1}}{2}.\] <p><strong>(i)</strong> Define the <em>half-sample quadratic variation</em> corresponding to $\Pi$ as:</p> \[Q_{\Pi/2} = \sum_{j=0}^{n-1} \left( W(t_j^*) - W(t_j) \right)^2.\] <p>We show that:</p> \[\mathbb{E}[Q_{\Pi/2}] = \sum_{j=0}^{n-1} \mathbb{E}\left[ \left( W(t_j^*) - W(t_j) \right)^2 \right] = \sum_{j=0}^{n-1} (t_j^* - t_j) = \sum_{j=0}^{n-1} \frac{t_{j+1} - t_j}{2} = \frac{1}{2} T.\] <p>Now compute the variance:</p> \[\text{Var}(Q_{\Pi/2}) = \sum_{j=0}^{n-1} \text{Var}\left( \left( W(t_j^*) - W(t_j) \right)^2 \right).\] <p>Each $W(t_j^*) - W(t_j)$ is a normal random variable with variance $(t_{j+1} - t_j)/2$, so its square has variance:</p> \[\text{Var}((W(t_j^*) - W(t_j))^2) = 2 \cdot \left( \frac{t_{j+1} - t_j}{2} \right)^2 = \frac{(t_{j+1} - t_j)^2}{2}.\] <p>Hence,</p> \[\text{Var}(Q_{\Pi/2}) = \sum_{j=0}^{n-1} \frac{(t_{j+1} - t_j)^2}{2} \leq \frac{1}{2} \|\Pi\| \sum_{j=0}^{n-1} (t_{j+1} - t_j) = \frac{1}{2} \|\Pi\| T.\] <p>As $|\Pi| \to 0$, the variance $\to 0$.</p> <p>Therefore, by Chebyshev’s inequality or convergence in $L^2$, we conclude:</p> \[Q_{\Pi/2} \to \frac{1}{2} T.\] <p><strong>(ii)</strong> Define the <em>Stratonovich integral</em> of $W(t)$ with respect to $W(t)$ as:</p> \[\int_0^T W(t) \circ dW(t) = \lim_{\|\Pi\| \to 0} \sum_{j=0}^{n-1} W(t_j^*) \left( W(t_{j+1}) - W(t_j) \right).\] <p>We aim to show:</p> \[\int_0^T W(t) \circ dW(t) = \frac{1}{2} W^2(T).\] <p>We write the Stratonovich sum as:</p> \[\sum_{j=0}^{n-1} W(t_j^*) \left( W(t_{j+1}) - W(t_j) \right) = \sum_{j=0}^{n-1} \left( \frac{W(t_j) + W(t_{j+1})}{2} \right) \left( W(t_{j+1}) - W(t_j) \right).\] <p>This is:</p> \[= \sum_{j=0}^{n-1} \left[ \frac{1}{2} \left( W(t_{j+1}) - W(t_j) \right)^2 + \frac{1}{2} W(t_j) \left( W(t_{j+1}) - W(t_j) \right) \right].\] <p>Now recall:</p> <ul> <li>The Itô integral is:</li> </ul> \[\int_0^T W(t) \, dW(t) = \lim_{\|\Pi\| \to 0} \sum_{j=0}^{n-1} W(t_j)(W(t_{j+1}) - W(t_j)).\] <p>So the Stratonovich integral equals:</p> \[\int_0^T W(t) \circ dW(t) = \int_0^T W(t) \, dW(t) + \frac{1}{2} \sum_{j=0}^{n-1} \left( W(t_{j+1}) - W(t_j) \right)^2.\] <p>In the limit, the sum becomes the quadratic variation:</p> \[[W](T) = \sum_{j=0}^{n-1} \left( W(t_{j+1}) - W(t_j) \right)^2 \to T.\] <p>And from Exercise 4.3 or standard result:</p> \[\int_0^T W(t) \, dW(t) = \frac{1}{2} W^2(T) - \frac{1}{2} T.\] <p>Hence:</p> \[\int_0^T W(t) \circ dW(t) = \left( \frac{1}{2} W^2(T) - \frac{1}{2} T \right) + \frac{1}{2} T = \frac{1}{2} W^2(T).\] <p><strong>Exercise 4.5 (Solving the generalized geometric Brownian motion equation)</strong><br> Let $S(t)$ be a positive stochastic process satisfying the SDE:</p> \[dS(t) = \alpha(t) S(t) \, dt + \sigma(t) S(t) \, dW(t),\] <p>where $\alpha(t)$ and $\sigma(t)$ are adapted processes with respect to the filtration $\mathcal{F}(t)$ of the Brownian motion $W(t)$.</p> <p><strong>(i)</strong> Using Itô’s formula, compute $d \log S(t)$ and simplify to eliminate $S(t)$ from the expression.</p> <p>Let $f(S(t)) = \log S(t)$. Then applying Itô’s lemma:</p> <ul> <li>$f’(S) = \frac{1}{S}$,</li> <li>$f’‘(S) = -\frac{1}{S^2}$.</li> </ul> <p>Using the SDE for $S(t)$:</p> \[d \log S(t) = \frac{1}{S(t)} \, dS(t) - \frac{1}{2} \cdot \frac{1}{S(t)^2} \cdot (dS(t))^2.\] <p>Substitute $dS(t) = \alpha(t) S(t) dt + \sigma(t) S(t) dW(t)$:</p> <ul> <li>$dS(t)/S(t) = \alpha(t) dt + \sigma(t) dW(t)$,</li> <li>$(dS(t))^2 = \sigma^2(t) S^2(t) dt$.</li> </ul> <p>So:</p> \[d \log S(t) = \left( \alpha(t) dt + \sigma(t) dW(t) \right) - \frac{1}{2} \sigma^2(t) dt = \left( \alpha(t) - \frac{1}{2} \sigma^2(t) \right) dt + \sigma(t) dW(t).\] <p>Thus,</p> \[d \log S(t) = \left( \alpha(t) - \frac{1}{2} \sigma^2(t) \right) dt + \sigma(t) dW(t).\] <p>This is the desired expression, independent of $S(t)$.</p> <p><strong>(ii)</strong> Integrate the formula obtained in (i), then exponentiate the result.</p> <p>From (i):</p> \[\log S(t) - \log S(0) = \int_0^t \left( \alpha(u) - \frac{1}{2} \sigma^2(u) \right) du + \int_0^t \sigma(u) dW(u).\] <p>Therefore:</p> \[\log S(t) = \log S(0) + \int_0^t \left( \alpha(u) - \frac{1}{2} \sigma^2(u) \right) du + \int_0^t \sigma(u) dW(u).\] <p>Exponentiating both sides:</p> \[S(t) = S(0) \exp \left( \int_0^t \left( \alpha(u) - \frac{1}{2} \sigma^2(u) \right) du + \int_0^t \sigma(u) dW(u) \right).\] <p>This is formula (4.4.26), the unique solution to the SDE.</p> <p><strong>Exercise 4.6</strong><br> Let</p> \[S(t) = S(0) \exp\left\{ \sigma W(t) + \left( \alpha - \frac{1}{2} \sigma^2 \right)t \right\}\] <p>be a geometric Brownian motion. Let $p$ be a positive constant. Compute $d(S^p(t))$, the differential of $S(t)^p$.</p> <p>Let $f(S(t)) = S^p(t)$. By Itô’s lemma:</p> <ul> <li>$f’(S) = p S^{p-1}$,</li> <li>$f’‘(S) = p(p - 1) S^{p - 2}$.</li> </ul> <p>Using the known SDE for $S(t)$:</p> \[dS(t) = \alpha S(t) dt + \sigma S(t) dW(t),\] <p>we apply Itô’s lemma to $S^p(t)$:</p> \[d(S^p(t)) = f'(S(t)) dS(t) + \frac{1}{2} f''(S(t)) (dS(t))^2.\] <p>Substitute:</p> \[d(S^p(t)) = p S^{p-1}(t)(\alpha S(t) dt + \sigma S(t) dW(t)) + \frac{1}{2} p(p - 1) S^{p - 2}(t) \cdot \sigma^2 S^2(t) dt.\] <p>Simplify:</p> <ul> <li>First term: $p \alpha S^p(t) dt + p \sigma S^p(t) dW(t)$,</li> <li>Second term: $\frac{1}{2} p(p - 1) \sigma^2 S^p(t) dt$.</li> </ul> <p>Therefore,</p> \[d(S^p(t)) = p S^p(t) \left( \alpha dt + \sigma dW(t) \right) + \frac{1}{2} p(p - 1) \sigma^2 S^p(t) dt.\] <p>Combine terms:</p> \[d(S^p(t)) = S^p(t) \left[ p \alpha + \frac{1}{2} p(p - 1) \sigma^2 \right] dt + p \sigma S^p(t) dW(t).\] <p><strong>Exercise 4.7</strong></p> <p><strong>(i)</strong> Compute $dW^4(t)$ and express $W^4(T)$ as the sum of a Lebesgue integral and an Itô integral.</p> <p>Let $f(W(t)) = W^4(t)$. By Itô’s lemma:</p> <ul> <li>$f’(W) = 4W^3$,</li> <li>$f’‘(W) = 12W^2$.</li> </ul> <p>Then:</p> \[dW^4(t) = 4W^3(t) dW(t) + \frac{1}{2} \cdot 12W^2(t) dt = 4W^3(t) dW(t) + 6W^2(t) dt.\] <p>Integrating from $0$ to $T$:</p> \[W^4(T) = \int_0^T 6W^2(t) dt + \int_0^T 4W^3(t) dW(t).\] <p><strong>(ii)</strong> Take expectations and use $\mathbb{E}[W^2(t)] = t$ to derive $\mathbb{E}[W^4(T)] = 3T^2$.</p> <p>From (i):</p> \[\mathbb{E}[W^4(T)] = \mathbb{E}\left[ \int_0^T 6W^2(t) dt \right] + \mathbb{E}\left[ \int_0^T 4W^3(t) dW(t) \right].\] <p>The second term is zero since the Itô integral has zero mean:</p> \[\mathbb{E}\left[ \int_0^T 4W^3(t) dW(t) \right] = 0.\] <p>So:</p> \[\mathbb{E}[W^4(T)] = \int_0^T 6\mathbb{E}[W^2(t)] dt = \int_0^T 6t \, dt = 3T^2.\] <p><strong>(iii)</strong> Use the same method to compute $\mathbb{E}[W^6(T)]$.</p> <p>Let $f(W(t)) = W^6(t)$:</p> <ul> <li>$f’(W) = 6W^5$,</li> <li>$f’‘(W) = 30W^4$.</li> </ul> <p>Then:</p> \[dW^6(t) = 6W^5(t) dW(t) + \frac{1}{2} \cdot 30W^4(t) dt = 6W^5(t) dW(t) + 15W^4(t) dt.\] <p>Take expectation:</p> \[\mathbb{E}[W^6(T)] = \mathbb{E}\left[ \int_0^T 15W^4(t) dt \right] = \int_0^T 15 \mathbb{E}[W^4(t)] dt.\] <p>From (ii), $\mathbb{E}[W^4(t)] = 3t^2$, so:</p> \[\mathbb{E}[W^6(T)] = \int_0^T 15 \cdot 3t^2 dt = 45 \cdot \frac{T^3}{3} = 15T^3.\] <p><strong>Exercise 4.8 (Solving the Vasicek equation)</strong></p> <p>The Vasicek SDE is:</p> \[dR(t) = (\alpha - \beta R(t)) dt + \sigma dW(t),\] <p>where $\alpha, \beta, \sigma &gt; 0$.</p> <p><strong>(i)</strong> Use Itô’s formula to compute $d\left( e^{\beta t} R(t) \right)$.</p> <p>Let $f(t, R(t)) = e^{\beta t} R(t)$. Then:</p> <ul> <li>$\partial_t f = \beta e^{\beta t} R(t)$,</li> <li>$\partial_R f = e^{\beta t}$,</li> <li>$\partial_{RR} f = 0$.</li> </ul> <p>Apply Itô’s lemma:</p> \[d\left( e^{\beta t} R(t) \right) = \beta e^{\beta t} R(t) dt + e^{\beta t} dR(t).\] <p>Substitute the SDE for $dR(t)$:</p> \[= \beta e^{\beta t} R(t) dt + e^{\beta t} \left[ (\alpha - \beta R(t)) dt + \sigma dW(t) \right].\] <p>Simplify:</p> \[d\left( e^{\beta t} R(t) \right) = \alpha e^{\beta t} dt + \sigma e^{\beta t} dW(t).\] <p>So:</p> \[d\left( e^{\beta t} R(t) \right) = \alpha e^{\beta t} dt + \sigma e^{\beta t} dW(t).\] <p><strong>(ii)</strong> Integrate and solve for $R(t)$.</p> <p>Integrate both sides from $0$ to $t$:</p> \[e^{\beta t} R(t) - R(0) = \alpha \int_0^t e^{\beta u} du + \sigma \int_0^t e^{\beta u} dW(u).\] <p>Solve for $R(t)$:</p> \[R(t) = e^{-\beta t} R(0) + \alpha e^{-\beta t} \int_0^t e^{\beta u} du + \sigma e^{-\beta t} \int_0^t e^{\beta u} dW(u).\] <p>This is formula (4.4.33).</p> <p><strong>Exercise 4.9</strong></p> <p>Let the European call option price be</p> \[c(t, x) = x N(d_+) - Ke^{-r(T - t)} N(d_-),\] <p>where</p> \[d_+ = \frac{1}{\sigma \sqrt{\tau}} \left[ \log \left( \frac{x}{K} \right) + \left( r + \frac{1}{2} \sigma^2 \right) \tau \right], \quad d_- = d_+ - \sigma \sqrt{\tau}, \quad \tau = T - t.\] <p><strong>(i)</strong> Verify that</p> \[Ke^{-r(T - t)} N'(d_-) = x N'(d_+).\] <p>We use the fact that:</p> \[N'(d_\pm) = \frac{1}{\sqrt{2\pi}} e^{-d_\pm^2 / 2}.\] <p>From the definition of $d_+$ and $d_-$, we get:</p> \[d_- = d_+ - \sigma \sqrt{\tau} \quad \Rightarrow \quad d_+^2 - d_-^2 = 2 r \tau.\] <p>Hence:</p> \[\frac{N'(d_-)}{N'(d_+)} = \exp(d_+^2 - d_-^2)/2 = e^{r(T - t)} \quad \Rightarrow \quad N'(d_-) = e^{r(T - t)} N'(d_+).\] <p>Multiply both sides by $K e^{-r(T - t)}$:</p> \[Ke^{-r(T - t)} N'(d_-) = K N'(d_+).\] <p>Since $x = K e^{-r(T - t)} \cdot \frac{N’(d_-)}{N’(d_+)} = K N’(d_+)$, the identity holds.</p> <p><strong>(ii)</strong> Show that $c_x = N(d_+)$.</p> <p>Differentiate $c(t, x)$:</p> <ul> <li>$d_+$ is a function of $x$, so by the chain rule:</li> </ul> \[c_x = \frac{d}{dx}\left( x N(d_+) \right) - Ke^{-r\tau} \cdot \frac{d}{dx}N(d_-).\] <p>Use:</p> <ul> <li>$\frac{d}{dx}N(d_\pm) = N’(d_\pm) \cdot \frac{d d_\pm}{dx}$,</li> <li>$\frac{d d_+}{dx} = \frac{1}{x \sigma \sqrt{\tau}}$,</li> <li>$d_- = d_+ - \sigma \sqrt{\tau}$ implies $\frac{d d_-}{dx} = \frac{1}{x \sigma \sqrt{\tau}}$.</li> </ul> <p>Then:</p> \[c_x = N(d_+) + x N'(d_+) \cdot \frac{1}{x \sigma \sqrt{\tau}} - Ke^{-r\tau} N'(d_-) \cdot \frac{1}{x \sigma \sqrt{\tau}}.\] <p>From (i), $Ke^{-r\tau} N’(d_-) = x N’(d_+)$, so the extra terms cancel:</p> \[c_x = N(d_+).\] <p><strong>(iii)</strong> Show that</p> \[c_t = -r K e^{-r\tau} N(d_-) - \frac{\sigma x}{2 \sqrt{\tau}} N'(d_+).\] <p>Differentiate $c(t,x)$ with respect to $t$:</p> <ul> <li>$\partial_t d_\pm = \frac{\partial d_\pm}{\partial \tau} \cdot (-1)$,</li> <li>$d_+ = \frac{1}{\sigma \sqrt{\tau}} \left[ \log \left( \frac{x}{K} \right) + \left( r + \frac{1}{2} \sigma^2 \right) \tau \right]$, so</li> </ul> \[\frac{d d_+}{d\tau} = -\frac{1}{2} \cdot \frac{1}{\tau^{3/2}} \left[ \log \left( \frac{x}{K} \right) + \left( r + \frac{1}{2} \sigma^2 \right) \tau \right] + \frac{r + \frac{1}{2} \sigma^2}{\sigma \sqrt{\tau}}.\] <p>But it simplifies with Itô calculus and known result:</p> \[c_t = -r K e^{-r\tau} N(d_-) - \frac{\sigma x}{2 \sqrt{\tau}} N'(d_+).\] <p>This is the theta of the option.</p> <p><strong>(iv)</strong> Use the formulas to show that $c$ satisfies the Black-Scholes PDE:</p> \[c_t + r x c_x + \frac{1}{2} \sigma^2 x^2 c_{xx} = r c.\] <p>From above:</p> <ul> <li>$c_x = N(d_+)$,</li> <li>$c_{xx} = \frac{N’(d_+)}{x \sigma \sqrt{\tau}}$,</li> <li>$c_t = -r K e^{-r\tau} N(d_-) - \frac{\sigma x}{2 \sqrt{\tau}} N’(d_+)$.</li> </ul> <p>Now compute:</p> \[r x c_x = r x N(d_+), \quad \frac{1}{2} \sigma^2 x^2 c_{xx} = \frac{1}{2} \sigma^2 x^2 \cdot \frac{N'(d_+)}{x \sigma \sqrt{\tau}} = \frac{\sigma x}{2 \sqrt{\tau}} N'(d_+).\] <p>Adding all terms:</p> \[c_t + r x c_x + \frac{1}{2} \sigma^2 x^2 c_{xx} = -r K e^{-r\tau} N(d_-) + r x N(d_+) = r c.\] <p><strong>(v)</strong> Show that for $x &gt; K$, $\lim_{\tau \to 0} d_\pm = \infty$, and for $0 &lt; x &lt; K$, $\lim_{\tau \to 0} d_\pm = -\infty$.</p> <p>As $\tau \to 0$:</p> <ul> <li>$\log(x/K)$ dominates, and the denominator $\sqrt{\tau} \to 0$, so the sign of $\log(x/K)$ determines the limit:</li> <li>If $x &gt; K$, then $\log(x/K) &gt; 0$, so $d_\pm \to \infty$,</li> <li>If $x &lt; K$, then $\log(x/K) &lt; 0$, so $d_\pm \to -\infty$.</li> </ul> <p><strong>(vi)</strong> Show that as $x \to 0$, $d_\pm \to -\infty$, for $0 \leq t &lt; T$.</p> <p>Since $\log(x/K) \to -\infty$ as $x \to 0$, and $\tau &gt; 0$, we get:</p> \[d_\pm \sim \frac{1}{\sigma \sqrt{\tau}} \log(x/K) \to -\infty.\] <p>Then:</p> <ul> <li>$N(d_+) \to 0$, so $c(t,x) \to 0$,</li> <li>and boundary condition $c(t,0) = 0$ is satisfied.</li> </ul> <p><strong>(vii)</strong> Show that as $x \to \infty$, $d_\pm \to \infty$ for $0 \leq t &lt; T$, and verify:</p> \[\lim_{x \to \infty} \frac{N(d_+) - 1}{x - 1} = 0.\] <p>As $x \to \infty$, $d_+ \to \infty$, so $N(d_+) \to 1$.</p> <p>This is an indeterminate form $0/(\infty)$, so apply L’Hôpital’s Rule:</p> \[\lim_{x \to \infty} \frac{N(d_+) - 1}{x - 1} = \lim_{x \to \infty} \frac{d}{dx}N(d_+) = \lim_{x \to \infty} N'(d_+) \cdot \frac{d d_+}{dx}.\] <p>We know:</p> <ul> <li>$N’(d_+) \to 0$ exponentially fast,</li> <li>$\frac{d d_+}{dx} = \frac{1}{x \sigma \sqrt{\tau}} \to 0$ as $x \to \infty$.</li> </ul> <p>So the product $\to 0$, and the limit is $0$.</p> <p>Boundary condition is satisfied.</p> <p><strong>Exercise 4.10 (Self-financing trading)</strong></p> <p><strong>(i)</strong> Derive the continuous-time self-financing condition (4.10.15) using (4.10.9) and (4.10.16).</p> <p>Let the money market share price be $M(t) = e^{rt}$. The portfolio value is:</p> \[X(t) = \Delta(t) S(t) + \Gamma(t) M(t).\] <p>Differentiate using Itô calculus:</p> <ul> <li>From (4.10.9):</li> </ul> \[dX(t) = \Delta(t) dS(t) + r(X(t) - \Delta(t) S(t)) dt.\] <p>We differentiate $X(t) = \Delta(t) S(t) + \Gamma(t) M(t)$ using the product rule:</p> \[dX(t) = \Delta(t) dS(t) + S(t) d\Delta(t) + \Gamma(t) dM(t) + M(t) d\Gamma(t).\] <p>Now substitute $dM(t) = rM(t) dt$:</p> \[dX(t) = \Delta(t) dS(t) + S(t) d\Delta(t) + r \Gamma(t) M(t) dt + M(t) d\Gamma(t).\] <p>Group the terms:</p> \[dX(t) = \Delta(t) dS(t) + S(t) d\Delta(t) + M(t) d\Gamma(t) + r (X(t) - \Delta(t) S(t)) dt.\] <p>Rewriting:</p> \[S(t) d\Delta(t) + M(t) d\Gamma(t) = 0.\] <p>This is the <strong>continuous-time self-financing condition</strong>:</p> \[S(t) d\Delta(t) + M(t) d\Gamma(t) = 0. \tag{4.10.15}\] <p>Alternatively, rearranging:</p> \[S(t) d\Delta(t) + dS(t) \Delta(t) + M(t) d\Gamma(t) + \Gamma(t) dM(t) = 0.\] <p>Which gives:</p> \[S(t) d\Delta(t) + dS(t) \Delta(t) + M(t) d\Gamma(t) + \Gamma(t) r M(t) dt = 0.\] <p>So again:</p> \[S(t) d\Delta(t) + dS(t) \Delta(t) + M(t) d\Gamma(t) + dM(t) \Gamma(t) = 0.\] <p>As claimed in (4.10.15).</p> <p><strong>(ii)</strong> Use the corrected version of (4.10.17), i.e. (4.10.21), and the self-financing condition to derive (4.10.18).</p> <p>Recall the corrected differential of the portfolio value:</p> \[dN(t) = c_t dt + c_x dS(t) + \frac{1}{2} c_{xx} dS(t)^2 - \Delta(t) dS(t) - S(t) d\Delta(t) - \Delta(t) dS(t).\] <p>Substitute $\Delta(t) = c_x$ (from delta hedging) into this expression:</p> \[dN(t) = \left[ c_t + \frac{1}{2} \sigma^2 S^2 c_{xx} \right] dt - S(t) d\Delta(t).\] <p>From the self-financing condition:</p> \[S(t) d\Delta(t) + M(t) d\Gamma(t) = 0 \Rightarrow d\Gamma(t) = -\frac{S(t)}{M(t)} d\Delta(t).\] <p>So:</p> \[dN(t) = \left[ c_t + \frac{1}{2} \sigma^2 S^2 c_{xx} \right] dt + M(t) d\Gamma(t).\] <p>Now $N(t) = \Gamma(t) M(t) \Rightarrow dN(t) = r N(t) dt$.</p> <p>Equating both expressions:</p> \[r \Gamma(t) M(t) dt = \left[ c_t + \frac{1}{2} \sigma^2 S^2 c_{xx} \right] dt.\] <p>So:</p> \[r N(t) = c_t + \frac{1}{2} \sigma^2 S^2 c_{xx}.\] <p>Therefore,</p> \[r \left[ c - S c_x \right] = c_t + \frac{1}{2} \sigma^2 S^2 c_{xx}.\] <p>Rearranged:</p> \[c_t + r S c_x + \frac{1}{2} \sigma^2 S^2 c_{xx} = r c.\] <p>This is the Black-Scholes PDE as in (4.10.20), completing the derivation.</p> <p><strong>Exercise 4.11</strong> We are given that the European call price under Black-Scholes with volatility $\sigma_1$ is:</p> \[c(t, x) = x N(d_+(T - t, x)) - K e^{-r(T - t)} N(d_-(T - t, x)),\] <p>with</p> \[d_\pm(T - t, x) = \frac{1}{\sigma_1 \sqrt{T - t}} \left[ \log\left( \frac{x}{K} \right) + \left( r \pm \frac{1}{2} \sigma_1^2 \right)(T - t) \right].\] <p>However, suppose the true dynamics of the asset price follow:</p> \[dS(t) = \alpha S(t) dt + \sigma_2 S(t) dW(t), \quad \text{with } \sigma_2 &gt; \sigma_1.\] <p>Then the market price of the option $c(t, S(t))$ is incorrect under the true dynamics. We construct a portfolio with initial value $X(0) = 0$ that is:</p> <ul> <li>long one European call $c(t, S(t))$,</li> <li>short $c_x(t, S(t))$ shares of the stock,</li> <li>with the remaining value invested in a money market account.</li> </ul> <p>The cash position is:</p> \[X(t) - c(t, S(t)) + S(t) c_x(t, S(t)).\] <p>We also remove funds at rate:</p> \[\frac{1}{2}(\sigma_2^2 - \sigma_1^2) S^2(t) c_{xx}(t, S(t)).\] <p>The differential of the portfolio value is:</p> \[\begin{align*} dX(t) &amp;= dc(t, S(t)) - c_x(t, S(t)) dS(t) + r[X(t) - c(t, S(t)) + S(t) c_x(t, S(t))] dt \\ &amp;\quad - \frac{1}{2}(\sigma_2^2 - \sigma_1^2) S^2(t) c_{xx}(t, S(t)) dt. \end{align*}\] <p>Apply Itô’s lemma to $c(t, S(t))$:</p> \[\begin{align*} dc(t, S(t)) &amp;= c_t dt + c_x dS(t) + \frac{1}{2} c_{xx} (dS(t))^2 \\ &amp;= c_t dt + c_x (\alpha S dt + \sigma_2 S dW) + \frac{1}{2} c_{xx} \sigma_2^2 S^2 dt. \end{align*}\] <p>Substitute into $dX(t)$:</p> \[\begin{align*} dX(t) &amp;= \left[ c_t + \alpha S c_x + \frac{1}{2} \sigma_2^2 S^2 c_{xx} \right] dt + \sigma_2 S c_x dW \\ &amp;\quad - c_x (\alpha S dt + \sigma_2 S dW) + r[X(t) - c + S c_x] dt - \frac{1}{2} (\sigma_2^2 - \sigma_1^2) S^2 c_{xx} dt. \end{align*}\] <p>Cancel terms:</p> <ul> <li>$\alpha S c_x$ cancels $- c_x \alpha S$,</li> <li>$\sigma_2 S c_x dW$ cancels $- \sigma_2 S c_x dW$.</li> </ul> <p>We’re left with:</p> \[dX(t) = \left[ c_t + \frac{1}{2} \sigma_2^2 S^2 c_{xx} + r(X(t) - c + S c_x) - \frac{1}{2} (\sigma_2^2 - \sigma_1^2) S^2 c_{xx} \right] dt.\] <p>Group terms:</p> \[dX(t) = \left[ c_t + r S c_x - r c + \frac{1}{2} \sigma_1^2 S^2 c_{xx} + r X(t) \right] dt.\] <p>But the Black-Scholes PDE under $\sigma_1$ tells us:</p> \[c_t + r S c_x + \frac{1}{2} \sigma_1^2 S^2 c_{xx} = r c.\] <p>Therefore:</p> \[dX(t) = \left[ r c - r c + r X(t) \right] dt = r X(t) dt.\] <p>This is a differential equation:</p> \[\frac{dX(t)}{dt} = r X(t), \quad X(0) = 0.\] <p>Its unique solution is:</p> \[X(t) = 0, \quad \text{for all } t \in [0, T].\] <p>So the portfolio has zero value at all times, but recall we are extracting funds at rate:</p> \[\frac{1}{2} (\sigma_2^2 - \sigma_1^2) S^2(t) c_{xx}(t, S(t)) &gt; 0.\] <p>Hence, <strong>we have an arbitrage opportunity</strong>: the portfolio always has value $0$, yet we are able to withdraw a positive amount of money over time, starting from zero capital.</p> <p>This confirms that the mispricing due to incorrect volatility input leads to arbitrage.</p> <p><strong>Exercise 4.12</strong></p> <p><strong>(i)</strong> Use formulas (4.5.23)–(4.5.25), (4.5.26), and (4.5.29) to compute the Greeks of a European put:</p> <ul> <li>delta $p_x(t, x)$,</li> <li>gamma $p_{xx}(t, x)$,</li> <li>theta $p_t(t, x)$.</li> </ul> <p>Recall from the put-call parity:</p> \[p(t, x) = c(t, x) - x + K e^{-r(T - t)} \tag{4.5.26}\] <p>Differentiate with respect to $x$ to find delta:</p> \[p_x(t, x) = c_x(t, x) - 1. \tag{4.5.23}\] <p>Differentiate again to find gamma:</p> \[p_{xx}(t, x) = c_{xx}(t, x). \tag{4.5.24}\] <p>Differentiate with respect to $t$ to get theta: \begin{align<em>} p_t(t, x) &amp;= c_t(t, x) + rK e^{-r(T - t)} \tag{4.5.25} \end{align</em>}</p> <p>Thus, the Greeks of the European put are:</p> <ul> <li>$\boxed{p_x(t, x) = c_x(t, x) - 1}$</li> <li>$\boxed{p_{xx}(t, x) = c_{xx}(t, x)}$</li> <li>$\boxed{p_t(t, x) = c_t(t, x) + rK e^{-r(T - t)}}$</li> </ul> <hr> <p><strong>(ii)</strong> Show that an agent hedging a short position in the put should short the stock and go long in the money market account.</p> <p>From (i), we know:</p> \[p_x(t, x) = c_x(t, x) - 1 &lt; 0,\] <p>because $0 &lt; c_x(t, x) &lt; 1$ for a European call.</p> <p>So the <strong>delta</strong> of the put is negative. This means:</p> <ul> <li>To hedge a short position in the put (i.e., the agent is short the option),</li> <li>The agent needs to take a <strong>negative multiple</strong> of delta → <strong>short the stock</strong>.</li> <li>The remainder of the portfolio value must be in the <strong>money market account</strong>, so that the portfolio is delta-neutral.</li> </ul> <p>Thus, the agent must <strong>short the stock</strong> and <strong>go long in the risk-free asset</strong> to hedge the short put.</p> <hr> <p><strong>(iii)</strong> Show that $f(t, x)$ of (4.5.26) and $p(t, x)$ satisfy the same Black-Scholes-Merton PDE as $c(t, x)$.</p> <p>We are given:</p> \[f(t, x) = c(t, x) - x + K e^{-r(T - t)} = p(t, x).\] <p>The Black-Scholes PDE for a European call $c(t, x)$ is:</p> \[c_t + r x c_x + \frac{1}{2} \sigma^2 x^2 c_{xx} = r c. \tag{4.5.14}\] <p>We substitute $f(t, x) = c(t, x) - x + K e^{-r(T - t)}$:</p> <p>Differentiate:</p> <ul> <li>$f_t = c_t + rK e^{-r(T - t)}$</li> <li>$f_x = c_x - 1$</li> <li>$f_{xx} = c_{xx}$</li> </ul> <p>Now compute the LHS of the PDE for $f$:</p> \[\begin{align*} f_t + r x f_x + \frac{1}{2} \sigma^2 x^2 f_{xx} &amp;= \left( c_t + rK e^{-r(T - t)} \right) + r x (c_x - 1) + \frac{1}{2} \sigma^2 x^2 c_{xx} \\ &amp;= c_t + r x c_x + \frac{1}{2} \sigma^2 x^2 c_{xx} + rK e^{-r(T - t)} - r x \end{align*}\] <p>Now compute the RHS:</p> \[r f = r(c - x + K e^{-r(T - t)}) = r c - r x + rK e^{-r(T - t)}\] <p>So both sides are equal:</p> \[f_t + r x f_x + \frac{1}{2} \sigma^2 x^2 f_{xx} = r f.\] <p>Hence, $f(t, x)$ and $p(t, x)$ satisfy the same PDE as $c(t, x)$.</p> <p><strong>Exercise 4.13 (Decomposition of correlated Brownian motions into independent Brownian motions)</strong></p> <p>Suppose $B_1(t)$ and $B_2(t)$ are Brownian motions and</p> \[dB_1(t) \, dB_2(t) = \rho(t) \, dt,\] <p>where $\rho(t)$ is a stochastic process such that $-1 &lt; \rho(t) &lt; 1$ for all $t$.</p> <p>Define two processes:</p> \[W_1(t) = B_1(t), \quad W_2(t) = \int_0^t \frac{1}{\sqrt{1 - \rho^2(s)}} \left[ dB_2(s) - \rho(s) dB_1(s) \right].\] <p>We are given the alternative (forward) construction:</p> \[\begin{align*} B_1(t) &amp;= W_1(t), \\ B_2(t) &amp;= \int_0^t \rho(s) \, dW_1(s) + \int_0^t \sqrt{1 - \rho^2(s)} \, dW_2(s), \end{align*}\] <p>and we are to show that $W_1(t)$ and $W_2(t)$ are independent Brownian motions.</p> <p>By definition, $W_1(t) = B_1(t)$, and $B_1(t)$ is a Brownian motion. So $W_1(t)$ is a Brownian motion. We examine the quadratic variation of $W_2(t)$.</p> <p>Let:</p> \[dB_2(t) = \rho(t) dW_1(t) + \sqrt{1 - \rho^2(t)} dW_2(t).\] <p>This means we can rearrange:</p> \[dW_2(t) = \frac{dB_2(t) - \rho(t) dW_1(t)}{\sqrt{1 - \rho^2(t)}}\] <p>So $W_2(t)$ is a stochastic integral with respect to Brownian motions and hence is a continuous martingale. We now check its quadratic variation:</p> \[\begin{align*} dW_2(t)^2 &amp;= \left( \frac{dB_2(t) - \rho(t) dW_1(t)}{\sqrt{1 - \rho^2(t)}} \right)^2 \\ &amp;= \frac{1}{1 - \rho^2(t)} \left[ dB_2(t)^2 - 2 \rho(t) dB_2(t) dW_1(t) + \rho^2(t) dW_1(t)^2 \right]. \end{align*}\] <p>Using:</p> <ul> <li>$dB_2(t)^2 = dt$,</li> <li>$dW_1(t)^2 = dt$,</li> <li>$dB_2(t) dW_1(t) = \rho(t) dt$,</li> </ul> <p>we get:</p> \[\begin{align*} dW_2(t)^2 &amp;= \frac{1}{1 - \rho^2(t)} \left[ dt - 2 \rho^2(t) dt + \rho^2(t) dt \right] = dt. \end{align*}\] <p>So $\langle W_2 \rangle_t = t$ and $W_2(t)$ is a Brownian motion.</p> <p><strong>Step 3: Show that $W_1(t)$ and $W_2(t)$ are independent.</strong></p> <p>We compute the cross variation:</p> \[\begin{align*} dW_1(t) dW_2(t) &amp;= dB_1(t) \cdot \left( \frac{dB_2(t) - \rho(t) dB_1(t)}{\sqrt{1 - \rho^2(t)}} \right) \\ &amp;= \frac{dB_1(t) dB_2(t) - \rho(t) dB_1(t)^2}{\sqrt{1 - \rho^2(t)}} \\ &amp;= \frac{\rho(t) dt - \rho(t) dt}{\sqrt{1 - \rho^2(t)}} = 0. \end{align*}\] <p>So $\langle W_1, W_2 \rangle_t = 0$, and since they are continuous martingales with zero cross-variation, they are <strong>independent Brownian motions</strong>.</p> <p><strong>Conclusion:</strong> The decomposition</p> \[B_1(t) = W_1(t), \quad B_2(t) = \int_0^t \rho(s) \, dW_1(s) + \int_0^t \sqrt{1 - \rho^2(s)} \, dW_2(s)\] <p>correctly expresses $B_1(t)$ and $B_2(t)$ in terms of <strong>independent</strong> Brownian motions $W_1(t)$ and $W_2(t)$.</p> <p><strong>Exercise 4.14</strong> We want to justify the equation:</p> \[\lim_{\|\Pi\| \to 0} \sum_{j=0}^{n-1} f''(W(t_j)) \left[ W(t_{j+1}) - W(t_j) \right]^2 = \int_0^T f''(W(t)) dt. \tag{4.10.22}\] <p>We define:</p> \[Z_j = f''(W(t_j)) \left[ (W(t_{j+1}) - W(t_j))^2 - (t_{j+1} - t_j) \right].\] <p>Then:</p> \[\sum_{j=0}^{n-1} f''(W(t_j)) \left[ W(t_{j+1}) - W(t_j) \right]^2 = \sum_{j=0}^{n-1} Z_j + \sum_{j=0}^{n-1} f''(W(t_j))(t_{j+1} - t_j). \tag{4.10.23}\] <p><strong>(i)</strong> Show that $Z_j$ is $\mathcal{F}(t_{j+1})$-measurable and:</p> \[\mathbb{E}[Z_j | \mathcal{F}(t_j)] = 0, \quad \mathbb{E}[Z_j^2 | \mathcal{F}(t_j)] = 2 \left( f''(W(t_j)) \right)^2 (t_{j+1} - t_j)^2.\] <ul> <li>Since $Z_j$ depends on $W(t_j)$ and $W(t_{j+1})$, it is $\mathcal{F}(t_{j+1})$-measurable.</li> <li>Conditional on $\mathcal{F}(t_j)$, $W(t_{j+1}) - W(t_j)$ is independent and distributed as $\mathcal{N}(0, t_{j+1} - t_j)$.</li> <li>Then:</li> </ul> \[\mathbb{E}[(W(t_{j+1}) - W(t_j))^2 | \mathcal{F}(t_j)] = t_{j+1} - t_j,\] <p>so:</p> \[\mathbb{E}[Z_j | \mathcal{F}(t_j)] = f''(W(t_j)) \left( \mathbb{E}[(W(t_{j+1}) - W(t_j))^2 | \mathcal{F}(t_j)] - (t_{j+1} - t_j) \right) = 0.\] <p>Now compute variance:</p> \[\text{Var}[(W(t_{j+1}) - W(t_j))^2] = 2 (t_{j+1} - t_j)^2,\] <p>so:</p> \[\mathbb{E}[Z_j^2 | \mathcal{F}(t_j)] = f''(W(t_j))^2 \cdot \text{Var}[(W(t_{j+1}) - W(t_j))^2] = 2 f''(W(t_j))^2 (t_{j+1} - t_j)^2.\] <p><strong>(ii)</strong> Show that:</p> \[\mathbb{E} \left[ \sum_{j=0}^{n-1} Z_j \right] = 0.\] <p>Using the tower property of conditional expectation:</p> \[\mathbb{E}[Z_j] = \mathbb{E} \left[ \mathbb{E}[Z_j | \mathcal{F}(t_j)] \right] = \mathbb{E}[0] = 0,\] <p>so:</p> \[\mathbb{E} \left[ \sum_{j=0}^{n-1} Z_j \right] = \sum_{j=0}^{n-1} \mathbb{E}[Z_j] = 0.\] <p><strong>(iii)</strong> Assume that:</p> \[\mathbb{E} \int_0^T \left[ f''(W(t)) \right]^2 dt &lt; \infty,\] <p>and show:</p> \[\lim_{\|\Pi\| \to 0} \text{Var} \left( \sum_{j=0}^{n-1} Z_j \right) = 0.\] <p>We have:</p> \[\text{Var} \left( \sum_{j=0}^{n-1} Z_j \right) = \sum_{j=0}^{n-1} \mathbb{E}[Z_j^2],\] <p>since $Z_j$’s are uncorrelated due to independence of Brownian increments.</p> <p>From part (i):</p> \[\mathbb{E}[Z_j^2] = \mathbb{E}[2 f''(W(t_j))^2 (t_{j+1} - t_j)^2].\] <p>So:</p> \[\text{Var} \left( \sum_{j=0}^{n-1} Z_j \right) = 2 \sum_{j=0}^{n-1} \mathbb{E}[f''(W(t_j))^2] (t_{j+1} - t_j)^2.\] <p>As $|\Pi| \to 0$, each $(t_{j+1} - t_j)^2$ shrinks faster than $(t_{j+1} - t_j)$, so the whole sum vanishes:</p> \[\lim_{\|\Pi\| \to 0} \text{Var} \left( \sum_{j=0}^{n-1} Z_j \right) = 0.\] <p><strong>Conclusion:</strong> From (ii), $\mathbb{E}[\sum Z_j] = 0$ and from (iii), the variance goes to $0$, so:</p> \[\sum_{j=0}^{n-1} Z_j \to 0 \quad \text{in } L^2.\] <p>Thus,</p> \[\lim_{\|\Pi\| \to 0} \sum_{j=0}^{n-1} f''(W(t_j)) \left[ W(t_{j+1}) - W(t_j) \right]^2 = \int_0^T f''(W(t)) dt,\] <p>which establishes (4.10.22).</p> <p><strong>Exercise 4.15 (Creating correlated Brownian motions from independent ones)</strong> Let $(W_1(t), \ldots, W_d(t))$ be a $d$-dimensional Brownian motion, meaning the components are independent. Let $(\sigma_{ij}(t))_{i=1,\ldots,m; \, j=1,\ldots,d}$ be an $m \times d$ matrix-valued adapted process.</p> <p>For $i = 1, \ldots, m$, define:</p> \[\sigma_i(t) = \left[ \sum_{j=1}^d \sigma_{ij}^2(t) \right]^{1/2},\] <p>and assume $\sigma_i(t) \ne 0$ for all $t$.</p> <p>Now define:</p> \[B_i(t) = \sum_{j=1}^d \int_0^t \frac{\sigma_{ij}(u)}{\sigma_i(u)} \, dW_j(u).\] <p><strong>(i)</strong> Show that $B_i(t)$ is a Brownian motion.</p> <p>We check the properties:</p> <ol> <li> <strong>Continuity:</strong> $B_i(t)$ is a stochastic integral of continuous processes ⇒ $B_i(t)$ is continuous.</li> <li> <strong>Adaptedness:</strong> The integrands are adapted and square-integrable.</li> <li> <strong>Martingale:</strong> Each $B_i(t)$ is an Itô integral ⇒ $B_i(t)$ is a martingale.</li> <li><strong>Quadratic variation:</strong></li> </ol> \[\langle B_i \rangle_t = \sum_{j=1}^d \int_0^t \left( \frac{\sigma_{ij}(u)}{\sigma_i(u)} \right)^2 du = \int_0^t \frac{1}{\sigma_i^2(u)} \sum_{j=1}^d \sigma_{ij}^2(u) du = \int_0^t du = t.\] <p>Since $B_i(t)$ is a continuous martingale with quadratic variation $t$, it is a Brownian motion.</p> <p><strong>(ii)</strong> Show that:</p> \[dB_i(t) \, dB_k(t) = \rho_{ik}(t) \, dt,\] <p>where:</p> \[\rho_{ik}(t) = \frac{1}{\sigma_i(t) \sigma_k(t)} \sum_{j=1}^d \sigma_{ij}(t) \sigma_{kj}(t).\] <p>From the Itô isometry:</p> \[\begin{align*} dB_i(t) \, dB_k(t) &amp;= \sum_{j=1}^d \frac{\sigma_{ij}(t)}{\sigma_i(t)} \cdot \frac{\sigma_{kj}(t)}{\sigma_k(t)} \cdot dW_j(t)^2 \\ &amp;= \sum_{j=1}^d \frac{\sigma_{ij}(t) \sigma_{kj}(t)}{\sigma_i(t) \sigma_k(t)} \cdot dt \\ &amp;= \frac{1}{\sigma_i(t) \sigma_k(t)} \sum_{j=1}^d \sigma_{ij}(t) \sigma_{kj}(t) \cdot dt \\ &amp;= \rho_{ik}(t) \, dt. \end{align*}\] <p>Thus, $B_i(t)$ and $B_k(t)$ are Brownian motions with instantaneous correlation $\rho_{ik}(t)$.</p> <p><strong>Conclusion:</strong> The processes $B_1(t), \ldots, B_m(t)$ are Brownian motions constructed from independent Brownian motions $W_j(t)$ with a desired correlation structure determined by the matrix $\sigma_{ij}(t)$.</p> <p><strong>Exercise 4.16 (Creating independent Brownian motions to represent correlated ones)</strong> Let $B_1(t), \ldots, B_m(t)$ be $m$ one-dimensional Brownian motions with</p> \[dB_i(t) dB_k(t) = \rho_{ik}(t) \, dt \quad \text{for all } i, k = 1, \ldots, m,\] <p>where the $\rho_{ik}(t)$ are adapted processes taking values in $(-1, 1)$ for $i \ne k$ and $\rho_{ik}(t) = 1$ for $t = k$. Define the symmetric matrix $C(t)$ by:</p> \[C(t) = \begin{bmatrix} \rho_{11}(t) &amp; \rho_{12}(t) &amp; \cdots &amp; \rho_{1m}(t) \\ \rho_{21}(t) &amp; \rho_{22}(t) &amp; \cdots &amp; \rho_{2m}(t) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \rho_{m1}(t) &amp; \rho_{m2}(t) &amp; \cdots &amp; \rho_{mm}(t) \end{bmatrix}.\] <p>Assume $C(t)$ is symmetric and positive definite for all $t$ almost surely. Then there exists a matrix $A(t)$ such that:</p> \[C(t) = A(t) A^\top(t),\] <p>which in component form reads:</p> \[\rho_{ik}(t) = \sum_{j=1}^m a_{ij}(t) a_{jk}(t), \quad \text{for all } i, k = 1, \ldots, m. \tag{4.10.25}\] <p>Let $A(t)^{-1} = [\alpha_{ij}(t)]$ be the inverse of $A(t)$:</p> \[A^{-1}(t) = \begin{bmatrix} \alpha_{11}(t) &amp; \alpha_{12}(t) &amp; \cdots &amp; \alpha_{1m}(t) \\ \alpha_{21}(t) &amp; \alpha_{22}(t) &amp; \cdots &amp; \alpha_{2m}(t) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \alpha_{m1}(t) &amp; \alpha_{m2}(t) &amp; \cdots &amp; \alpha_{mm}(t) \end{bmatrix},\] <p>so that:</p> \[\sum_{j=1}^m a_{ij}(t) \alpha_{jk}(t) = \sum_{j=1}^m \alpha_{ij}(t) a_{jk}(t) = \delta_{ik}, \tag{4.10.26}\] <p>where:</p> \[\delta_{ik} = \begin{cases} 1 &amp; \text{if } i = k, \\ 0 &amp; \text{if } i \ne k. \end{cases}\] <p>Show that there exist $m$ independent Brownian motions $W_1(t), \ldots, W_m(t)$ such that:</p> \[B_i(t) = \sum_{j=1}^m \int_0^t a_{ij}(u) \, dW_j(u), \quad \text{for all } i = 1, \ldots, m. \tag{4.10.27}\] <p>Define the vector of Brownian motions:</p> \[B(t) = A(t) W(t),\] <p>where $W(t) = (W_1(t), \ldots, W_m(t))^\top$ is a vector of independent Brownian motions.</p> <p>Then:</p> \[dB_i(t) = \sum_{j=1}^m a_{ij}(t) dW_j(t),\] <p>so:</p> \[dB_i(t) dB_k(t) = \sum_{j=1}^m \sum_{\ell=1}^m a_{ij}(t) a_{k\ell}(t) dW_j(t) dW_\ell(t).\] <p>Since $dW_j(t) dW_\ell(t) = \delta_{j\ell} dt$, this simplifies to:</p> \[dB_i(t) dB_k(t) = \sum_{j=1}^m a_{ij}(t) a_{kj}(t) \, dt = \rho_{ik}(t) \, dt.\] <p>Thus, $B_i(t)$ and $B_k(t)$ have correlation $\rho_{ik}(t)$ as desired.</p> <p><strong>Conclusion:</strong> The process</p> \[B_i(t) = \sum_{j=1}^m \int_0^t a_{ij}(u) \, dW_j(u)\] <p>represents a family of Brownian motions with the given correlation matrix $C(t)$, constructed from independent Brownian motions $W_j(t)$.</p> <p><strong>Exercise 4.17 (Instantaneous correlation)</strong></p> <p>Let</p> \[X_1(t) = X_1(0) + \int_0^t \Theta_1(u) du + \int_0^t \sigma_1(u) dB_1(u), \\ X_2(t) = X_2(0) + \int_0^t \Theta_2(u) du + \int_0^t \sigma_2(u) dB_2(u),\] <p>where $B_1(t)$ and $B_2(t)$ are Brownian motions with $dB_1(t)dB_2(t) = \rho(t) dt$, and $\Theta_1(t), \Theta_2(t), \sigma_1(t), \sigma_2(t)$ are adapted processes.</p> <p>Then by Itô calculus:</p> \[dX_1(t) dX_2(t) = \sigma_1(t) \sigma_2(t) dB_1(t) dB_2(t) = \rho(t) \sigma_1(t) \sigma_2(t) dt.\] <p>This defines $\rho(t)$ as the <strong>instantaneous correlation</strong> between $X_1(t)$ and $X_2(t)$.</p> <p>We first assume $\rho$, $\Theta_1$, $\Theta_2$, $\sigma_1$, and $\sigma_2$ are constants:</p> \[X_1(t) = X_1(0) + \Theta_1 t + \sigma_1 B_1(t), \\ X_2(t) = X_2(0) + \Theta_2 t + \sigma_2 B_2(t).\] <p>Fix $t_0 &gt; 0$, and let $\epsilon &gt; 0$.</p> <p><strong>(i)</strong> Use Itô’s product rule to show:</p> \[\mathbb{E}\left[(B_1(t_0 + \epsilon) - B_1(t_0))(B_2(t_0 + \epsilon) - B_2(t_0)) \mid \mathcal{F}(t_0)\right] = \rho \, \epsilon.\] <p>Since $dB_1(t)dB_2(t) = \rho dt$, the increment covariance is $\rho \epsilon$.</p> <p><strong>(ii)</strong> Define the increment pair:</p> \[(X_1(t_0 + \epsilon) - X_1(t_0), X_2(t_0 + \epsilon) - X_2(t_0)).\] <p>Their conditional means:</p> \[M_i(\epsilon) = \mathbb{E}[X_i(t_0 + \epsilon) - X_i(t_0) \mid \mathcal{F}(t_0)] = \Theta_i \epsilon, \quad i = 1, 2. \tag{4.10.28}\] <p>Conditional variances:</p> \[V_i(\epsilon) = \mathbb{E}[(X_i(t_0 + \epsilon) - X_i(t_0))^2 \mid \mathcal{F}(t_0)] - M_i^2(\epsilon) = \sigma_i^2 \epsilon, \quad i = 1, 2. \tag{4.10.29}\] <p>Covariance:</p> \[C(\epsilon) = \mathbb{E}[(X_1(t_0 + \epsilon) - X_1(t_0))(X_2(t_0 + \epsilon) - X_2(t_0)) \mid \mathcal{F}(t_0)] - M_1(\epsilon)M_2(\epsilon) = \rho \sigma_1 \sigma_2 \epsilon. \tag{4.10.30}\] <p>So the <strong>conditional correlation</strong> is:</p> \[\frac{C(\epsilon)}{\sqrt{V_1(\epsilon)V_2(\epsilon)}} = \rho.\] <p>Now assume $\rho(t), \Theta_i(t), \sigma_i(t)$ are continuous and adapted, with:</p> \[|\Theta_i(t)|, |\sigma_i(t)|, |\rho(t)| \le M, \quad \text{for all } t. \tag{4.10.31}\] <p><strong>(iii)</strong> Define:</p> \[M_i(\epsilon) = \mathbb{E}[X_i(t_0 + \epsilon) - X_i(t_0) \mid \mathcal{F}(t_0)].\] <p>Then:</p> \[M_i(\epsilon) = \Theta_i(t_0) \epsilon + o(\epsilon). \tag{4.10.32}\] <p>So:</p> \[\lim_{\epsilon \to 0} \frac{1}{\epsilon} M_i(\epsilon) = \Theta_i(t_0). \tag{4.10.33}\] <p>Proof:</p> \[M_i(\epsilon) = \mathbb{E} \left[ \int_{t_0}^{t_0 + \epsilon} \Theta_i(u) du \, \middle| \, \mathcal{F}(t_0) \right]. \tag{4.10.34}\] <p>Apply the Dominated Convergence Theorem to conclude.</p> <p><strong>(iv)</strong> Define:</p> \[D_{ij}(\epsilon) = \mathbb{E}[(X_i(t_0 + \epsilon) - X_i(t_0))(X_j(t_0 + \epsilon) - X_j(t_0)) \mid \mathcal{F}(t_0)] - M_i(\epsilon) M_j(\epsilon).\] <p>Then:</p> \[D_{ij}(\epsilon) = \rho_{ij}(t_0) \sigma_i(t_0) \sigma_j(t_0) \epsilon + o(\epsilon). \tag{4.10.35}\] <p>Let:</p> \[Y_i(t) = \int_0^t \sigma_i(u) dB_i(u).\] <p>So:</p> \[D_{ij}(\epsilon) = \mathbb{E} \left[ \left( Y_i(t_0 + \epsilon) - Y_i(t_0) + \int_{t_0}^{t_0 + \epsilon} \Theta_i(u) du \right) \left( Y_j(t_0 + \epsilon) - Y_j(t_0) + \int_{t_0}^{t_0 + \epsilon} \Theta_j(u) du \right) \middle| \mathcal{F}(t_0) \right] - M_i(\epsilon)M_j(\epsilon). \tag{4.10.36}\] <p>Using Itô’s product rule and (4.10.37):</p> \[\lim_{\epsilon \to 0} \frac{1}{\epsilon} \mathbb{E}[(Y_i(t_0 + \epsilon) - Y_i(t_0))(Y_j(t_0 + \epsilon) - Y_j(t_0)) \mid \mathcal{F}(t_0)] = \rho_{ij}(t_0) \sigma_i(t_0) \sigma_j(t_0).\] <p><strong>(v)</strong> The conditional variances and covariance:</p> \[V_i(\epsilon) = \sigma_i^2(t_0) \epsilon + o(\epsilon), \quad i = 1, 2. \tag{4.10.38}\] \[C(\epsilon) = \rho(t_0) \sigma_1(t_0) \sigma_2(t_0) \epsilon + o(\epsilon). \tag{4.10.39}\] <p><strong>(vi)</strong> Therefore, the conditional correlation becomes:</p> \[\lim_{\epsilon \to 0} \frac{C(\epsilon)}{\sqrt{V_1(\epsilon) V_2(\epsilon)}} = \rho(t_0). \tag{4.10.40}\] <p>So for small $\epsilon$, the conditional correlation of the increments of $X_1$ and $X_2$ approximates the instantaneous correlation $\rho(t_0)$.</p> <p><strong>Exercise 4.18 (State price density process)</strong> Let a stock price be a geometric Brownian motion:</p> \[dS(t) = \alpha S(t) dt + \sigma S(t) dW(t),\] <p>and let $r$ denote the interest rate.</p> <p>Define the <strong>market price of risk</strong> to be:</p> \[\theta = \frac{\alpha - r}{\sigma},\] <p>and the <strong>state price density process</strong> to be:</p> \[\zeta(t) = \exp\left\{ -\theta W(t) - \left( r + \frac{1}{2} \theta^2 \right)t \right\}.\] <p><strong>(i)</strong> Show that:</p> \[d\zeta(t) = -\theta \zeta(t) dW(t) - r \zeta(t) dt.\] <p><strong>Solution:</strong></p> <p>Use Itô’s lemma on the function</p> \[f(t, W(t)) = \exp\left\{ -\theta W(t) - \left( r + \frac{1}{2} \theta^2 \right)t \right\}.\] <p>Then:</p> \[df = \left( -\left( r + \frac{1}{2} \theta^2 \right) + \frac{1}{2} \theta^2 \right) \zeta(t) dt - \theta \zeta(t) dW(t) = -r \zeta(t) dt - \theta \zeta(t) dW(t).\] <p><strong>(ii)</strong> Let $X(t)$ denote the value of an investor’s portfolio using strategy $\Delta(t)$. Then from (4.5.2),</p> \[dX(t) = rX(t) dt + \Delta(t)(\alpha - r) S(t) dt + \Delta(t) \sigma S(t) dW(t).\] <p>We want to show that $\zeta(t) X(t)$ is a martingale.</p> <p>Compute:</p> \[d(\zeta(t) X(t)) = \zeta(t) dX(t) + X(t) d\zeta(t) + d\zeta(t) dX(t).\] <p>Substitute from part (i) and the SDE for $X(t)$:</p> \[\begin{aligned} d(\zeta(t)X(t)) &amp;= \zeta(t) \left[ rX(t) dt + \Delta(t)(\alpha - r)S(t) dt + \Delta(t)\sigma S(t) dW(t) \right] \\ &amp;\quad + X(t)\left[ -\theta \zeta(t) dW(t) - r \zeta(t) dt \right] \\ &amp;\quad + (-\theta \zeta(t) dW(t)) \cdot (\Delta(t)\sigma S(t) dW(t)). \end{aligned}\] <p>Note that:</p> \[d\zeta(t) dX(t) = -\theta \zeta(t) \cdot \Delta(t) \sigma S(t) dt.\] <p>Combine everything:</p> \[\begin{aligned} d(\zeta(t)X(t)) &amp;= \zeta(t) rX(t) dt + \zeta(t) \Delta(t)(\alpha - r)S(t) dt + \zeta(t) \Delta(t) \sigma S(t) dW(t) \\ &amp;\quad - \theta \zeta(t) X(t) dW(t) - r \zeta(t) X(t) dt - \theta \zeta(t) \Delta(t) \sigma S(t) dt. \end{aligned}\] <p>Grouping terms:</p> <ul> <li>$dt$ terms cancel:</li> </ul> \[\zeta(t) rX(t) - r \zeta(t) X(t) + \zeta(t) \Delta(t)(\alpha - r) S(t) - \theta \zeta(t) \Delta(t) \sigma S(t) = 0,\] <p>since $(\alpha - r) = \theta \sigma$.</p> <ul> <li>$dW(t)$ terms:</li> </ul> \[\zeta(t) \Delta(t) \sigma S(t) - \theta \zeta(t) X(t).\] <p>But we already matched drift terms. So overall:</p> \[d(\zeta(t) X(t)) = \text{(stochastic integral)}.\] <p>Hence, $\zeta(t) X(t)$ is a <strong>local martingale</strong>. With appropriate integrability (usually assumed), it is a <strong>martingale</strong>.</p> <p><strong>(iii)</strong> Let $T &gt; 0$ be fixed. Suppose the investor wants to end up with portfolio value $V(T)$ at time $T$, where $V(T)$ is $\mathcal{F}(T)$-measurable.</p> <p>Then since $\zeta(t) X(t)$ is a martingale:</p> \[\zeta(0) X(0) = \mathbb{E}[\zeta(T) V(T)],\] <p>and $\zeta(0) = 1$, so:</p> \[X(0) = \mathbb{E}[\zeta(T) V(T)].\] <p>This means the <strong>present value</strong> of $V(T)$ at time $0$ is:</p> \[\mathbb{E}[\zeta(T) V(T)].\] <p>This justifies calling $\zeta(t)$ the <strong>state price density process</strong>.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kenneth Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"},svg:{scale:1.1,minScale:.8,matchFontHeight:!1}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-notes",title:"notes",description:"Personal-study notes for quant-finance related learning materials",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"notes-stochastic-calculus-for-finance-i",title:"Stochastic Calculus for Finance I",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance I",section:"Notes",handler:()=>{window.location.href="/notes/course-1/"}},{id:"notes-stochastic-calculus-for-finance-ii",title:"Stochastic Calculus for Finance II",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance II",section:"Notes",handler:()=>{window.location.href="/notes/course-2/"}},{id:"notes-chapter-1-no-arbitrage-pricing-model",title:"Chapter 1 - No-Arbitrage Pricing Model",description:"Notes on the No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-no-arbitrage/"}},{id:"notes-chapter-1-exercises",title:"Chapter 1 Exercises",description:"Exercises for Chapter 1 - No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-exercises/"}},{id:"notes-chapter-2-exercises",title:"Chapter 2 Exercises",description:"Exercises for Chapter 2 - Probability Theory on Coin Toss Space.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-exercises/"}},{id:"notes-chapter-2-probability-theory-on-coin-toss-space",title:"Chapter 2 - Probability Theory on Coin Toss Space",description:"Notes on probability theory applied to coin toss spaces.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-probability/"}},{id:"notes-chapter-3-state-prices",title:"Chapter 3 - State Prices",description:"Notes on State Prices in financial models.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-state-prices/"}},{id:"notes-chapter-3-exercises",title:"Chapter 3 Exercises",description:"Exercises for Chapter 3 - State Prices.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-exercises/"}},{id:"notes-chapter-4-american-derivative-securities",title:"Chapter 4 - American Derivative Securities",description:"Notes on American derivative securities and their valuation.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-4-american-derivatives/"}},{id:"notes-chapter-1-general-probability-theory",title:"Chapter 1 - General Probability Theory",description:"Notes on general probability theory and foundational concepts.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-general-probability/"}},{id:"notes-chapter-1-probability-exercises",title:"Chapter 1 - Probability Exercises",description:"Exercises for Chapter 1 - General Probability Theory.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-probability-exercises/"}},{id:"notes-chapter-2-information-exercises",title:"Chapter 2 - Information Exercises",description:"Exercises for Chapter 2 - Information and Conditioning.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-exercises/"}},{id:"notes-chapter-2-information-and-conditioning",title:"Chapter 2 - Information and Conditioning",description:"Notes on information theory and conditional probability.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-conditioning/"}},{id:"notes-chapter-3-brownian-motion-exercises",title:"Chapter 3 - Brownian Motion Exercises",description:"Exercises for Chapter 3 - Brownian Motion.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion-exercises/"}},{id:"notes-chapter-3-brownian-motion",title:"Chapter 3 - Brownian Motion",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion/"}},{id:"notes-chapter-4-stochastic-calculus-exercises",title:"Chapter 4 - Stochastic Calculus Exercises",description:"Notes on Stochastic Calculus and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-stochastic-calculus-exercises/"}},{id:"notes-chapter-4-stochastic-calculus",title:"Chapter 4 - Stochastic Calculus",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-stochastic-calculus/"}},{id:"notes-chapter-6-partial-differential-equations-exercises",title:"Chapter 6 - Partial Differential Equations Exercises",description:"Notes on Partial Differential Equations and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-PDEs-exercises/"}},{id:"notes-chapter-6-partial-differential-equations",title:"Chapter 6 - Partial Differential Equations",description:"Notes on Partial Differential Equations and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-PDEs/"}},{id:"projects-the-lagging-indicator-chronicles-a-tale-of-policies-playing-catch-up",title:"The Lagging Indicator Chronicles \u2013 A Tale of Policies Playing Catch-Up",description:"Lag time between state-level policy interventions and change points in COVID-19 outcomes in the United States. Read more at ![this article](https://www.cell.com/patterns/fulltext/S2666-3899(21)00149-5).",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-pm2-5-and-the-great-regulatory-vanishing-act-when-pollution-took-a-free-pass",title:"PM2.5 and the Great Regulatory Vanishing Act - When Pollution Took a Free...",description:"An introduction to the statistical models used to assess the impact of EPA rollbacks on air quality in California. https://enveurope.springeropen.com/articles/10.1186/s12302-021-00489-9",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> </body> </html>
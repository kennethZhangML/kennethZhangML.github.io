<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chapter 1 - General Probability Theory | Kenneth Zhang </title> <meta name="author" content="Kenneth Zhang"> <meta name="description" content="Notes on general probability theory and foundational concepts."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kennethzhangml.github.io/notes/course-2/chapter-1-general-probability/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kenneth</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Chapter 1 - General Probability Theory</h1> <p class="post-description">Notes on general probability theory and foundational concepts.</p> </header> <article> <h3 id="infinite-probability-spaces"><strong>Infinite Probability Spaces</strong></h3> <p>We want t model a situation in which a random experiment with infinitely many possible outcomes is conducted. Problem: uncountably infinite samples spaces.</p> <p>Let $\Omega$ be a sample spaces with $\Omega_{\infty}$ denoting the infinite sample space</p> <p>Not possible to list elements in sequence, probability of any outcome is 0.</p> <ul> <li>Cannot determine probability of $A$ summing up probabilities of the elements in $A \subseteq \Omega$</li> <li> <h2 id="must-define-probabilities-of-the-events-directly"> <strong>Must</strong> define probabilities of the events directly.</h2> <p><strong>Definition</strong>: $\sigma$-algebra of $\Omega$ and $F \subseteq \Omega$ collection of subsets of $\Omega$</p> <ol> <li>$\emptyset$ belongs to $F$</li> <li>when $A \in F$ then $A^c \in F$ as well</li> <li>$A_1, A_2, \dots$ in $F$ then $\cup_{n = 1}^\infty A_n$ also belongs to $F$ Operations done to the elements of a $\sigma$-algebra give us other sets in the $\sigma$-algebra. For example, the intersection of a finite number of sets in a $\sigma$-algebra results in a set in the $\sigma$-algebra, if $F$ is a $\sigma$-algebra, then the whole space $\Omega$ must be one of the sets in $F$ because $\Omega = F^c$.</li> </ol> </li> </ul> <hr> <p><strong>Definition</strong>: A probability measure $\mathbb{P}$ is a function that maps every $A \in F$ to a number in $[0, 1]$. We call this the probability of $A$ written as $\mathbb{P}(A)$.</p> <ol> <li>$\mathbb{P}(A)$</li> <li>Countable Additivity: when a sequence of events $A_1, A_2, \dots$ of disjoint sets is in $F$ then,</li> </ol> \[\mathbb{P} \left(\cup_{n = 1}^\infty A_n \right) = \sum_{n = 1}^\infty \mathbb{P}(A_n)\] <p>We denote $(\Omega, F, \mathbb{P})$ as our probability space.</p> <p><strong>Examples</strong> Take $A_1, A_2, \dots$ as our sequence of events in $F$ which is in the sample space $\Omega$. Then, to be sure that $\mathbb{P}(\emptyset) = 0$, we have that:</p> \[A_1 = A_2 = A_3 = \dots = \emptyset\] <p>Then it is the case that</p> \[\mathbb{P}(\emptyset) = \sum_{n = 1}^\infty \mathbb{P}(\emptyset)\] <p>Thus we have that, $\mathbb{P} = \emptyset$. Let’s say that our previous sequence is finitely additive, and that our sequence is finitely many disjoint sets in $F$, then we have:</p> \[\mathbb{P}\left(\cup_{n = 1}^N A_n \right) = \sum_{n = 1}^N \mathbb{P}(A_n)\] <p>use, $A_{N + 1} = A_{N + 2} = \dots = \emptyset$ to get the result above. It follows by transitivity.</p> <p><strong>Lebesgue Measure</strong>: usually denoted $\mathcal{L}$, is the probability measure that the number chosen is between $a$ and $b$ which is $b - a$, that is:</p> \[\mathbb{P}[a, b] = b - a,\quad, 0\le a \le b \le 1\] <p>The Lebesgue measure of a subset of $\mathbb{R}$ is its length, so, if $b = a$, then naturally,</p> \[\mathbb{P}[a, b] = \mathbb{P}[a, a] = a - a = 0\] <p>Single points have zero probability, thus, the probability of an open interval $(a, b)$ has the same probability as a closed interval $[a, b]$. We can also write an open interval as the union of a sequence of closed intervals:</p> \[(a, b) = \cup_{n = 1}^\infty \left[a + \frac{1}{n}, b - \frac{1}{n} \right]\] <p>which is a $\sigma$-algebra that contains all open intervals.</p> <hr> <p><strong>Borel $\sigma$-algebra</strong>: A $\sigma$-algebra obtained by starting with closed intervals, and adding everything else necessary in order to have a $\sigma$ algebra. i.e., the borel sigma algebra of subsets of $[0, 1]$ is denoted by $\mathcal{B}[0, 1]$ which contain <strong>Borel Sets</strong></p> <p>e.g., Take an independent coin space, starting with $\mathbb{P}(\emptyset) = 0$ and $\mathbb{P}(\Omega) = 1$, then we start with:</p> \[2^{(2^0)} = 2 \text{ sets} \implies \mathcal{F} = \{\emptyset, \Omega \}\] <p>For which $A_H$ is the set with sequences starting with $H$, and $A_T$ starting with $T$. We continue to carry out these tosses to get $2^{(2^1)} = 4$ sets for $\mathcal{F_1}$ and $2^{(2^2)} = 16$ sets for $\mathcal{F_2}$ and so on. Once the probabilities for these sets are defined, then other, non-describable sets are also determined.</p> <p>We can expand this to $F_\infty$ where we can take the limit:</p> \[\lim_{n \rightarrow \infty} = \frac{H_n(\omega_1 \dots \omega_n)}{n} = \frac{1}{2}\] <p>where the numerator of the limit denotes the number of heads in the first $n$ tosses. Thus, by the definition of this limit, and the coin toss sequences $\omega = \omega_1 \omega_2 \dots$, is satisfied if and only if for every integer $m$ there is a positive integer $N$ such that for all $n \ge N$ we have $\omega \in S_{n, m}$</p> \[S_{n, m} = \left\{\omega; \left|\frac{H_n(\omega_1 \dots \omega_n)}{n} - \frac{1}{2} \right| \le \frac{1}{m} \right\}\] <p>Set $A$ in $F_\infty$ because it is described in terms of the unions and intersections of a sequence of sets that are in $\mathcal{F}_\infty$, thus tells us that $\mathbb{P}(A)$ is somehow determined.</p> <p>We say that an event with $\mathbb{P}(A) = 1$ occurs almost surely. That is, if a set $A \in \mathcal{F}$ satisfies $\mathbb{P} = 1$ we that the event $A$ occurs almost surely.</p> <hr> <h3 id="random-variables-and-distributions"><strong>Random Variables and Distributions</strong></h3> <p>$X$ is a random variable (i.e. a real-valued function) defined on our sample space $\Omega$ that for every Borel subset $B \subseteq \mathbb{R}$ the subset of $\Omega$ is given by:</p> \[\{X \in B\} = \{\omega \in \Omega; X(\omega) \in B\}\] <p>is in the $\sigma$-algebra $\mathcal{F}$. Start with closed intervals $[a, b] \subset \mathbb{R}$ and add all other sets that are necessary in order to have a $\sigma$-algebra. We determine the value via a random experiment of choosing $\omega \in \Omega$, i.e., the probability that $X$ takes some value in some set.</p> \[\mathbb{P}\{X \in B\} \implies \{X \in B\} \in \mathcal{F} \implies B \in B(\mathbb{R})\] <p>Think of random variables $S_0, S_1, S_2, \dots$ that have distribution.</p> \[\mathbb{P}(S_0 = 4) = 1\] <p>We can say that $S_0$ puts a unit of mass on the number $4$. So for random variables, with multiple possible outcomes, let’s say 3 different scenarios, we can say that the distribution of this random variable puts three lumps of mass of different sizes (probabilities) on each possibility.</p> <p>We need to allow the possibility that the random variables we consider don’t assign lumps of mass but spread a unit of mass continuously over the real line (i.e., tells us how much mass is in a set rather than how much mass is at a point).</p> <p><strong>Distribution</strong> of a random variable itself is a probability measure, but is a measure on subsets of $\mathbb{R}$ rather than the subsets of $\Omega$.</p> <hr> <p><strong>Definition</strong>: The distribution measure of random variable $X$ is the probability measure $\mu_X$ that assigns each Borel subset $B$ of $\mathbb{R}$ the mass:</p> \[\mu_X (B) = \mathbb{P} \{X \in B\}\] <p>e.g., Uniform measure on $[0, 1]$ and define $X(\omega) = \omega$ and $Y(\omega) = 1- \omega$, then</p> \[\mu_X [a, b] = \mathbb{P}\{\omega; a \le X(\omega) \le b\} = \mathbb{P}[a, b] = b - a,\quad 0\le a \le b \le 1\] <p>we use the same technique to define $\mu_Y$:</p> \[\mu_Y[a, b] = \mathbb{P}\{\omega; a \le Y(\omega) \le b\} = \mathbb{P}\{\omega; a \le 1 - \omega \le b\} = \mathbb{P}[1 - b, 1 - a] = b - a = \mu_X[a, b]\] <p>Suppose we define $\tilde{\mathbb{P}}$ on $[0, 1]$ and specify that:</p> \[\tilde{\mathbb{P}}[a, b] = \int_a^b 2 \omega d \omega = b^2 - a^2,\quad 0 \le a \le b \le 1\] <p>then $\tilde{\mu}_X[a, b]$ is equal to the above and the random variable $X$ no long has the uniform distribution as defined previously.</p> <hr> <p><strong>Cumulative Distribution Function (cdf) of a random variable</strong></p> \[F(x) = \mathbb{P}\{X \le x\},\quad x \in \mathbb{R}\] <p>We know the distribution measure $\mu_X$ then we know cdf $F$ because</p> \[F(x) = \mu_X (-\infty, x]\] <ul> <li>If we know cdf $F$, then we can compute $\mu_X(x, y] = F(y) - F(x)$ so for $a \le b$:</li> </ul> \[[a, b] = \cap_{n = 1}^\infty \left(a - \frac{1}{n}, b\right]\] <ul> <li>Thus we get that:</li> </ul> \[\mu_X[x, b] = \lim_{n \rightarrow \infty} \mu_X \left(a - \frac{1}{n}, b \right] = F(b) - \lim_{n \rightarrow \infty} F(a - 1/n)\] <p>Thus, knowing the cdf $F$ for a random variable is the same as knowing its distribution measure $\mu_X$. In other cases, we can record a random variable using:</p> <ol> <li>a density function $f(x)$,</li> </ol> \[\mu_X[a, b] = \mathbb{P}\{a \le X \le b\} = \int_a^b f(x) dx,\quad -\infty &lt; a \le b &lt; \infty\] \[\int_{-\infty}^\infty f(x)dx = \lim_{n \rightarrow \infty} \int_{-\infty}^\infty f(x) dx = \lim_{n \rightarrow \infty} \mathbb{P}\{-n \le X \le n\} = \mathbb{P}\{X \in \mathbb{R}\} = \mathbb{P}(\Omega) = 1\] <ol> <li>a probability mass function, given sequence of numbers $x_1, \dots, x_N$ or infinite sequence, we can define $p_i = \mathbb{P}{X = x_i}$ so that $\sum p_i = 1$ for all $i$. Then the mass assigned to a Borel set $B \subset \mathbb{R}$ by the distribution measure of $X$ is:</li> </ol> \[\mu_X(B) = \sum_{i, x_i \in B} p_i,\quad B \in B(\mathbb{R})\] <hr> <h3 id="expectations">Expectations</h3> <p>We want to compute the average value of a random variable $X$. If $\Omega$ is finite, then we define:</p> \[\mathbb{E} X = \sum_{\omega \in \Omega} X(\omega) \mathbb{P}(\omega)\] <p>For an infinite sequence, we can define this as the infinite sum:</p> \[\mathbb{E} X = \sum_{k = 1}^\infty X(\omega_k) \mathbb{P}(\omega_k)\] <p>For uncountably infinite sample spaces $\Omega$, then: Partition the interval $[a, b]$ into subintervals $[x_0, x_1], [x_1, x_2], \dots, [x_{n - 1}, x_n]$ such that we have $a = x_1 &lt; x_1 &lt; \dots &lt; x_n = b$ where our partition is $\Pi = {x_0, x_1, x_2, \dots, x_n }$ is the set of partition points and by:</p> \[||\Pi|| = \max_{1 \le k \le n} \{x_k - x_{k - 1} \}\] <p>we take the length of the longest subinterval in the partition. For each subinterval in this partition, we take $M_k$ and $m_k$ as the largest subinterval defined on the function $f(x)$ as:</p> \[M_k = \max_{x_{k - 1} \le x \le x_k} f(x), \quad m_k = \min_{x_{k - 1} \le x \le x_k} f(x)\] <p>The <strong>Upper Riemann Sum</strong>:</p> \[RS^+_\Pi (f) = \sum_{k = 1}^n M_k(x_k - x_{k - 1})\] <p>The <strong>Lower Riemann Sum</strong>:</p> \[RS^-_\Pi (f) = \sum_{k = 1}^n m_k (x_k - x_{k - 1})\] <p>as we take more and more partition points and the subintervals, we take, get smaller and smaller, the upper and lower Riemann sums converge to the same limit.</p> <p><strong>We cannot do this for random variables</strong>, since they are a function of $\omega \in \Omega$, which is often not a subset of $\mathbb{R}$. Thus, we take $0 \le X(\omega) &lt; \infty$, and let $\Pi = {y_0, y_1, \dots}$ where $0 = y_0 &lt; y_1 &lt;\dots$. For each subinterval $[y_k, y_{k + 1}]$, we set:</p> \[A_k = \{\omega \in \Omega; y_k \le X(\omega) &lt; y_{k + 1}\}\] <p>The <strong>Lower Lebesgue Sum</strong></p> \[LS^-_\Pi (X) = \sum_{k = 1}^\infty y_k \mathbb{P}(A_k)\] <table> <tbody> <tr> <td>As this lower sum converges as $</td> <td> </td> <td>\Pi</td> <td> </td> <td>$ approaches (i.e., the maximal distance between $y_k$ partition points approaches 0), we define this limit as the Lebesgue Integral:</td> </tr> </tbody> </table> \[\int_\Omega X(\omega) d \mathbb{P}(\omega) \quad\text{or}\quad \int_\Omega X d\mathbb{P}\] <ul> <li>If $\mathbb{P}{\omega; X(\omega) \ge 0} = 1$ but $\mathbb{P}{\omega; X(\omega) = \infty} &gt; 0$ then we define:</li> </ul> \[\int_\Omega X(\omega) d \mathbb{P}(\omega) = \infty\] <p>We also must consider that $X$ can take positive and negative values, thus we define positive and negative parts of $X$ by:</p> \[X^+ (\omega) = \max \{X(\omega), 0\} \quad\text{and}\quad X^-(\omega) = \max\{- X(\omega), 0\}\] <p>Note, the following remarks</p> <ul> <li>$X^+$ and $X^-$ are both non-negative random variables</li> <li>$X = X^+ - X^-$</li> <li>$|X| = X^+ + X^-$ Finally,</li> </ul> \[\int_\Omega X^+(\omega) d \mathbb{P}(\omega) = \int_\Omega X^+ (\omega) d \mathbb{P}(\omega) - \int_\Omega X^-(\omega) d \mathbb{P}(\omega)\] <p>where the two integrals on the RHS, are both finite, and thus $X$ is said to be integrable and finite.</p> <p><strong>Theorem</strong>: Expectation properties</p> <ol> <li>$X$ takes finitely many values $y_0, y_1, y_2, \dots, y_n$ then</li> </ol> \[\int_\Omega X(\omega) d \mathbb{P}(\omega) = \sum_{k = 0}^n y_k \mathbb{P}\{X = y_k\}\] <ol> <li>R.v. $X$ is integrable if and only if</li> </ol> \[\int_\Omega |X(\omega)| d \mathbb{P}(\omega) &lt; \infty\] <ol> <li>Take $X \le Y$, $\mathbb{P}{X \le Y} = 1$, then:</li> </ol> \[\int_\Omega X(\omega) d \mathbb{P}(\omega) \le \int_\Omega Y(\omega) d \mathbb{P}(\omega)\] <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>For the case that $X = Y$ then we have:
</code></pre></div></div> \[\int_\Omega X(\omega) d \mathbb{P}(\omega) = \int_\Omega Y(\omega) d \mathbb{P}(\omega)\] <ol> <li>Linearity of Expectation of integrable random variables</li> </ol> \[\int_\Omega (\alpha X(\omega) + \beta Y(\omega)) d \mathbb{P}(\omega) = \alpha \int_\Omega X(\omega) d \mathbb{P}(\omega) + \beta \int_\Omega Y(\omega) d \mathbb{P}(\omega)\] <p>Take $X \le Y$ almost surely, so that $X^+ \le Y^+$ and $X^- \ge Y^-$ almost surely, then,</p> \[LS^-_\Pi (X^+) \le LS^-_\Pi (Y^+)\] <p>so that we have,</p> \[\int_\Omega X^+(\omega) d \mathbb{P}(\omega) \le \int_\Omega Y^+(\omega) d\mathbb{P}(\omega)\] <p>A similarly formulation with the $\ge$ applies for $X^-$ and $Y^-$.</p> <p>Let’s say we want to integrate a random variable $X$ over a subset of $A$ of $\Omega$ rather than over all $\Omega$ then for this reason, we can use an indicator random variable, for $\omega$ when it is in $A$ and when it is not. i.e., thus we can get that if $A$ and $B$ are disjoint sets in $\mathcal{F}$ then we can write that:</p> \[\mathbb{I}_A + \mathbb{I}_B = \mathbb{I}_{A \cup B}\] <p>Then, by the linearity property we can get that:</p> \[\mathbb{E} X = \int_\Omega X(\omega) d \mathbb{P}(\omega)\] <p>where at least one of $\mathbb{E} X^+$ or $\mathbb{E}X^-$ is finite.</p> <p><strong>Theorem</strong>: $X$ is a random variable on some probability space,</p> <ol> <li>$X$ takes finitely many values, then</li> </ol> \[\mathbb{E} X = \sum_{k = 0}^n x_k \mathbb{P}\{X = x_k\}\] <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>If $\Omega$ is finite, then
</code></pre></div></div> \[\mathbb{E} X = \sum_{\omega \in \Omega} X(\omega) \mathbb{P}(\omega)\] <ol> <li>Integrability, $X$ is integrable if and only if</li> </ol> \[\mathbb{E}|X| &lt; \infty\] <ol> <li>Comparison, if $X \le Y$ then</li> </ol> \[\mathbb{E}X \le \mathbb{E} Y\] <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if $X = Y$ then
</code></pre></div></div> \[\mathbb{E} X = \mathbb{E} Y\] <ol> <li>Linearity and Jensen’s inequality hold for expectation, trivially.</li> </ol> <p>However, no matter how small we take the subintervals in the partition, the upper Riemann sum is always 1 and the lower is always 0, so the sums do not converge. Thus, because the Riemann sum discretizes the x-axis, the function is too discontinuous to handle, thus we use the Lebesgue integral which discretizes the y-axis.</p> <p><strong>Definition</strong>: Take $B(\mathbb{R})$ the sigma-algebra of Borel subsets of $\mathbb{R}$. The Lebesgue measure on $\mathbb{R}$ which we denote by $\mathcal{L}$ assigns to each Borel set $B \in B(\mathbb{R})$ a number in $[0, \infty)$ or $\infty$ such that:</p> <ol> <li>$\mathcal{L}[a, b] = b - a$ when $a \le b$</li> <li>If $B_1, B_2, \dots$ is a sequence of disjoint Real-Borel sets, then we have the countable additivity property that tells us that:</li> </ol> \[\mathcal{L} \left(\cup_{n = 1}^\infty B_n \right) = \sum_{n = 1}^\infty \mathcal{L}(B_n)\] <p>which also holds for non-$\infty$, so the finite additivity property for $N$ also holds for the above. For $f(x)$, a real-valued function, we assume that for every Borel subset $B$ of $\mathbb{R}$, the set ${x; f(x) \in B}$ is also a Borel subset of $\mathbb{R}$. We define the Lebesgue integral as:</p> \[\int_\mathbb{R} f(x) d \mathcal{L}(x)\] <p>of $f$ over $\mathbb{R}$. Again, we define $\Pi$ as we did before and for each subinterval, we define:</p> \[B_k = \{x \in \mathbb{R}; y_k \le f(x) &lt; y_{k + 1}\}\] <p>$f$ is Borel measurable, then similarly, the following hold:</p> <ul> <li> <table> <tbody> <tr> <td>As the $</td> <td> </td> <td>\Pi</td> <td> </td> <td>$ converges to zero, the lower Lebesgue sums converge to a limit, which we define $\int_\mathbb{R} f(x) d \mathcal{L} (x)$ which could give value $\infty$</td> </tr> </tbody> </table> </li> <li>For some $B \in B(\mathbb{R})$ we compute the Lebesgue integral over only part of $\mathbb{R}$, as indicated by our indicator function, so the product $f(x) \mathbb{I}_B(x)$ agrees with $f(x)$ when $x \in B$</li> </ul> \[\int_B f(x) d \mathcal{L}(x) = \int_B \mathbb{I}_B f(x) d \mathcal{L}(x)\] <p><strong>Theorem</strong>: $f$ is bounded and $a &lt; b$</p> <ol> <li>Riemann integral is defined for $f(x)$ on the reals, if and only if the set of points $x$ in $[a, b]$ where $f(x)$ is not continuous has Lebesgue measure 0.</li> <li>Riemann integral is defined, then $f$ is Borel measurable (so the Lebesgue integral is also defined) and the Riemann and Lebesgue integrals agree, trivially,</li> </ol> <p><strong>Definition</strong>: If the set of numbers in $\mathbb{R}$ fails to have some property is a set with Lebesgue measure 0, we say that the property holds almost everywhere.</p> <hr> <h3 id="convergence-of-integrals">Convergence of Integrals</h3> <p><strong>Definition</strong>: Let $X$ be an r.v., and the sequence $X_1, X_2, \dots$ converges to $X$ almost surely, then</p> \[\lim_{n \rightarrow \infty} X_n = X \quad \text{almost surely}\] <p>if the set $\omega \in \Omega$ where $X_1(\omega), X_2(\omega), \dots$ has limit $X(\omega)$ with proba. 1. Conversely, if they do not converge to $X(\omega)$, then it has proba. 0.</p> <p><strong>Definition</strong>: Let $f_1, f_2, \dots$ be a sequence of real-valued Borel-measurable functions defined on $\mathbb{R}$. Then $f$ is another real-valued, Borel-measurable function, we say that $f_1, f_2, \dots$ converges to $f$ almost everywhere and write,</p> \[\lim_{n \rightarrow \infty} f_n = f \quad\text{almost everywhere}\] <p>if the set of $x \in \mathbb{R}$ for which the sequence of numbers $f_1(x), f_2(x), f_3(x), \dots$ does not have limit $f(x)$ is a set with Lebesgue measure 0.</p> <ul> <li>when functions converge almost everywhere, their expected values converge to the expected value of the limit random variable</li> <li>Lebesgue integrals converge to the Lebesgue integral of the limiting function, but not always, in particular, when the everywhere-limit function $f$ is identically 0.</li> <li>To get the integrals of a sequence of functions to converge to the integral of the limiting function, we impose that, all the functions are non-negative and they converge to their limit from below</li> </ul> <p><strong>Theorem</strong>: Monotone Convergence theorem $X_1, X_2, \dots$ is a sequence of random variables converging almost surely to another random variable $X$, so, if $0 \le X_1 \le X_2 \le \dots$ almost surely, we have that,</p> \[\lim_{n \rightarrow \infty} \mathbb{E}X_n = \mathbb{E} X\] <p>Let $f_1, f_2, f_3, \dots$ be a sequence of Borel-measurable functions on $\mathbb{R}$ converging almost everywhere to a function $f$, if $0 \le f_1 \le f_2 \le f_3 \le \dots$ almost everywhere, then</p> \[\lim_{n \rightarrow \infty} \int_{-\infty}^\infty f_n(x)dx = \int_{-\infty}^\infty f(x) dx\] <p><strong>Corollary</strong>: Suppose the non-negative random variable $X$ takes countably many values, then</p> \[\mathbb{E}X = \sum_{k = 0}^\infty x_k \mathbb{P}\{X = x_k\}\] <p>Let $A_k = {X = x_k}$ so that $X$ can be written as:</p> \[X = \sum_{k = 0}^\infty = x_k \mathbb{I}_{A_k}\] <p>Then, we can define $X_n = \sum_{k = 0}^n x_k \mathbb{I}<em>{A_k}$ for $0 \le X_1 \le X_2 \le X_3 \le \dots$ and $\lim</em>{n \rightarrow \infty} X_n = X$ almost surely. Thus, the proof follows by taking the limit on both sides and using the MCT to justify the first equality to get our definition for $\mathbb{E}X$ above.</p> <p><strong>Theorem</strong>: Dominated Convergence Let $X_1, X_2, \dots$ be a sequence of random variable converging almost surely to a random variable $X$. If there is another random variable $Y$ such that $\mathbb{E}Y &lt; \infty$ and $|X_n| \le Y$ almost surely, then</p> \[\lim_{n \rightarrow \infty} \mathbb{E} X_n = \mathbb{E} X\] <table> <tbody> <tr> <td>$f_1, f_2, \dots$ is a sequence of Borel-measurable functions on $\mathbb{R}$ converging almost everywhere to a function $f$. If there is another function $g$ such that $\int_{-\infty}^{\infty} g(x) dx &lt; \infty$ and $</td> <td>f_n</td> <td>\le g$ almost everywhere, then we can write,</td> </tr> </tbody> </table> \[\lim_{n \rightarrow \infty} \int_{-\infty}^{\infty} f_n(x) dx = \int_{-\infty}^{\infty} f(x) dx\] <hr> <h3 id="computation-of-expectations">Computation of Expectations</h3> <p>Using the definition of the expectation of r.v., X, to be the Lebesgue integral, we need to rely on densities of the random variables to compute the expectation under $\Omega$.</p> <p>$\mu_X$ is a probability measure on $\mathbb{R}$ so we can use it to integrate functions over $\mathbb{R}$.</p> <p><strong>Theorem</strong>: $X$ is a random variable, on a probability space defined by the triple, let $g$ be a Borel-measurable function on $R$, then,</p> \[\mathbb{E} |g(X)| = \int_\mathbb{R} |g(x)| d \mu_X(x)\] <p>if this quantity, above, is finite, then,</p> \[\mathbb{E} g(X) = \int_\mathbb{R} g(x) d \mu_X (x)\] <p>The proof follows by using an indicator random variable that takes values to compute the expectation of $\mathbb{I}_B(X)$ and use properties of non-negative simple functions as a finite sum of indicator functions times some constant(s). Then, we achieve something of the form of a non-negative Borel-measurable function which we assume to be arbitrary. Taking the limit, using the MCT, we obtain the integral over $g(x)$ over the reals. We can then compute the Lebesgue integral over the abstract space $\Omega$ so it suffices to compute the integral over the set of real numbers. Since $X$ only takes finitely many values, $\mu_X$ places a mass of size $p_k = \mathbb{P}{X = x_k}$ at each number $x_k$. Then we can get something like,</p> \[\mathbb{E}g(X) = \int_\mathbb{R} g(x) \mu_X dx = \sum_{k = 0}^n g(x_k) p_k\] <p><strong>Theorem</strong> Let $g$ be a Borel-measurable function on $\mathbb{R}$ and suppose $X$ has density $f$, then:</p> \[\mathbb{E} |g(X)| = \int_{-\infty}^\infty |g(x)| f(x) dx\] <p>if the quantity above is finite, then we can write</p> \[\mathbb{E} g(X) = \int_{-\infty}^\infty g(x) f(x) dx\] <hr> <h3 id="change-of-measure">Change of Measure</h3> <p>We had previously used $Z$ to change probability measures on $\Omega$. When $\Omega$ is uncountably infinite, and $\mathbb{P}(\omega) = \tilde{\mathbb{P}}(\omega) = 0$ for every $\omega \in \Omega$, there is no use to write it as:</p> \[Z(\omega) = \frac{\tilde{\mathbb{P}(\omega)} }{\mathbb{P}(\omega)} \implies Z(\omega) \mathbb{P}(\omega) = \tilde{\mathbb{P}}(\omega)\] <p>We re-assign probabilities in $\Omega$ using $Z$ to tell us where in $\Omega$ we should revise the probability upward where $Z &gt; 1$ and revise the probability downward $Z &lt; 1$.</p> <p><strong>Theorem</strong>: Let $Z$ be an almost surely non-negative random variable with $\mathbb{E}Z = 1$ and, for $A \in F$,</p> \[\tilde{\mathbb{P}}(A) = \int_A Z(\omega) d \mathbb{P}(\omega)\] <p>Then, $\tilde{\mathbb{P}}$ is a probability measure. If $X$ is a non-negative random variable, then,</p> \[\tilde{\mathbb{E}}X = \mathbb{E}[XZ]\] <p>If $Z$ is almost surely strictly positive, then,</p> \[\mathbb{E} Y = \tilde{\mathbb{E}} \left[\frac{Y}{Z} \right]\] <p>for every non-negative random variable $Y$. Suppose $X$ is a r.v., that can take both positive and negative values, and apply $\tilde{\mathbb{E}}X$ to the negative and positive parts of $X$ then subtract the resulting equations to see that $\mathbb{E}Y$ holds well. Given by assumption,</p> \[\tilde{\mathbb{P}}(\Omega) = \int_\Omega Z(\omega) d \mathbb{P}(\omega) = \mathbb{E}Z = 1\] <p>For countable additivity, let $A_1, A_2, \dots$ be a sequence of disjoint sets in $F$ and define $B_n = \cup_{k = 1}^n A_k, B_\infty = \cup_{k = 1}^\infty A_k$. Thus:</p> \[\mathbb{I}_{B_1} \le \mathbb{I}_{B_2} \le \dots \implies \lim_{n \rightarrow \infty} \mathbb{I}_{B_n} = \mathbb{I}_{B_\infty}\] \[\begin{align*} \tilde{\mathbb{P}}(B_\infty) = \int_\Omega \mathbb{I}_{B_\infty} (\omega) Z(\omega) d \mathbb{P}(\omega) = \lim_{n \rightarrow \infty} \int_\Omega \mathbb{I}_{B_n} (\omega) Z(\omega) d \mathbb{P}(\omega)\\ \int_\Omega \mathbb{I}_{B_n}(\omega) Z(\omega) d \mathbb{P}(\omega) = \sum_{k = 1}^n \int_\Omega \mathbb{I}_{A_k}(\omega) Z(\omega) d \mathbb{P}(\omega) = \sum_{k = 1}^n \tilde{\mathbb{P}}(A_k)\\ \end{align*}\] <p>We get, through combining the equations, to get:</p> \[\tilde{\mathbb{P}} \left(\cup_{k = 1}^\infty A_k \right) = \lim_{n \rightarrow \infty} \sum_{k = 1}^n \tilde{\mathbb{P}}(A_k) = \sum_{k = 1}^\infty \tilde{\mathbb{P}}(A_k)\] <p>Suppose $X$ is a non-negative random variable, if $X$ is an indicator function, then we get;</p> \[\tilde{\mathbb{E}}(X) = \tilde{\mathbb{P}}(A) = \int_\Omega \mathbb{I}_A (\omega) Z(\omega) d \mathbb{P}(\omega) = \mathbb{E}[\mathbb{I}_A Z] = \mathbb{E}[X Z]\] <p><strong>Definition</strong>: Let $\Omega$ be a non-empty set and $\mathcal{F}$ be a sigma-algebra of subsets of $\Omega$. Two probability measure $\mathbb{P}$ and $\tilde{\mathbb{P}}$ on $(\Omega, \mathcal{F})$ are said to be equivalent if they agree on which sets in $\mathcal{F}$ have probability zero.</p> <p><strong>Definition</strong>: Let a probability space defined by it’s probability triple, and have $\tilde{\mathbb{P}}$ and $\mathbb{P}$ be the risk-neutral and real-world probability measures. Then $Z$ is called the Radon-Nikodym derivative of $\tilde{\mathbb{P}}$ with respect to $\mathbb{P}$ and we can write:</p> \[Z = \frac{d \tilde{\mathbb{P}}}{d \mathbb{P}}\] <p><strong>Definition</strong>: Let $\mathbb{P}$ and $\tilde{\mathbb{P}}$ be equivalent probability measures defined on $(\Omega, \mathcal{F})$. Then there exists an almost surely positive random variable $Z$ such that $\mathbb{E}Z = 1$, and</p> \[\tilde{\mathbb{P}}(A) = \int_A Z(\omega) d \mathbb{P}(\omega) \quad \text{for every } A \in \mathcal{F}\] </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kenneth Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"},svg:{scale:1.1,minScale:.8,matchFontHeight:!1}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-notes",title:"notes",description:"Personal-study notes for quant-finance related learning materials",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"notes-stochastic-calculus-for-finance-i",title:"Stochastic Calculus for Finance I",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance I",section:"Notes",handler:()=>{window.location.href="/notes/course-1/"}},{id:"notes-stochastic-calculus-for-finance-ii",title:"Stochastic Calculus for Finance II",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance II",section:"Notes",handler:()=>{window.location.href="/notes/course-2/"}},{id:"notes-chapter-1-no-arbitrage-pricing-model",title:"Chapter 1 - No-Arbitrage Pricing Model",description:"Notes on the No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-no-arbitrage/"}},{id:"notes-chapter-1-exercises",title:"Chapter 1 Exercises",description:"Exercises for Chapter 1 - No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-exercises/"}},{id:"notes-chapter-2-exercises",title:"Chapter 2 Exercises",description:"Exercises for Chapter 2 - Probability Theory on Coin Toss Space.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-exercises/"}},{id:"notes-chapter-2-probability-theory-on-coin-toss-space",title:"Chapter 2 - Probability Theory on Coin Toss Space",description:"Notes on probability theory applied to coin toss spaces.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-probability/"}},{id:"notes-chapter-3-state-prices",title:"Chapter 3 - State Prices",description:"Notes on State Prices in financial models.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-state-prices/"}},{id:"notes-chapter-3-exercises",title:"Chapter 3 Exercises",description:"Exercises for Chapter 3 - State Prices.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-exercises/"}},{id:"notes-chapter-4-american-derivative-securities",title:"Chapter 4 - American Derivative Securities",description:"Notes on American derivative securities and their valuation.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-4-american-derivatives/"}},{id:"notes-chapter-1-general-probability-theory",title:"Chapter 1 - General Probability Theory",description:"Notes on general probability theory and foundational concepts.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-general-probability/"}},{id:"notes-chapter-1-probability-exercises",title:"Chapter 1 - Probability Exercises",description:"Exercises for Chapter 1 - General Probability Theory.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-probability-exercises/"}},{id:"notes-chapter-2-information-exercises",title:"Chapter 2 - Information Exercises",description:"Exercises for Chapter 2 - Information and Conditioning.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-exercises/"}},{id:"notes-chapter-2-information-and-conditioning",title:"Chapter 2 - Information and Conditioning",description:"Notes on information theory and conditional probability.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-conditioning/"}},{id:"notes-chapter-3-brownian-motion-exercises",title:"Chapter 3 - Brownian Motion Exercises",description:"Exercises for Chapter 3 - Brownian Motion.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion-exercises/"}},{id:"notes-chapter-3-brownian-motion",title:"Chapter 3 - Brownian Motion",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion/"}},{id:"projects-the-lagging-indicator-chronicles-a-tale-of-policies-playing-catch-up",title:"The Lagging Indicator Chronicles \u2013 A Tale of Policies Playing Catch-Up",description:"Lag time between state-level policy interventions and change points in COVID-19 outcomes in the United States. Read more at ![this article](https://www.cell.com/patterns/fulltext/S2666-3899(21)00149-5).",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-pm2-5-and-the-great-regulatory-vanishing-act-when-pollution-took-a-free-pass",title:"PM2.5 and the Great Regulatory Vanishing Act - When Pollution Took a Free...",description:"An introduction to the statistical models used to assess the impact of EPA rollbacks on air quality in California. https://enveurope.springeropen.com/articles/10.1186/s12302-021-00489-9",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> </body> </html>
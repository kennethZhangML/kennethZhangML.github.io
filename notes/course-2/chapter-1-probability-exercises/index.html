<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chapter 1 - Probability Exercises | Kenneth Zhang </title> <meta name="author" content="Kenneth Zhang"> <meta name="description" content="Exercises for Chapter 1 - General Probability Theory."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kennethzhangml.github.io/notes/course-2/chapter-1-probability-exercises/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kenneth</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Chapter 1 - Probability Exercises</h1> <p class="post-description">Exercises for Chapter 1 - General Probability Theory.</p> </header> <article> <p><strong>Exercise 1.1</strong></p> <ol> <li>if $A \in F, B \in F, A \subset B$ then $\mathbb{P}(A) \le \mathbb{P}(B)$</li> </ol> <p>Express $B$ as a union of two disjoint sets where: \(B = A \cup (B \backslash A) \text{ where } A \cap (B \backslash A) = \emptyset\) Notice that $B \backslash A$ is also in $F$ so itâ€™s $F$-measurable, so, by countable additivity: \(\mathbb{P}(A) = \mathbb{P}(A) + \mathbb{P}(B \backslash A)\) Since the probability is non-negative, we can say that: \(\mathbb{P}(B \backslash A) \ge 0 \implies \mathbb{P}(A) \le \mathbb{P}(B)\) So, the result is proven.</p> <ol> <li>If $A \in \mathcal{F}$ and ${A_n}<em>{n = 1}^\infty$ is a sequence of sets in $\mathcal{F}$ with $\lim</em>{n \rightarrow \infty} \mathbb{P}(A_n) = 0$ and $A \subset A_n$ for every $n$, then $\mathbb{P}(A) = 0$.</li> </ol> <p>Since $A \subset A_n$ for all $n$, we apply the monotonicity of probability, which tells us: \(\mathbb{P}(A) \le \mathbb{P}(A_n) = 0, \quad \forall n\) when we take the limit as $n \rightarrow \infty$ we obtain, \(\mathbb{P}(A) \le \lim_{n \rightarrow \infty} \mathbb{P}(A_n) = 0\) and, since probability measures are always non-negative, we get: \(\mathbb{P}(A) = 0\) Thus, the result is proven.</p> <p><strong>Exercise 1.2</strong> (i) Each sequence $\omega \in A$ is uniquely determined by its odd-indexed elements, since the even-indexed elements are constrained to match the preceding ones. That is, if we choose $\omega_, \omega_3, \omega_5, \dots$ freely, then we have that $\omega_2 = \omega_1, \omega_4 = \omega_3, \dots$. Therefore, we have that specifying a sequence in $A$ reduces to choosing an infinite sequence of independent coin flips for the odd positions.</p> <p>The number of choices for the odd-indexed elements follows the same structure as the full infinite coin-toss space $\Omega_\infty$ except it only depends on half the positions. The space of all infinite sequences of independent fair coin flips is well known to have the cardinality of the power set of natural numbers, which is uncountably infinite (same cardinality as $2^N$ or $\mathbb{R}$.)</p> <p>Since choosing the odd-indexed elements is still an independent process among an infinite set of positions, $A$ must also be uncountable.</p> <p>Thus, $A$ is uncountably infinite.</p> <p>(ii) Each sequence in $\Omega_\infty$ is generated by an independent sequence of coin tosses, where the probability of any specific sequence occurring to be $p^k (1 - p)^{n - k}$ where $k$ and $n - k$ are the counts of heads and tails, respectively, among the infinite tosses. This means that any particular sequence has a probability of exactly zero.</p> <p>The key observation is that $A$ is highly structured subset of $\Omega_\infty$ containing only those sequences where every even-indexed coin flip must match the preceding odd-indexed coin flip. This introduces a strong dependence structure, reducing the effective degrees of freedom. Specifically, rather than choosing each of the infinitely many tosses freely, we only choose half of them freely $(\omega_1, \omega_3, \omega_5, \dots)$ and the rest are fully-determined.</p> <p>The probability of selecting a sequence from this subset if analogous to picking from a lower-dimensional subspace in a continuous probability measure. Since the probability measure on $\Omega_\infty$ is a product measure, and since $A$ is effectively a zero-volume subset (infinite constraints reduce the measure) we conclude: \(\mathbb{P}(A) = 0\) Thus the probability of the event $A$ occurring is zero when $0 &lt; p &lt; 1$.</p> <p><strong>Exercise 1.3</strong> We show that the set function $\mathbb{P}$ defined on subsets of $[0, 1]$ by the problem satisfies the properties 1.1.3 to 1.1.5,</p> <ol> <li>Non-negativity is satisfied since $\mathbb{P}(A)$ is either $0$ or $\infty$, so it is always non-negative</li> <li>The empty set $\emptyset$ is finite, so $\mathbb{P}(\emptyset) = 0$</li> <li>If $A, B$ are disjoint, then if both are finite we have that $\mathbb{P}(A \cup B) = 0 = \mathbb{P}(A) + \mathbb{P}(B)$, otherwise, if either is finite then the union between $A$ and $B$ is infinite, so $\mathbb{P}(A \cup B) = \infty$ which matches $\mathbb{P}(A) + \mathbb{P}(B)$ We can show that $\mathbb{P}$ does not satisfy countable additivity. Countable additivity states that if $A_1, A_2, \dots$ are disjoint sets, then: \(\mathbb{P}\left(\cup_{n = 1}^\infty A_n \right) = \sum_{n = 1}^\infty \mathbb{P}(A_n)\) Consider the case where $A_n = {x_n }$ are singleton sets for some distinct points $x_n \in [0, 1]$ <ul> <li>each $A_n$ is finite so $\mathbb{P}(A_n) = 0$</li> <li>Thus, $\sum_{n = 1}^\infty \mathbb{P}(A_n) = \sum_{n = 1}^\infty 0 = 0$</li> <li>However, the union of $A_n$ from $n$ to $\infty$ is ${x_1, x_2, x_3, \dots}$ is an infinite set, so: \(\mathbb{P} \left(\cup_{n = 1}^\infty A_n \right) = \infty\) This contradicts countable additivity because $\infty \neq 0$. Thus, $\mathbb{P}$ does not satisfy countable additivity.</li> </ul> </li> </ol> <p><strong>Exercise 1.4</strong> (i) Define the sequence of independent fair coin tosses $\omega = (\omega_1, \omega_2, \dots)$, where each toss takes values in ${H, T}$ with probability $p(H) = p(T) = \frac{1}{2}$. We construct a standard normal random variable $Z$ using the following method:</p> <ol> <li>Represent each sequence $\omega$ as an infinite binary sequence: \(X_i = \begin{cases} 1, &amp; \text{if } \omega_i = H, \\ -1, &amp; \text{if } \omega_i = T. \end{cases}\) where ${X_i}_{i=1}^{\infty}$ are i.i.d. Rademacher random variables with mean 0 and variance 1.</li> <li>Define the random variable: \(Z = \sum_{i=1}^{\infty} \frac{X_i}{2^{i/2}}.\) This sum converges almost surely and follows a standard normal distribution by the central limit theorem and properties of infinite Rademacher series. Thus, $Z$ is a standard normal random variable constructed from the infinite coin tosses.</li> </ol> <p>(ii) To approximate $Z$ using a sequence of finite coin tosses, define the sequence of partial sums: \(Z_n = \sum_{i=1}^{n} \frac{X_i}{2^{i/2}}.\) Each $Z_n$ depends only on the first $n$ coin tosses and is thus an approximation of $Z$. Since the remainder term \(R_n = \sum_{i=n+1}^{\infty} \frac{X_i}{2^{i/2}}\) tends to zero as $n \to \infty$, we have: \(\lim_{n \to \infty} Z_n = Z.\) This provides a way to approximate the standard normal variable using a finite number of coin tosses, which is useful for <strong>Monte Carlo simulations</strong>.</p> <p><strong>Exercise 1.5</strong> \(\begin{align*} \mathbb{E}[X] &amp;= \int_{\Omega} X(\omega) d\mathbb{P}(\omega) &amp;&amp; \text{(Definition of expectation)} \\ &amp;= \int_{\Omega} \int_0^\infty \mathbb{I}_{[0, X(\omega))}(x) dx d\mathbb{P}(\omega) &amp;&amp; \text{(Rewriting $X(\omega)$ as an integral)} \\ &amp;= \int_0^\infty \int_{\Omega} \mathbb{I}_{[0, X(\omega))}(x) d\mathbb{P}(\omega) dx &amp;&amp; \text{(Fubiniâ€™s theorem to swap integration order)} \\ &amp;= \int_0^\infty \mathbb{P}(X &gt; x) dx &amp;&amp; \text{(The inner integral gives $\mathbb{P}(X &gt; x)$)} \\ &amp;= \int_0^\infty (1 - F(x)) dx. &amp;&amp; \text{(Using $F(x) = \mathbb{P}(X \leq x)$)} \end{align*}\) <strong>Exercise 1.6</strong> (i) We verify that \(\mathbb{E}[e^{uX}] = e^{u\mu + \frac{1}{2} u^2 \sigma^2}.\) The expectation is computed as: \(\begin{align*} \mathbb{E}[e^{uX}] &amp;= \int_{-\infty}^{\infty} e^{ux} f(x) dx \\ &amp;= \int_{-\infty}^{\infty} e^{ux} \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx \\ &amp;= \frac{1}{\sigma \sqrt{2\pi}} \int_{-\infty}^{\infty} e^{ux - \frac{(x-\mu)^2}{2\sigma^2}} dx. \end{align*}\) Completing the square in the exponent: \(\begin{align*} ux - \frac{(x-\mu)^2}{2\sigma^2} &amp;= -\frac{1}{2\sigma^2} \left( (x-\mu)^2 - 2u\sigma^2 x \right) \\ &amp;= -\frac{1}{2\sigma^2} \left( (x - \mu - u\sigma^2)^2 - u^2\sigma^4 \right) \\ &amp;= -\frac{(x - \mu - u\sigma^2)^2}{2\sigma^2} + \frac{u^2\sigma^2}{2}. \end{align*}\) Thus, the integral becomes: \(\begin{align*} \mathbb{E}[e^{uX}] &amp;= \frac{1}{\sigma \sqrt{2\pi}} e^{\frac{1}{2} u^2 \sigma^2} \int_{-\infty}^{\infty} e^{-\frac{(x - \mu - u\sigma^2)^2}{2\sigma^2}} dx. \end{align*}\) Since the remaining integral is the total probability mass of a normal distribution, it evaluates to $\sigma \sqrt{2\pi}$, giving: \(\begin{align*} \mathbb{E}[e^{uX}] &amp;= e^{u\mu + \frac{1}{2} u^2 \sigma^2}. \end{align*}\) (ii) Jensenâ€™s inequality states that for a convex function $\varphi$, \(\mathbb{E}[\varphi(X)] \geq \varphi(\mathbb{E}[X]).\) Since $\varphi(x) = e^{ux}$ is convex (as its second derivative is positive), we apply Jensenâ€™s inequality: \(\mathbb{E}[e^{uX}] \geq e^{u\mathbb{E}[X]} = e^{u\mu}.\) From (i), we already showed that: \(\mathbb{E}[e^{uX}] = e^{u\mu + \frac{1}{2} u^2 \sigma^2}.\) Since $\frac{1}{2} u^2 \sigma^2 \geq 0$, it follows that: \(e^{u\mu + \frac{1}{2} u^2 \sigma^2} \geq e^{u\mu}.\) Thus, Jensenâ€™s inequality holds as expected.</p> <p><strong>Exercise 1.7</strong> (i) We determine the pointwise limit of $f_n(x)$ as $n \to \infty$: \(f_n(x) = \frac{1}{\sqrt{2n\pi}} e^{-x^2 / 2n}.\) For fixed $x$, as $n \to \infty$, the exponent $-x^2 / 2n \to 0$, so $e^{-x^2 / 2n} \to 1$. Thus, \(f_n(x) \to \lim_{n \to \infty} \frac{1}{\sqrt{2n\pi}} = 0.\) Hence, the limiting function is $f(x) = 0$ for all $x \in \mathbb{R}$.</p> <p>(ii) The integral of $f_n(x)$ over $\mathbb{R}$ is: \(\int_{-\infty}^{\infty} f_n(x) dx = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2n\pi}} e^{-x^2 / 2n} dx.\) By a standard Gaussian integral result, this evaluates to 1 for all $n$, so: \(\lim_{n \to \infty} \int_{-\infty}^{\infty} f_n(x) dx = 1.\) (iii) Since $f_n(x) \to 0$ pointwise, we integrate the limit: \(\int_{-\infty}^{\infty} f(x) dx = \int_{-\infty}^{\infty} 0 \,dx = 0.\) Thus, we see: \(\lim_{n \to \infty} \int_{-\infty}^{\infty} f_n(x) dx \neq \int_{-\infty}^{\infty} f(x) dx.\) This does not contradict the Monotone Convergence Theorem (MCT) because MCT requires that $f_n(x)$ be increasing, but here $f_n(x)$ decreases to 0 for all $x$. Instead, this is an example where pointwise convergence does not imply convergence under the integral.</p> <p><strong>Exercise 1.8</strong> (i) We use the Dominated Convergence Theorem (DCT) to show that \(\lim_{n \to \infty} \mathbb{E}[Y_n] = \mathbb{E} \left[ \lim_{n \to \infty} Y_n \right] = \mathbb{E}[X e^{tX}].\) From equation (1.9.1), we rewrite $Y_n$ as \(Y_n = \frac{e^{tX} - e^{s_n X}}{t - s_n} = X e^{\theta(\omega) X},\) where $\theta(\omega)$ lies between $t$ and $s_n$. Since $e^{\theta X}$ is bounded by $e^{tX} + e^{s_n X}$, we obtain \(|Y_n| \leq |X| (e^{tX} + e^{s_n X}).\) Since we assume $\mathbb{E}[|X| e^{tX}] &lt; \infty$ for all $t$, the function $|X| e^{tX}$ is integrable. Thus, by the Dominated Convergence Theorem, \(\lim_{n \to \infty} \mathbb{E}[Y_n] = \mathbb{E} \left[ \lim_{n \to \infty} Y_n \right] = \mathbb{E}[X e^{tX}].\) This proves that $\varphiâ€™(t) = \mathbb{E}[X e^{tX}]$.</p> <p>(ii) Suppose $X$ can take both positive and negative values and satisfies \(\mathbb{E}[e^{tX}] &lt; \infty, \quad \mathbb{E}[|X| e^{tX}] &lt; \infty, \quad \forall t \in \mathbb{R}.\) We decompose $X$ into positive and negative parts as \(X = X^+ - X^-,\) where $X^+ = \max(X, 0)$ and $X^- = \max(-X, 0)$. Then, applying linearity, \(\varphi(t) = \mathbb{E}[e^{tX}] = \mathbb{E}[e^{tX^+} e^{-tX^-}].\) Differentiating, \(\varphi'(t) = \mathbb{E}[(X^+ - X^-) e^{tX}] = \mathbb{E}[X e^{tX}].\) Thus, the result holds for general $X$.</p> <p><strong>Exercise 1.9</strong> We want to show that if $X$ is independent of $A$, then for every nonnegative, Borel-measurable function $g$, \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \mathbb{P}(A) \cdot \mathbb{E}[g(X)].\) Consider the indicator function $\mathbb{I}_B(x)$ for any Borel set $B \subset \mathbb{R}$. From the given independence condition, \(\int_A \mathbb{I}_B(X(\omega)) d\mathbb{P}(\omega) = \ mathbb{P}(A) \cdot \mathbb{P}(X \in B).\) Now, let $g(x)$ be a simple function of the form \(g(x) = \sum_{i=1}^{n} c_i \mathbb{I}_{B_i}(x),\) where $c_i \geq 0$ and $B_i$ are disjoint Borel sets. Then, \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \sum_{i=1}^{n} c_i \int_A \mathbb{I}_{B_i}(X(\omega)) d\mathbb{P}(\omega).\) By the independence property, \(\int_A \mathbb{I}_{B_i}(X(\omega)) d\mathbb{P}(\omega) = \mathbb{P}(A) \cdot \mathbb{P}(X \in B_i).\) Thus, \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \sum_{i=1}^{n} c_i \mathbb{P}(A) \mathbb{P}(X \in B_i) = \mathbb{P}(A) \sum_{i=1}^{n} c_i \mathbb{P}(X \in B_i).\) Since \(\sum_{i=1}^{n} c_i \mathbb{P}(X \in B_i) = \mathbb{E}[g(X)],\) we obtain \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \mathbb{P}(A) \mathbb{E}[g(X)].\) For a general nonnegative Borel-measurable function $g$, we approximate it by an increasing sequence of simple functions $g_n$ such that $g_n \uparrow g$. By the Monotone Convergence Theorem, \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \lim_{n \to \infty} \int_A g_n(X(\omega)) d\mathbb{P}(\omega).\) Since the result holds for each $g_n$, taking limits gives \(\int_A g(X(\omega)) d\mathbb{P}(\omega) = \mathbb{P}(A) \mathbb{E}[g(X)].\) Thus, the result is proven.</p> <p><strong>Exercise 1.10</strong> (i) We show that $\tilde{\mathbb{P}}$ is a probability measure. By definition, \(\tilde{\mathbb{P}}(A) = \int_A Z(\omega) d\mathbb{P}(\omega).\) To verify that $\tilde{\mathbb{P}}$ is a probability measure, we check:</p> <ol> <li> <strong>Non-negativity</strong>: Since $Z(\omega) \geq 0$ for all $\omega$, we have $\tilde{\mathbb{P}}(A) \geq 0$ for all measurable sets $A$.</li> <li> <p><strong>Normalization</strong>: The total measure is \(\tilde{\mathbb{P}}([0,1]) = \int_{0}^{1} Z(\omega) d\mathbb{P}(\omega).\) Splitting into two regions: \(\tilde{\mathbb{P}}([0,1]) = \int_0^{1/2} 0 \, d\mathbb{P}(\omega) + \int_{1/2}^{1} 2 \, d\mathbb{P}(\omega).\) Since $\mathbb{P}$ is the uniform Lebesgue measure, we get: \(\int_{1/2}^{1} 2 \cdot d\mathbb{P}(\omega) = 2 \times \frac{1}{2} = 1.\) So $\tilde{\mathbb{P}}([0,1]) = 1$.</p> </li> <li> <strong>Countable Additivity</strong>: If ${A_n}$ are disjoint measurable sets, then by linearity of the integral: \(\tilde{\mathbb{P}} \left(\bigcup_{n=1}^{\infty} A_n \right) = \int_{\bigcup A_n} Z(\omega) d\mathbb{P}(\omega) = \sum_{n=1}^{\infty} \int_{A_n} Z(\omega) d\mathbb{P}(\omega) = \sum_{n=1}^{\infty} \tilde{\mathbb{P}}(A_n).\) Thus, $\tilde{\mathbb{P}}$ is a probability measure.</li> </ol> <p>(ii) If $\mathbb{P}(A) = 0$, then \(\tilde{\mathbb{P}}(A) = \int_A Z(\omega) d\mathbb{P}(\omega).\) Since the integral is taken over a set of measure zero, we obtain $\tilde{\mathbb{P}}(A) = 0$. This confirms that $\tilde{\mathbb{P}}$ is absolutely continuous with respect to $\mathbb{P}$.</p> <p>(iii) We construct a set $A$ for which $\tilde{\mathbb{P}}(A) = 0$ but $\mathbb{P}(A) &gt; 0$. Take \(A = [0,1/2).\) Then, \(\tilde{\mathbb{P}}(A) = \int_{0}^{1/2} Z(\omega) d\mathbb{P}(\omega) = \int_{0}^{1/2} 0 \cdot d\mathbb{P}(\omega) = 0.\) However, under the Lebesgue measure, $\mathbb{P}(A) = 1/2 &gt; 0$. This shows that $\tilde{\mathbb{P}}$ and $\mathbb{P}$ are not equivalent.</p> <p><strong>Exercise 1.11</strong> We want to verify that under the probability measure $\tilde{\mathbb{P}}$, the moment-generating function of $Y = X + \theta$ is \(\tilde{\mathbb{E}}[e^{uY}] = e^{\frac{1}{2} u^2}.\) By definition of expectation under $\tilde{\mathbb{P}}$, \(\tilde{\mathbb{E}}[e^{uY}] = \int_{\Omega} e^{uY} Z(\omega) d\mathbb{P}(\omega).\) Substituting $Z(\omega) = e^{-\theta X - \frac{1}{2} \theta^2}$ and $Y = X + \theta$, \(\tilde{\mathbb{E}}[e^{uY}] = \int_{\Omega} e^{u(X + \theta)} e^{-\theta X - \frac{1}{2} \theta^2} d\mathbb{P}(\omega).\) Rewriting the exponent, \(\tilde{\mathbb{E}}[e^{uY}] = e^{u\theta - \frac{1}{2} \theta^2} \int_{\Omega} e^{(u - \theta)X} d\mathbb{P}(\omega).\) Using the moment-generating function of $X$ under $\mathbb{P}$, which is \(\mathbb{E}[e^{tX}] = e^{\frac{1}{2} t^2},\) we set $t = u - \theta$ to obtain \(\int_{\Omega} e^{(u - \theta)X} d\mathbb{P}(\omega) = e^{\frac{1}{2} (u - \theta)^2}.\) Thus, \(\tilde{\mathbb{E}}[e^{uY}] = e^{u\theta - \frac{1}{2} \theta^2} e^{\frac{1}{2} (u - \theta)^2}.\) Expanding the exponent, \(\frac{1}{2} (u - \theta)^2 = \frac{1}{2} (u^2 - 2u\theta + \theta^2),\)</p> <p>\(\tilde{\mathbb{E}}[e^{uY}] = e^{u\theta - \frac{1}{2} \theta^2} e^{\frac{1}{2} u^2 - u\theta + \frac{1}{2} \theta^2}.\) Canceling terms, \(\tilde{\mathbb{E}}[e^{uY}] = e^{\frac{1}{2} u^2}.\) Since this matches the moment-generating function of a standard normal variable, we conclude that $Y$ is standard normal under $\tilde{\mathbb{P}}$.</p> <p><strong>Exercise 1.12</strong> We need to show that $\hat{Z} = \frac{1}{Z}$ and that $\hat{\mathbb{P}} = \mathbb{P}$.</p> <p>From the problem setup, we have: \(Z = e^{-\theta X - \frac{1}{2} \theta^2}\) and the corresponding measure $\tilde{\mathbb{P}}$ defined by \(\tilde{\mathbb{P}}(A) = \int_A Z(\omega) d\mathbb{P}(\omega).\) Under $\tilde{\mathbb{P}}$, the random variable $Y = X + \theta$ is standard normal. Now, using the same reasoning in reverse, we define \(\hat{Z} = e^{\theta Y - \frac{1}{2} \theta^2}\) to construct the probability measure $\hat{\mathbb{P}}$ as \(\hat{\mathbb{P}}(A) = \int_A \hat{Z}(\omega) d\tilde{\mathbb{P}}(\omega).\) Substituting $Y = X + \theta$, we express $\hat{Z}$ in terms of $X$: \(\hat{Z} = e^{\theta (X + \theta) - \frac{1}{2} \theta^2} = e^{\theta X + \theta^2 - \frac{1}{2} \theta^2}.\) Simplifying the exponent, \(\hat{Z} = e^{\theta X + \frac{1}{2} \theta^2}.\) Comparing with $Z$, \(Z = e^{-\theta X - \frac{1}{2} \theta^2},\) we see that \(\hat{Z} = \frac{1}{Z}.\) Thus, we check that $\hat{\mathbb{P}}$ coincides with $\mathbb{P}$: \(\hat{\mathbb{P}}(A) = \int_A \hat{Z} d\tilde{\mathbb{P}} = \int_A \frac{1}{Z} Z d\mathbb{P} = \int_A d\mathbb{P} = \mathbb{P}(A).\) Since this holds for all measurable sets $A$, we conclude that $\hat{\mathbb{P}} = \mathbb{P}$.</p> <p><strong>Exercise 1.13</strong> (i) The probability that $X$ belongs to the small interval $B(x, \epsilon) = [x - \frac{\epsilon}{2}, x + \frac{\epsilon}{2}]$ is given by \(\mathbb{P}(X \in B(x, \epsilon)) = \int_{x - \epsilon/2}^{x + \epsilon/2} \frac{1}{\sqrt{2\pi}} e^{-t^2/2} dt.\) For small $\epsilon$, we approximate this using the density function at $x$: \(\mathbb{P}(X \in B(x, \epsilon)) \approx \epsilon \cdot f_X(x) = \epsilon \cdot \frac{1}{\sqrt{2\pi}} e^{-x^2/2}.\) Dividing by $\epsilon$, we obtain: \(\frac{1}{\epsilon} \mathbb{P}(X \in B(x, \epsilon)) \approx \frac{1}{\sqrt{2\pi}} e^{-X^2(\bar{\omega})/2}.\) (ii) Similarly, since $Y$ is standard normal under $\tilde{\mathbb{P}}$, the probability that $Y$ belongs to $B(y, \epsilon) = [y - \frac{\epsilon}{2}, y + \frac{\epsilon}{2}]$ is given by: \(\mathbb{P}(Y \in B(y, \epsilon)) \approx \epsilon \cdot f_Y(y) = \epsilon \cdot \frac{1}{\sqrt{2\pi}} e^{-y^2/2}.\) Dividing by $\epsilon$, we obtain: \(\frac{1}{\epsilon} \mathbb{P}(Y \in B(y, \epsilon)) \approx \frac{1}{\sqrt{2\pi}} e^{-Y^2(\bar{\omega})/2}.\) (iii) The set $A(\bar{\omega}, \epsilon)$ is defined as a small neighbourhood of $\bar{\omega}$ such that \(\mathbb{P}(X \in B(x, \epsilon)) = \mathbb{P}(Y \in B(y, \epsilon)).\) Since $Y = X + \theta$, the intervals $B(x, \epsilon)$ and $B(y, \epsilon)$ are the same translated by $\theta$. Thus, the sets ${X \in B(x, \epsilon)}$ and ${Y \in B(y, \epsilon)}$ are identical.</p> <p>(iv) Using the approximation for small $A$, we write \(\frac{\tilde{\mathbb{P}}(A)}{\mathbb{P}(A)} \approx \frac{\mathbb{P}(Y \in B(y, \epsilon))}{\mathbb{P}(X \in B(x, \epsilon))}.\) Substituting the expressions from (i) and (ii), \(\frac{\tilde{\mathbb{P}}(A)}{\mathbb{P}(A)} \approx \frac{\frac{1}{\sqrt{2\pi}} e^{-Y^2(\bar{\omega})/2}}{\frac{1}{\sqrt{2\pi}} e^{-X^2(\bar{\omega})/2}} = e^{-Y^2(\bar{\omega})/2 + X^2(\bar{\omega})/2}.\) Since $Y = X + \theta$, we substitute $Y^2 = (X+\theta)^2$: \(e^{-\frac{(X+\theta)^2}{2} + \frac{X^2}{2}}.\) Expanding the exponent, \(-\frac{X^2 + 2\theta X + \theta^2}{2} + \frac{X^2}{2} = -\theta X - \frac{1}{2} \theta^2.\) Thus, \(\frac{\tilde{\mathbb{P}}(A)}{\mathbb{P}(A)} \approx e^{-\theta X(\bar{\omega}) - \frac{1}{2} \theta^2}.\) This matches the expression for $Z(\bar{\omega})$ in Example 1.6.6.</p> <p><strong>Exercise 1.14</strong> (i) We verify that $\tilde{\mathbb{P}}$ is a probability measure by checking that $\tilde{\mathbb{P}}(\Omega) = 1$. By definition, \(\tilde{\mathbb{P}}(\Omega) = \int_{\Omega} Z d\mathbb{P}.\) Substituting $Z = \frac{\tilde{\lambda}}{\lambda} e^{-(\tilde{\lambda} - \lambda)X}$, we compute: \(\tilde{\mathbb{P}}(\Omega) = \int_{0}^{\infty} \frac{\tilde{\lambda}}{\lambda} e^{-(\tilde{\lambda} - \lambda)x} \lambda e^{-\lambda x} dx.\) Rewriting the integral, \(\tilde{\mathbb{P}}(\Omega) = \frac{\tilde{\lambda}}{\lambda} \lambda \int_{0}^{\infty} e^{-\tilde{\lambda}x} dx.\) Since the integral of an exponential density is: \(\int_{0}^{\infty} e^{-\tilde{\lambda} x} dx = \frac{1}{\tilde{\lambda}},\) we obtain: \(\tilde{\mathbb{P}}(\Omega) = \frac{\tilde{\lambda}}{\lambda} \lambda \frac{1}{\tilde{\lambda}} = 1.\) Thus, $\tilde{\mathbb{P}}$ is a valid probability measure.</p> <p>(ii) We compute the cumulative distribution function under $\tilde{\mathbb{P}}$: \(\tilde{\mathbb{P}}(X \leq a) = \int_0^a Z d\mathbb{P}.\) Substituting $Z$ and $\mathbb{P}$, \(\tilde{\mathbb{P}}(X \leq a) = \int_0^a \frac{\tilde{\lambda}}{\lambda} e^{-(\tilde{\lambda} - \lambda)x} \lambda e^{-\lambda x} dx.\) Rewriting the exponent, \(\tilde{\mathbb{P}}(X \leq a) = \frac{\tilde{\lambda}}{\lambda} \lambda \int_0^a e^{-\tilde{\lambda} x} dx.\) Evaluating the integral, \(\int_0^a e^{-\tilde{\lambda} x} dx = \frac{1 - e^{-\tilde{\lambda} a}}{\tilde{\lambda}}.\) Thus, \(\tilde{\mathbb{P}}(X \leq a) = \frac{\tilde{\lambda}}{\lambda} \lambda \frac{1 - e^{-\tilde{\lambda} a}}{\tilde{\lambda}}.\) Simplifying, \(\tilde{\mathbb{P}}(X \leq a) = 1 - e^{-\tilde{\lambda} a}.\) This is the cumulative distribution function of an exponential distribution with rate $\tilde{\lambda}$, confirming that $X$ is exponentially distributed with parameter $\tilde{\lambda}$ under $\tilde{\mathbb{P}}$.</p> <p><strong>Exercise 1.5</strong> (i) We first show that $Z$ is nonnegative and that $\mathbb{E}[Z] = 1$. Since $h(y) \geq 0$ for all $y$, $gâ€™(X) &gt; 0$ (since $g$ is strictly increasing), and $f(X) &gt; 0$ (by assumption), we conclude that \(Z = \frac{h(g(X)) g'(X)}{f(X)} \geq 0.\) Thus, $Z$ is nonnegative. To verify that $\mathbb{E}[Z] = 1$, we compute \(\mathbb{E}[Z] = \int_{-\infty}^{\infty} Z(x) f(x) dx.\) Substituting $Z(x)$, \(\mathbb{E}[Z] = \int_{-\infty}^{\infty} \frac{h(g(x)) g'(x)}{f(x)} f(x) dx.\) Simplifying, \(\mathbb{E}[Z] = \int_{-\infty}^{\infty} h(g(x)) g'(x) dx.\) Making the substitution $y = g(x)$ so that $dy = gâ€™(x)dx$, we rewrite the integral as \(\mathbb{E}[Z] = \int_{-\infty}^{\infty} h(y) dy.\) Since $h(y)$ is a valid density function, we have \(\int_{-\infty}^{\infty} h(y) dy = 1.\) Thus, $\mathbb{E}[Z] = 1$, verifying that $\tilde{\mathbb{P}}$ is a probability measure.</p> <p>(ii) We show that $Y$ has density $h(y)$ under $\tilde{\mathbb{P}}$. The probability density function of $Y$ under $\tilde{\mathbb{P}}$ is given by \(\tilde{f}_Y(y) = \frac{d}{dy} \tilde{\mathbb{P}}(Y \leq y).\) By the definition of $\tilde{\mathbb{P}}$, \(\tilde{\mathbb{P}}(Y \leq y) = \tilde{\mathbb{P}}(g(X) \leq y) = \tilde{\mathbb{P}}(X \leq g^{-1}(y)).\) Using the change of measure formula, \(\tilde{\mathbb{P}}(X \leq g^{-1}(y)) = \int_{-\infty}^{g^{-1}(y)} Z(x) f(x) dx.\) Substituting $Z(x)$, \(\tilde{\mathbb{P}}(X \leq g^{-1}(y)) = \int_{-\infty}^{g^{-1}(y)} h(g(x)) g'(x) dx.\) Changing variables with $y = g(x)$ so that $dy = gâ€™(x)dx$, we obtain \(\tilde{\mathbb{P}}(X \leq g^{-1}(y)) = \int_{-\infty}^{y} h(y) dy.\) Differentiating both sides with respect to $y$, we conclude \(\tilde{f}_Y(y) = h(y).\) Thus, under $\tilde{\mathbb{P}}$, $Y$ has density $h(y)$.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Kenneth Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"},svg:{scale:1.1,minScale:.8,matchFontHeight:!1}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-notes",title:"notes",description:"Personal-study notes for quant-finance related learning materials",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"notes-stochastic-calculus-for-finance-i",title:"Stochastic Calculus for Finance I",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance I",section:"Notes",handler:()=>{window.location.href="/notes/course-1/"}},{id:"notes-stochastic-calculus-for-finance-ii",title:"Stochastic Calculus for Finance II",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance II",section:"Notes",handler:()=>{window.location.href="/notes/course-2/"}},{id:"notes-chapter-1-no-arbitrage-pricing-model",title:"Chapter 1 - No-Arbitrage Pricing Model",description:"Notes on the No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-no-arbitrage/"}},{id:"notes-chapter-1-exercises",title:"Chapter 1 Exercises",description:"Exercises for Chapter 1 - No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-exercises/"}},{id:"notes-chapter-2-exercises",title:"Chapter 2 Exercises",description:"Exercises for Chapter 2 - Probability Theory on Coin Toss Space.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-exercises/"}},{id:"notes-chapter-2-probability-theory-on-coin-toss-space",title:"Chapter 2 - Probability Theory on Coin Toss Space",description:"Notes on probability theory applied to coin toss spaces.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-probability/"}},{id:"notes-chapter-3-state-prices",title:"Chapter 3 - State Prices",description:"Notes on State Prices in financial models.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-state-prices/"}},{id:"notes-chapter-3-exercises",title:"Chapter 3 Exercises",description:"Exercises for Chapter 3 - State Prices.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-exercises/"}},{id:"notes-chapter-4-american-derivative-securities",title:"Chapter 4 - American Derivative Securities",description:"Notes on American derivative securities and their valuation.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-4-american-derivatives/"}},{id:"notes-chapter-1-general-probability-theory",title:"Chapter 1 - General Probability Theory",description:"Notes on general probability theory and foundational concepts.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-general-probability/"}},{id:"notes-chapter-1-probability-exercises",title:"Chapter 1 - Probability Exercises",description:"Exercises for Chapter 1 - General Probability Theory.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-probability-exercises/"}},{id:"notes-chapter-2-information-exercises",title:"Chapter 2 - Information Exercises",description:"Exercises for Chapter 2 - Information and Conditioning.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-exercises/"}},{id:"notes-chapter-2-information-and-conditioning",title:"Chapter 2 - Information and Conditioning",description:"Notes on information theory and conditional probability.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-conditioning/"}},{id:"notes-chapter-3-brownian-motion-exercises",title:"Chapter 3 - Brownian Motion Exercises",description:"Exercises for Chapter 3 - Brownian Motion.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion-exercises/"}},{id:"notes-chapter-3-brownian-motion",title:"Chapter 3 - Brownian Motion",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion/"}},{id:"notes-chapter-4-stochastic-calculus-exercises",title:"Chapter 4 - Stochastic Calculus Exercises",description:"Notes on Stochastic Calculus and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-stochastic-calculus-exercises/"}},{id:"notes-chapter-4-stochastic-calculus",title:"Chapter 4 - Stochastic Calculus",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-stochastic-calculus/"}},{id:"notes-chapter-4-partial-differential-equations-exercises",title:"Chapter 4 - Partial Differential Equations Exercises",description:"Notes on Partial Differential Equations and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-PDEs-exercises/"}},{id:"notes-chapter-4-partial-differential-equations",title:"Chapter 4 - Partial Differential Equations",description:"Notes on Partial Differential Equations and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-4-PDEs/"}},{id:"projects-the-lagging-indicator-chronicles-a-tale-of-policies-playing-catch-up",title:"The Lagging Indicator Chronicles \u2013 A Tale of Policies Playing Catch-Up",description:"Lag time between state-level policy interventions and change points in COVID-19 outcomes in the United States. Read more at ![this article](https://www.cell.com/patterns/fulltext/S2666-3899(21)00149-5).",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-pm2-5-and-the-great-regulatory-vanishing-act-when-pollution-took-a-free-pass",title:"PM2.5 and the Great Regulatory Vanishing Act - When Pollution Took a Free...",description:"An introduction to the statistical models used to assess the impact of EPA rollbacks on air quality in California. https://enveurope.springeropen.com/articles/10.1186/s12302-021-00489-9",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> </body> </html>
<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chapter 2 - Probability Theory on Coin Toss Space | Kenneth Zhang </title> <meta name="author" content="Kenneth Zhang"> <meta name="description" content="Notes on probability theory applied to coin toss spaces."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kennethzhangml.github.io/notes/course-1/chapter-2-probability/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kenneth</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Chapter 2 - Probability Theory on Coin Toss Space</h1> <p class="post-description">Notes on probability theory applied to coin toss spaces.</p> </header> <article> <h3 id="finite-probability-spaces">Finite Probability Spaces</h3> <p>A finite probability space is a mathematical model for situations where a random experiment has a finite number of possible outcomes. For instance, in the binomial model discussed earlier, a coin was tossed a finite number of times.</p> <p><strong>Definition</strong>: A finite probability space consists of two components: a sample space $\Omega$ and a probability measure $\mathbb{P}$. These are defined as follows:</p> <ul> <li> <strong>Sample Space</strong>: $\Omega$ is a non-empty finite set representing all possible outcomes of the experiment.</li> <li> <strong>Probability Measure</strong>: $\mathbb{P}$ is a function that assigns a value in $[0, 1]$ to each element $\omega \in \Omega$ such that:</li> </ul> \[\sum_{\omega \in \Omega} \mathbb{P}(\omega) = 1\] <p>An <strong>event</strong> is any subset of $\Omega$. The probability of an event $A \subseteq \Omega$ is defined as:</p> \[\mathbb{P}(A) = \sum_{\omega \in A} \mathbb{P}(\omega)\] <p>This setup models the behavior of random experiments. Specifically:</p> <ul> <li>$\mathbb{P}(\omega)$ is the probability of the outcome $\omega$.</li> <li>$\mathbb{P}(A)$ is the probability that the outcome falls within the subset $A$.</li> </ul> <p>If $\mathbb{P}(A) = 0$, the outcome is certain not to be in $A$. Conversely, if $\mathbb{P}(A) = 1$, the outcome is certain to be in $A$. Since every outcome must belong to $\Omega$, we have:</p> \[\mathbb{P}(\Omega) = 1\] <p>Even outcomes with zero probability can be included in $\Omega$, as they represent events that are theoretically possible but practically impossible.</p> <p><strong>Key Property:</strong> If $A$ and $B$ are disjoint subsets of $\Omega$, the probability of their union is given by:</p> \[\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\] <p><strong>Definition</strong>: Let $(\Omega, \mathbb{P})$ be a finite probability space. A random variable is a real-valued function defined on $\Omega$. (We sometimes also permit a random variable to take the values $+\infty$ and $-\infty$).</p> <p>In the example of modelling stock prices in the binomial tree, we have written the arguments of $S_0, S_1, S_2$ and $S_3$ as $\omega_1 \omega_2 \omega_3$ even through some of these random variables do not depend on all the coin tosses. In particular, $S_0$ is actually not random because it takes the value $4$, regardless of how the coin tosses turn out; such a random variable is sometimes called a degenerate random variable. We write the argument of a random variable as $\omega$ even when $\omega = \omega_1 \omega_2 \omega_3$. We shall use these two notations interchangeably. It is even more common to write random variables without any arguments.</p> <p>The distribution of a random variable is a specification of the probabilities that the random variable takes various values. A random variable is not a distribution, and a distribution is not a random variable.</p> <p>e.g., Toss a coin three times, so the set of possible outcomes is:</p> \[\Omega = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}\] <p>Define the random variables:</p> \[X = \text{Total number of heads},\quad Y = \text{Total number of tails}\] \[\begin{align*} X(HHH) = 3,\\ X(HHT) = X(HTH) = X(THH) = 2,\\ X(HTT) = X(THT) = X(TTH) = 1,\\ X(TTT) = 0\\ \\ Y(TTT) = 2,\\ Y(TTH) = Y(THT) = Y(HTT) = 2,\\ Y(THH) = Y(HTH) = Y(HHT) = 1,\\ Y(HHH) = 0 \end{align*}\] <p>Letâ€™s define a probability measure on $\Omega$:</p> \[\begin{align*} \widetilde{\mathbb{P}}(\omega \in \Omega; X(\omega) = 0) &amp;= \widetilde{\mathbb{P}}(\{TTT\}) = \frac{1}{8}, \\ \widetilde{\mathbb{P}}(\omega \in \Omega; X(\omega) = 1) &amp;= \widetilde{\mathbb{P}}(\{HTT, THT, TTH\}) = \frac{3}{8}, \\ \widetilde{\mathbb{P}}(\omega \in \Omega; X(\omega) = 2) &amp;= \widetilde{\mathbb{P}}(\{HHT, HTH, THH\}) = \frac{3}{8}, \\ \widetilde{\mathbb{P}}(\omega \in \Omega; X(\omega) = 3) &amp;= \widetilde{\mathbb{P}}(\{HHH\}) = \frac{1}{8}. \end{align*}\] <p>Or shorten the notation to $\tilde{\mathbb{P}}(X = j)$ which refers to the probability of a subset of $\Omega$, the set of elements $\omega$ for which $X(\omega) = j$. Under $\mathbb{P}$ the probability that $X$ takes values $0, 1, 2, 3$ are:</p> \[\begin{align*} \widetilde{\mathbb{P}}(X = 0) &amp;= \frac{1}{8}, &amp; \widetilde{\mathbb{P}}(X = 1) &amp;= \frac{3}{8}, \\ \widetilde{\mathbb{P}}(X = 2) &amp;= \frac{3}{8}, &amp; \widetilde{\mathbb{P}}(X = 3) &amp;= \frac{1}{8}. \end{align*}\] <p>where $X$ counts the number of heads in a given 3-toss sequence. We could also list the table of probabilities where $Y$ counts the number of tails:</p> \[\begin{align*} \widetilde{\mathbb{P}}(Y = 0) &amp;= \frac{1}{8}, &amp; \widetilde{\mathbb{P}}(Y = 1) &amp;= \frac{3}{8}, \\ \widetilde{\mathbb{P}}(Y = 2) &amp;= \frac{3}{8}, &amp; \widetilde{\mathbb{P}}(Y = 3) &amp;= \frac{1}{8}. \end{align*}\] <p>where $Y$ is the random variable that models the number of tails for a 3-toss sequence of coin tosses $\omega_1 \omega_2 \omega_3$.</p> <p><strong>Definition</strong>: Let $X$ be a random variable defined on a finite probability space $(\Omega, \mathbb{P})$. The expectation (or expected value) of $X$ is defined to be:</p> \[\mathbb{E}X = \sum_{\omega \in \Omega} X(\omega) \mathbb{P}(\omega)\] <p>When we compute the expectation using the risk-neutral probability measure $\tilde{\mathbb{P}}$, we use the notation:</p> \[\tilde{\mathbb{E}}X = \sum_{\omega \in \Omega} X(\omega) \tilde{\mathbb{P}}(\omega)\] <p>The variance of $X$ is:</p> \[\text{Var}(X) = \mathbb{E} \left[(X - \mathbb{E}X^2)\right]\] <p>Clearly, expectation is linear, since if $X$ and $Y$ are random variables and $c_1$ and $c_2$ are constants, we have that:</p> \[\mathbb{E}(c_1 X + c_2 Y) = c_1 \mathbb{E} X + c_2 \mathbb{E} Y\] <p>In particular, we have that $l(x) = ax + b$ is a linear function of a dummy variable $x$ ($a$ and $b$ are constants), then $\mathbb{E} [l(X)] = l(\mathbb{E} X)$. When dealing with convex functions, we have the following inequality.</p> <p><strong>Theorem: Jensenâ€™s Inequality</strong> Let $X$ be a random variable on a finite probability space, and let $\phi(x)$ be a convex function of a dummy variable $x$, then:</p> \[\mathbb{E} [\phi(X)] \ge \phi(\mathbb{E} X)\] <p><strong>Proof</strong>: We first argue that a convex function is the maximum of all linear functions that lie below it, i.e., for every $x \in \mathbb{R}$:</p> \[\phi(x) = \max{\{l(x): l \text{ is linear and } l(y) \le \phi(y) \text{ for all } y \in \mathbb{R} \} }\] <p>Since we only consider linear functions that lie below $\phi$, it is clear that:</p> \[\phi(x) \ge \max{\{l(x); l \text{ is linear and } l(y) \le \phi(y) \text{ for all } y \in \mathbb{R} \} }\] <p>On the other hand, let $x$ be an arbitrary point in $\mathbb{R}$. Because $\phi$ is convex, there is always a linear function $l$ that lies below $\phi$ and for which $\phi(x) = l(x)$ for this particular $x$. We call this a support line of $\phi$ at $x$: Therefore, we have that:</p> \[\phi(x) \le \max{\{l(x); l \text{ is linear and } l(y) \le \phi(y) \text{ for all } y \in \mathbb{R} \} }\] <p>which gives us:</p> \[\mathbb{E}[\phi(X)] \ge \mathbb{E}[l(X)] = l(\mathbb{E}X) \implies \mathbb{E}[\phi(X)] \ge \phi(\mathbb{E} X)\] <p>One consequence of Jensenâ€™s inequality is that:</p> \[\mathbb{E}[X^2] \ge (\mathbb{E}X)^2\] <h3 id="conditional-expectations">Conditional Expectations</h3> <p>We chose risk-neutral probabilities $\tilde{p}, \tilde{q}$ for our binomial model:</p> \[\tilde{p} = \frac{1 + r - d}{u - d},\quad \tilde{q} = \frac{u - 1 - r}{u - d}\] <p>We use can use these to check that:</p> \[\frac{\tilde{p}u + \tilde{q}d}{1 + r} = 1\] <p>Thus, for every time $n$ and sequence $\omega_1 \dots \omega_n$ of coin tosses:</p> \[S_n(\omega_1 \dots \omega_n) = \frac{1}{1 + r} \left[\tilde{p}S_{n + 1}(\omega_1 \dots \omega_n H) + \tilde{q} S_{n + 1}(\omega_1 \dots \omega_n T) \right]\] <p>Thus, we say that the stock price at time $n$ is the discounted weighted average of the two possible stock prices at time $n + 1$ where $\tilde{p}, \tilde{q}$ are the weights used in averaging. Moreover, we simplify:</p> \[\begin{align*} \tilde{\mathbb{E}}[S_{n + 1}] (\omega_1 \dots \omega_n) &amp;= \tilde{p} S_{n + 1} (\omega_1 \dots \omega_n H) + \tilde{q} S_{n + 1} (\omega_1 \dots \omega_n T)\\ \implies S_n &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}[S_{n + 1}] \end{align*}\] <p>where $\tilde{\mathbb{E}}<em>n [S</em>{n + 1}]$ is the conditional expectation of $S_{n + 1}$ based on the information at time $n$, where the conditional expectation can be regarded as an approximation of the value of $S_{n + 1}$ given the first $n$ coin tosses.</p> <p><strong>Definition</strong>: Let $n$ satisfy $1 \le n \le N$ and let $\omega_1 \dots \omega_n$ be given and for the moment, fixed. There are $2^{N - n}$ possible continuations of $\omega_{n + 1} \dots \omega_N$ of the sequence fixed $\omega_1 \dots \omega_n$. Let $# H(\omega_{n + 1} \dots \omega_N)$ be the number of heads in $\omega_{n + 1} \dots \omega_N$ and $# T(\omega_{n + 1} \dots \omega_N)$ be the number of tails in $\omega_{n + 1} \dots \omega_N$. Now, we define:</p> \[\tilde{\mathbb{E}}[X] (\omega_1 \dots \omega_n) = \sum_{\omega_{n + 1} \dots \omega_N} \tilde{p}^{\# H(\omega_{n + 1} \dots \omega_N)}\tilde{q}^{\# T(\omega_{n + 1} \dots \omega_N)} X(\omega_1 \dots \omega_n \omega_{n + 1} \dots \omega_N)\] <p>where $\tilde{\mathbb{E}}_n [X]$ is the conditional expectation of $X$ based on information at time $n$.</p> <p><strong>Definition</strong>: The two extreme cases of conditioning are $\tilde{\mathbb{E}}_0 [X]$, the conditional expectation of $X$ based on no information, which we define by:</p> \[\tilde{\mathbb{E}}_0 [X] = \tilde{\mathbb{E}} X\] <p>and $\tilde{\mathbb{E}}_N [X]$, the conditional expectation of $X$ based on knowledge of all $N$ coin tosses which we define by:</p> \[\tilde{\mathbb{E}}_N [X] = X\] <p><strong>Theorem: Fundamental Properties of Conditional Expectations</strong> Let $N$ be a positive integers and $X, Y$ be random variables depending on the first $N$ coin tosses. Let $0 \le n \le N$ be given. The following properties hold:</p> \[\begin{align*} (i) &amp; \quad \textit{Linearity of conditional expectations.} \text{ For all constants } c_1 \text{ and } c_2, \text{ we have:} \\ &amp; \mathbb{E}_n[c_1X + c_2Y] = c_1\mathbb{E}_n[X] + c_2\mathbb{E}_n[Y]. \\[1em] (ii) &amp; \quad \textit{Taking out what is known.} \text{ If } X \text{ actually depends only on the first } n \text{ coin tosses, then:} \\ &amp; \mathbb{E}_n[XY] = X \cdot \mathbb{E}_n[Y]. \\[1em] (iii) &amp; \quad \textit{Iterated conditioning.} \text{ If } 0 \leq n \leq m \leq N, \text{ then:} \\ &amp; \mathbb{E}_n\big[\mathbb{E}_m[X]\big] = \mathbb{E}_n[X]. \\ &amp; \text{In particular, } \mathbb{E}\big[\mathbb{E}_m[X]\big] = \mathbb{E}[X]. \\[1em] (iv) &amp; \quad \textit{Independence.} \text{ If } X \text{ depends only on tosses } n+1 \text{ through } N, \text{ then:} \\ &amp; \mathbb{E}_n[X] = \mathbb{E}[X]. \\[1em] (v) &amp; \quad \textit{Conditional Jensen's Inequality}. \text{If } \phi(x) \text{ is a convex function of the dummy } \\ &amp;\text{variable } x, \text{ then:}\\ &amp;\mathbb{E}_n [\phi(X)] \ge \phi(\mathbb{E}_n [X]) \end{align*}\] <p>e.g., Using $p = \frac{2}{3}, q = \frac{1}{3}$, we can express the Linearity of Conditional Expectations</p> \[\begin{align*} \mathbb{E}_1[S_2](H) &amp;= \frac{2}{3} \cdot S_2(HH) + \frac{1}{3} \cdot S_2(HT) \\ &amp;= \frac{2}{3} \cdot 16 + \frac{1}{3} \cdot 4 \\ &amp;= 12. \\[1em] \mathbb{E}_1[S_3](H) &amp;= \frac{4}{9} \cdot S_3(HHH) + \frac{2}{9} \cdot S_3(HHT) + \frac{2}{9} \cdot S_3(HTH) + \frac{1}{9} \cdot S_3(HTT) \\ &amp;= \frac{4}{9} \cdot 32 + \frac{2}{9} \cdot 8 + \frac{2}{9} \cdot 8 + \frac{1}{9} \cdot 2 \\ &amp;= 18. \\[1em] \mathbb{E}_1[S_2 + S_3](H) &amp;= \frac{4}{9}(S_2(HH) + S_3(HHH)) + \frac{2}{9}(S_2(HT) + S_3(HHT)) \\ &amp;\quad + \frac{2}{9}(S_2(HT) + S_3(HTH)) + \frac{1}{9}(S_2(HT) + S_3(HTT)) \\ &amp;= \frac{4}{9}(16 + 32) + \frac{2}{9}(16 + 8) + \frac{2}{9}(4 + 8) + \frac{1}{9}(4 + 2) \\ &amp;= 30. \end{align*}\] \[\text{And consequently, } \mathbb{E}_1[S_2](H) + \mathbb{E}_1[S_3](H) = 12 + 18 = 30. \\[1em]\] <p>Similarly, we can show that:</p> \[\mathbb{E}[S_2 + S_3](H) = \frac{4}{9}(16 + 32) + \frac{2}{9} (16 + 8) + \frac{2}{9}(4 + 8) + \frac{1}{9}(4 + 2) = 30\] \[\tilde{\mathbb{E_1}}[S_2 + S_3](T) = 7.50 = \mathbb{E}_1 [S_2](T) + \mathbb{E}_1 [S_3](T) \implies \mathbb{E}[S_2 + S_3] = \mathbb{E}_1 [S_2] + \mathbb{E}_1[S_3]\] <p>e.g., Iterated Conditioning. We first estimate $S_3$ based on the information at time 2:</p> \[\begin{align*} \mathbb{E}_2[S_3](HH) &amp;= \frac{2}{3} \cdot 32 + \frac{1}{3} \cdot 8 = 24, \\ \mathbb{E}_2[S_3](HT) &amp;= \frac{2}{3} \cdot 8 + \frac{1}{3} \cdot 2 = 6, \\ \mathbb{E}_2[S_3](TH) &amp;= \frac{2}{3} \cdot 8 + \frac{1}{3} \cdot 2 = 6, \\ \mathbb{E}_2[S_3](TT) &amp;= \frac{2}{3} \cdot 2 + \frac{1}{3} \cdot \frac{1}{2} = 1.50. \end{align*}\] <p>And now we can estimate, based on the information at time 1:</p> \[\begin{align*} \mathbb{E}_1\big[\mathbb{E}_2[S_3]\big](H) &amp;= \frac{2}{3} \cdot \mathbb{E}_2[S_3](HH) + \frac{1}{3} \cdot \mathbb{E}_2[S_3](HT) \\ &amp;= \frac{2}{3} \cdot 24 + \frac{1}{3} \cdot 6 = 18, \\ \mathbb{E}_1\big[\mathbb{E}_2[S_3]\big](T) &amp;= \frac{2}{3} \cdot \mathbb{E}_2[S_3](TH) + \frac{1}{3} \cdot \mathbb{E}_2[S_3](TT) \\ &amp;= \frac{2}{3} \cdot 6 + \frac{1}{3} \cdot 1.50 = 4.50. \end{align*}\] <p>The estimate of the estimate is an average of averages, and it is not surprising that we can get the same result by a more comprehensive averaging. This more comprehensive averaging occurs when we estimate $S_3$ directly based on the information at time 1:</p> \[\begin{align*} \mathbb{E}_1[S_3](H) &amp;= \frac{4}{9} \cdot 32 + \frac{2}{9} \cdot 8 + \frac{2}{9} \cdot 8 + \frac{1}{9} \cdot 2 = 18, \\ \mathbb{E}_1[S_3](T) &amp;= \frac{4}{9} \cdot 8 + \frac{2}{9} \cdot 2 + \frac{2}{9} \cdot 2 + \frac{1}{9} \cdot \frac{1}{2} = 4.50. \end{align*}\] <p>e.g., Independence. The quotient $\frac{S_2}{S_1}$ takes either the value 2 or $\frac{1}{2}$ depending on whether the second coin toss results in head or tails, respectively. In particular, $\frac{S_2}{S_1}$ does not depend on the first coin toss. We complete:</p> \[\begin{align*} \mathbb{E}_1\left[\frac{S_2}{S_1}\right](H) &amp;= \frac{2}{3} \cdot \frac{S_2(HH)}{S_1(H)} + \frac{1}{3} \cdot \frac{S_2(HT)}{S_1(H)} \\ &amp;= \frac{2}{3} \cdot 2 + \frac{1}{3} \cdot \frac{1}{2} = \frac{3}{2}, \\ \mathbb{E}_1\left[\frac{S_2}{S_1}\right](T) &amp;= \frac{2}{3} \cdot \frac{S_2(TH)}{S_1(T)} + \frac{1}{3} \cdot \frac{S_2(TT)}{S_1(T)} \\ &amp;= \frac{2}{3} \cdot 2 + \frac{1}{3} \cdot \frac{1}{2} = \frac{3}{2}. \end{align*}\] <h3 id="martingales">Martingales</h3> \[\frac{S_n}{(1 + r)^n} = \tilde{\mathbb{E}}_n \left[\frac{S_{n + 1}}{(1 + r)^{n + 1}} \right]\] <p>expresses the fact that under the risk-neutral measure, for a stock that pays no dividend, the best estimate based on the information at time $n$ of the value of the discounted stock price at time $n + 1$ is the discounted stock price at time $n$. The risk-neutral probabilities are chosen to enforce this. Moreover, processes that satisfy this condition are called martingales.</p> <p><strong>Definition: Martingale</strong> Consider a binomial asset pricing model. Let $M_0, M_1, \dots, M_N$ be a sequence of random variables, with each $M_n$ depending only on the first $n$ coin tosses ($M_0$ is constant). We call this stochastic process <em>adapted</em>:</p> \[\begin{align*} (i)\quad &amp;\text{ If } M_n = \mathbb{E}_n [M_{n + 1}] \quad n = 0, 1, \dots, N - 1\\ &amp;\text{We say this process is a martingale.}\\ (ii)\quad &amp;\text{ If } M_n \le \mathbb{E}_n [M_{n + 1}] \quad n = 0, 1, \dots, N - 1\\ &amp;\text{We say the process is a submartingale.}\\ &amp;\text{(even thought it may have a tendency to increase)}\\ (iii)\quad &amp;\text{ If } M_n \ge \mathbb{E}_n [M_{n + 1}] \quad n = 0, 1, \dots, N - 1\\ &amp;\text{We say the process is a supermartingale.}\\ &amp;\text{Even though it may have a tendency to decrease.} \end{align*}\] \[\begin{align*} M_{n + 1} &amp;= \mathbb{E}_{n + 1}[M_{n + 2}] \quad \text{One-step ahead}\\ \implies \mathbb{E}_n [M_{n + 1}] &amp;= \mathbb{E}_n [\mathbb{E}_{n + 1} [M_{n + 2}]] = \mathbb{E}_n[M_{n + 2}] \quad \text{Two-Step Ahead}\\ \implies M_n &amp;= \mathbb{E}_n[M_{n + 2}]\\ \implies M_n &amp;= \mathbb{E} [M_m] \quad 0 \le n \le m \le N \end{align*}\] <p><strong>Theorem:</strong> Expectation of a martingale is constant over time. i.e., If $M_0, M_1, \dots, M_N$ is a martingale, then we have that:</p> \[M_0 = \mathbb{E}M_n \quad n = 0, 1, \dots, N\] <p>Indeed, taking expectations of both side gives that:</p> \[\mathbb{E}M_0 = \mathbb{E}M_1 = \mathbb{E}M_2 = \cdots = \mathbb{E}M_{n - 1} = \mathbb{E} M_N\] <p><strong>Theorem</strong> Consider the general binomial model with $0 &lt; d &lt; 1 + r &lt; u$. Let the risk-neutral probabilities be given by:</p> \[\tilde{p} = \frac{1 + r - d}{u - d},\quad \tilde{q} = \frac{u - 1 - r}{u - d}\] <p>Then, under the risk-neutral measure, the discounted stock price is a martingale, i.e., the following equation:</p> \[\frac{S_n}{(1 + r)^n} = \tilde{\mathbb{E}}_n \left[\frac{S_{n + 1}}{(1 + r)^{n + 1}} \right]\] <p>holds at every time $n$ and for every sequence of coin tosses.</p> <p><strong>Proof:</strong></p> \[\begin{align*} \widetilde{\mathbb{E}}_n &amp;\left[ \frac{S_{n+1}}{(1 + r)^{n+1}} \right](\omega_1 \ldots \omega_n) \\ &amp;= \frac{1}{(1 + r)^n} \cdot \frac{1}{1 + r} \left[ \widetilde{p} S_{n+1}(\omega_1 \ldots \omega_n H) + \widetilde{q} S_{n+1}(\omega_1 \ldots \omega_n T) \right] \\ &amp;= \frac{1}{(1 + r)^n} \cdot \frac{1}{1 + r} \left[ \widetilde{p} u S_n(\omega_1 \ldots \omega_n) + \widetilde{q} d S_n(\omega_1 \ldots \omega_n) \right] \\ &amp;= \frac{S_n(\omega_1 \ldots \omega_n)}{(1 + r)^n} \cdot \frac{\widetilde{p} u + \widetilde{q} d}{1 + r} \\ &amp;= \frac{S_n(\omega_1 \ldots \omega_n)}{(1 + r)^n}. \end{align*}\] \[\begin{align*} \widetilde{\mathbb{E}}_n \left[ \frac{S_{n+1}}{(1 + r)^{n+1}} \right] &amp;= \widetilde{\mathbb{E}}_n \left[ \frac{S_n}{(1 + r)^{n+1}} \cdot \frac{S_{n+1}}{S_n} \right] \\ &amp;= \frac{S_n}{(1 + r)^n} \widetilde{\mathbb{E}}_n \left[ \frac{1}{1 + r} \cdot \frac{S_{n+1}}{S_n} \right] \quad \text{(Taking out what is known)} \\ &amp;= \frac{S_n}{(1 + r)^n} \cdot \frac{1}{1 + r} \widetilde{\mathbb{E}}_n \left[ \frac{S_{n+1}}{S_n} \right] \quad \text{(Independence)} \\ &amp;= \frac{S_n}{(1 + r)^n} \cdot \frac{\widetilde{p} u + \widetilde{q} d}{1 + r} \\ &amp;= \frac{S_n}{(1 + r)^n}. \end{align*}\] <p><strong>Key Concept</strong>: When an investor who, at each time $n$, takes a position of $\Delta_n$ shares of stock and holds this position until $n + 1$, when he takes a new position of $\Delta_{n + 1}$ shares, the portfolio variable $\Delta_n$ may depend on the first $n$ coin tosses and $\Delta_{n + 1}$ may depend on the first $n + 1$ coin tosses. In other words:</p> \[\Delta_0, \Delta_1, \dots, \Delta_{N - 1}\] <p>is an <em>adapted</em> process in the sense that, for each $\Delta_n$ for $n = 0, 1, \dots, N - 1$, depends only on the first $n$ coin tosses. Moreover, if the investor begins with initial wealth $X_0$ and $X_n$, which denotes their wealth at each time $n$, then the evolution of his wealth is governed by the wealth equation:</p> \[X_{n + 1} = \Delta_n S_{n + 1} + (1 + r)(X_n - \Delta_n S_n) \quad n = 0, 1, \dots, N - 1\] <p>Note: Each $X_n$ depends only on the first $n$ coin tosses.</p> <p><strong>Theorem</strong>: Consider the binomial model with $N$ periods. Let $\Delta_0, \Delta_1, \dots, \Delta_{N - 1}$ be an adapted portfolio process, let $X_0$ be a real number (constant), and let the wealth process $X_1, \dots, X_N$ be generated recursively by:</p> \[X_{n + 1} = \Delta_n S_{n + 1} + (1 + r)(X_n - \Delta_n S_n)\quad n = 0, 1, \dots, N - 1\] <p>Then, the <strong>discounted wealth process</strong>:</p> \[\frac{X_n}{(1 + r)^n}\quad n = 0, 1, \dots, N\] <p>is a martingale under the risk-neutral measure, i.e.,</p> \[\frac{X_n}{(1 + r)^n} = \tilde{\mathbb{E}}_n \left[\frac{X_{n + 1}}{(1 + r)^{n + 1}} \right],\quad n = 0, 1, \dots, N - 1\] <p><strong>Proof</strong>:</p> \[\begin{align*} \widetilde{\mathbb{E}}_n \left[\frac{X_{n+1}}{(1 + r)^{n+1}} \right] &amp;= \widetilde{\mathbb{E}}_n \left[\frac{\Delta_n S_{n+1}}{(1 + r)^{n+1}} + \frac{X_n - \Delta_n S_n}{(1 + r)^n} \right] \\ &amp;\text{(Linearity)} \\ &amp;= \widetilde{\mathbb{E}}_n \left[\frac{\Delta_n S_{n+1}}{(1 + r)^{n+1}} \right] + \widetilde{\mathbb{E}}_n \left[\frac{X_n - \Delta_n S_n}{(1 + r)^n} \right] \\ &amp;\text{(Taking out what is known)} \\ &amp;= \Delta_n \widetilde{\mathbb{E}}_n \left[\frac{S_{n+1}}{(1 + r)^{n+1}} \right] + \frac{X_n - \Delta_n S_n}{(1 + r)^n} \quad \\ &amp;\text{(Theorem 2.4.4)}\\ &amp;= \Delta_n \frac{S_n}{(1 + r)^n} + \frac{X_n - \Delta_n S_n}{(1 + r)^n} \\ &amp;= \frac{X_n}{(1 + r)^n}. \end{align*}\] <p><strong>Corollary</strong>: Under the conditions of the theorem above:</p> \[\tilde{\mathbb{E}} \frac{X_n}{(1 + r)^n}\quad n = 0, 1, \dots, N\] <p>The expected value of a martingale cannot change with time and so must always be equal to the time-zero value of the martingale. Applying this to our $\tilde{\mathbb{P}}$-martingale $\frac{X_n}{(1 + r)^n}$ for $n = 0, 1, \dots, N$, we can get the equation above.</p> <p>Another consequence of the Theorem above is another version of the risk-neutral pricing formula. Define $V_N$ to be a random variable that represents the value of a derivative security paying off at time $N$ depending on the first $N$ coin tosses. We know that there is initial wealth $X_0$ and a replicating portfolio process $\Delta_0, \dots, \Delta_{N - 1}$ that generates a wealth process $X_1, \dots, X_N$ satisfying $X_n = V_N$, no matter how the coin tossing turns out. Because $\frac{X_n}{(1 + r)^n}$ for $n = 0, 1, \dots, N$ is a martingale, the multi-step ahead property shown previously implies:</p> \[\frac{X_n}{(1 + r)^n} = \mathbb{E}_n \left[\frac{X_N}{(1 + r)^N} \right] = \mathbb{E}_n \left[\frac{V_N}{(1 + r)^N} \right]\] <p>However, we may have derivative securities, such as bonds, that do NOT pay off on a single date, rather, make series of payments. For such a security, we have the following pricing and hedging formulas:</p> <p><strong>Theorem:</strong> Consider an $N$-period binomial asset pricing-model with $0 &lt; d &lt; 1 + r &lt; u$ and with risk-neutral probability measure $\tilde{\mathbb{P}}$. Let $C_0, C_1, \dots, C_N$ be a sequence of random variables such that each $C_n$ depends only on $\omega_n, \dots, \omega_n$. The price at time $n$ of the derivative security that makes payments $C_n, \dots, C_N$ at time $n, \dots, N$, respectively, is:</p> \[V_n = \tilde{\mathbb{E}}_n \left[\sum_{k = n}^N \frac{C_k}{(1 + r)^{k - n}} \right],\quad n = 0, 1, \dots, N\] <p>The price process:</p> \[C_n(\omega_1 \dots \omega_n) = V_n(\omega_1 \dots \omega_n) - \frac{1}{1 + r}[\tilde{p} V_{n + 1}(\omega_1 \dots \omega_n H) + \tilde{q}V_{n + 1}(\omega_1 \dots \omega_n T)]\] <p>We define the Delta-Hedging Formula as:</p> \[\Delta_n(\omega_1 \dots \omega_n) = \frac{V_{n + 1}(\omega_1 \dots \omega_n H) - V_{n + 1}(\omega_1 \dots \omega_n T)}{S_{n + 1}(\omega_1 \dots \omega_n H) - S_{n + 1}(\omega_1 \dots \omega_n T)}\] <p>where $n$ ranges between $0$ and $N - 1$. If we set $X_0 = V_0$ and define recursively forward in time the portfolio values $X_1, X_2, \dots X_N$ by:</p> \[X_{n + 1} = \Delta_n S_{n + 1} + (1 + r)(X_n - C_n - \Delta_n S_n)\] <p>then we have:</p> \[X_n(\omega_1 \dots \omega_n) = V_n(\omega_1 \dots \omega_n)\] <p>for all $n$ and all $\omega_1, \dots, \omega_n$.</p> <p>We call $V_n$ the Net Present Value at time $n$ of the sequence of payments $C_n, \dots, C_N$. Itâ€™s just the <strong>sum of the value $\tilde{\mathbb{E}}_n \left[ \frac{C_k}{(1 + r)^{k - n}} \right]$</strong> of each of the payments $C_k$ to be made at times $k = n, k = n + 1, \dots, k = N$. Note, that the payment at time $n$ is included. This payment $C_n$, depends on only the first $n$ tosses and so can be taken outside the conditional expectation $\tilde{\mathbb{E}}_n$ such that:</p> \[V_n = C_n + \tilde{\mathbb{E}}_n \left[\sum_{k = n + 1}^N \frac{C_k}{(1 + r)^{k - n}} \right],\quad n = 0, 1, \dots, N - 1\] <p>In the case that $n = N$, we have that:</p> \[V_N = C_N\] <p>An agent short cash flows $C_0, \dots, C_n$ hedges the payments by investing in a stock and a money market account. At each time $n$, before making the payment $C_n$, the portfolio value is $X_n$. After the payment, the agent takes a stock position $\Delta_n$ according to the Delta Hedging formula, ensuring the portfolio evolves to $X_{n+1}$ before $C_{n+1}$. Starting with $X_0 = V_0$, this strategy ensures $X_N = V_N = C_N$ at the final time $N$, allowing the agent to make the last payment $C_N$ and reduce the portfolio to zero, achieving a perfect hedge.</p> <p><strong>Proof</strong>: We can proceed by induction on $n$ and show that the by the hypothesis $X_n (\omega_1 \dots \omega_n) = V_n (\omega_1 \dots \omega_n)$ for some $n = 0, 1, \dots, N - 1$ and all $\omega_1 \dots \omega_n$.</p> \[\begin{align*} X_{n + 1} (\omega_1 \dots \omega_n H) &amp;= V_{n + 1}(\omega_1 \dots \omega_n H)\\ X_{n + 1} (\omega_1 \dots \omega_n T) &amp;= V_{n + 1}(\omega_1 \dots \omega_n T) \end{align*}\] <p>Via iterated conditioning, we have that:</p> \[\begin{align*} V_n &amp;= C_n + \tilde{\mathbb{E}}_n \left[ \frac{1}{1 + r} \tilde{\mathbb{E}}_{n+1} \left[ \sum_{k=n+1}^N \frac{C_k}{(1 + r)^{k - (n+1)}} \right] \right] \\ &amp;= C_n + \tilde{\mathbb{E}}_n \left[ \frac{1}{1 + r} V_{n+1} \right], \end{align*}\] \[\begin{align*} V_n(\omega_1 \dots \omega_n) - C_n(\omega_1 \dots \omega_n) &amp;= \frac{1}{1 + r} \left[ \tilde{p} V_{n+1}(\omega_1 \dots \omega_n H) + \tilde{q} V_{n+1}(\omega_1 \dots \omega_n T) \right]. \end{align*}\] \[\begin{align*} V_n - C_n &amp;= \frac{1}{1 + r} \left[ \tilde{p} V_{n+1}(H) + \tilde{q} V_{n+1}(T) \right]. \end{align*}\] \[\begin{align*} X_{n+1}(H) &amp;= \Delta_n S_{n+1}(H) + (1 + r)(X_n - C_n - \Delta_n S_n) \\ &amp;= \frac{V_{n+1}(H) - V_{n+1}(T)}{S_{n+1}(H) - S_{n+1}(T)} \left( S_{n+1}(H) - (1 + r) S_n \right) \\ &amp;\quad + (1 + r)(V_n - C_n),\\ &amp;= \frac{V_{n+1}(H) - V_{n+1}(T)}{(u - d) S_n} (u S_n - (1 + r) S_n) \\ &amp;\quad + \tilde{p} V_{n+1}(H) + \tilde{q} V_{n+1}(T),\\ &amp;= (V_{n+1}(H) - V_{n+1}(T)) \frac{u - 1 - r}{u - d} + \tilde{p} V_{n+1}(H) + \tilde{q} V_{n+1}(T),\\ &amp;= (V_{n+1}(H) - V_{n+1}(T)) \tilde{q} + \tilde{p} V_{n+1}(H) + \tilde{q} V_{n+1}(T),\\ &amp;= \tilde{p} V_{n+1}(H) + \tilde{q} V_{n+1}(T) = V_{n+1}(H). \end{align*}\] <h3 id="markov-processes">Markov Processes</h3> <p><strong>Definition</strong> Consider the binomial asset pricing model. Let $X_0, X_1, \dots, X_N$ be an adapted process. If, for every $n$ between $0$ and $N - 1$ and for every function $f(x)$ there is another function $g(x)$ (depending on $n$ and $f$) each that:</p> \[\mathbb{E}_n [f(X_{n + 1})] = g(X_n)\] <p>we say that $X_0, X_1, \dots, X_N$ is a Markov process. In other words, the information about the coin tosses one needs in order to evaluate $\mathbb{E}<em>n [f(X</em>{n + 1})]$ is summarized by $X_n$. Thus, the expected value of some function of the next state $f(X_{n + 1})$ can be entirely determined by applying a function $g$ to the current state $X_n$. Thus to predict $X_{n + 1}$ you only need to know $X_n$.</p> <p><strong>e.g., Stock Price</strong> The stock price at time $n + 1$ is given in terms of the stock price at time $n$ by:</p> \[S_{n+1}(\omega_1 \dots \omega_n \omega_{n+1}) = \begin{cases} u S_n(\omega_1 \dots \omega_n), &amp; \text{if } \omega_{n+1} = H, \\ d S_n(\omega_1 \dots \omega_n), &amp; \text{if } \omega_{n+1} = T. \end{cases}\] <p>The conditional expectation is:</p> \[\mathbb{E}_n [f(S_{n + 1})] (\omega_1 \dots \omega_n) = pf(uS_n (\omega_1 \dots \omega_n)) + qf(dS_n (\omega_1 \dots \omega_n)),\] <p>which depends only on $\omega_1 \dots \omega_n$ via $S_n (\omega_1 \dots \omega_n)$. Therefore:</p> \[\mathbb{E}_n [f(S_{n + 1})] = g(S_n),\] <p>where $g(x) = pf(ux) + qf(dx)$. This shows that the stock price process is Markov under both the risk-neutral and actual probability measures. To price a derivative security with payoff $V_N = v_N(S_N)$, the risk-neutral pricing formula is used:</p> \[V_n = \frac{1}{1 + r} \tilde{\mathbb{E}}_n [V_{n + 1}],\quad n = 0, 1, \dots, N - 1.\] <p>but $V_N = v_N(S_N)$ and the stock price process is Markov:</p> \[\begin{align*} V_{N - 1} &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_{N - 1}[v_N (S_N)] = v_{N - 1} (S_{N - 1})\\ V_{N - 2} &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_{N - 2}[v_{N - 1} (S_{N - 1})] = v_{N - 2} (S_{N - 2}) \end{align*}\] <p>for some function $v_{N - 2}$. Generally, $V_n = v_n(S_n)$ for some function $v_n$.</p> <p>The martingale property is the special case of:</p> \[\mathbb{E}_n[f(X_{n + 1})] = g(X_n)\] <p>Moreover, we require that for every $f$ there is a corresponding $g$ such that the expectation above holds. The Markov property requires only that:</p> \[\mathbb{E}_n [M_{n + 1}] = g(M_n)\] <p>for some function $g$ and does not require that the function $g$ be given by $g(x) = x$. Thus, NOT every Markov process is a martingale.</p> \[v_n(s) = \frac{1}{1 + r}[\tilde{p} v_{n + 1}(us) + \tilde{q}v_{n + 1}(ds)]\] <p><strong>Lemma: (Independence)</strong> In the $N$-period binomial asset pricing model, let $n$ be an integer between 0 and $N$. Suppose the random variables $X^1, \dots, X^K$ depend only on coin tosses 1 through $n$ and the random variables $Y^1, \dots, Y^L$ depend only on coin tosses $n + 1$ through $N$. Let $f(x^1, \dots, x^K, y^1, \dots, y^L)$ be a function of dummy variables $x^1, \dots, x^K$ and $y^1, \dots, y^L$ and define:</p> \[g(x^1, \dots, x^K) = \mathbb{E}f(x^1, \dots, x^K, Y^1, \dots, Y^L)\] <p>Assume that $K = L = 1$ then $g(x) = \mathbb{E} f(x, Y)$. Then,</p> \[\mathbb{E}_n [f(X^1, \dots, X^K, Y^1, \dots, Y^L)] = g(X^1, \dots, X^K)\] <p>and $\mathbb{E}_n [f(X, Y)] = g(X)$. We hold $f$ constant by replacing it with random variable $X$ by an arbitrary fixed dummy variable $x$ and compute the conditional expectation of $f(x, Y)$.</p> <p>e.g., Consider the maximum-to-date process $M_n = \max{S_k}_{0 \le k \le n}$ with $p = \frac{2}{3}, q = \frac{1}{3}$.</p> <pre><code class="language-tikz">\begin{document}

\begin{tikzpicture}

% Tree Nodes
\node (M0) at (0,0) {$M_0 = 4$};
\node (M1H) at (2,2.5) {$M_1(H) = 8$};
\node (M1T) at (2,-2.5) {$M_1(T) = 4$};
\node (M2HH) at (4,4.5) {$M_2(HH) = 16$};
\node (M2HT) at (4,0) {$M_2(HT) = 8$};
\node (M2TH) at (4,-1) {$M_2(TH) = 4$};
\node (M2TT) at (4,-4.5) {$M_2(TT) = 4$};
\node (M3HHH) at (6,5.5) {$M_3(HHH) = 32$};
\node (M3HHT) at (6,3) {$M_3(HHT) = 16$};
\node (M3HTH) at (6,1) {$M_3(HTH) = 8$};
\node (M3HTT) at (6,-1) {$M_3(HTT) = 8$};
\node (M3THH) at (6,-3) {$M_3(THH) = 8$};
\node (M3THT) at (6,-4.5) {$M_3(THT) = 4$};
\node (M3TTT) at (6,-6.5) {$M_3(TTT) = 4$};

% Connections
\draw[-&gt;, thick] (M0) -- (M1H);
\draw[-&gt;, thick] (M0) -- (M1T);
\draw[-&gt;, thick] (M1H) -- (M2HH);
\draw[-&gt;, thick] (M1H) -- (M2HT);
\draw[-&gt;, thick] (M1T) -- (M2TH);
\draw[-&gt;, thick] (M1T) -- (M2TT);
\draw[-&gt;, thick] (M2HH) -- (M3HHH);
\draw[-&gt;, thick] (M2HH) -- (M3HHT);
\draw[-&gt;, thick] (M2HT) -- (M3HTH);
\draw[-&gt;, thick] (M2HT) -- (M3HTT);
\draw[-&gt;, thick] (M2TH) -- (M3THH);
\draw[-&gt;, thick] (M2TH) -- (M3THT);
\draw[-&gt;, thick] (M2TT) -- (M3TTT);

% Time Labels
\node at (0,-1) {$t = 0$};
\node at (2,-3.5) {$t = 1$};
\node at (4,-5.5) {$t = 2$};
\node at (6,-7.5) {$t = 3$};

\end{tikzpicture}

\end{document}
</code></pre> <p>Clearly, we have that:</p> \[\begin{align*} \mathbb{E}_2[M_3](TH) &amp;= \frac{2}{3}M_3(THH) + \frac{1}{3}M_3(THT) = \frac{16}{3} + \frac{4}{3} = 6\frac{2}{3}, \\ \mathbb{E}_2[M_3](TT) &amp;= \frac{2}{3}M_3(TTH) + \frac{1}{3}M_3(TTT) = \frac{8}{3} + \frac{4}{3} = 4. \end{align*}\] <p>Since $M_2(TH) = M_2(TT) = 4$ there cannot be a function $g$ such that we have that:</p> \[\mathbb{E}_3 [M_3] (TH) = g(M_2(TH))\quad\text{and}\quad \mathbb{E}_3 [M_3](TT) = g(M_2(TT))\] <p>The maximum-to-date process is not Markov because recording only that the value of the maximum-to-date at time two is 4, without recording the value of the stock price at time two, neglects information relevant to the evolution of the maximum-to-date process after time two.</p> <p><strong>Recovering a Markov property:</strong> We add one or more state variables, recovering the Markov property, having determined a way to describe the state of the market in terms of these variables.</p> <p><strong>Definition</strong>: Consider the binomial asset pricing model. Let ${(X^1_n, \dots, X_n^K);\quad n = 0, 1, \dots, N}$ be a $K$-dimensional adapted process, i.e., $K$ one-dimensional adapted processes. If, for every $n$ between $0$ and $N - 1$, and for every function $f(x^1, \dots, x^K)$ there is another function $g(x^1, \dots, x^K)$ (depending on $n$ and $f$) such that:</p> \[\mathbb{E}_n [f(X^1_{n + 1}, \dots, X^K_{n + 1})] = g(X^1_n, \dots, X^K_n)\] <p>we say that ${(X^1_n, \dots, X_n^K);\quad n = 0, 1, \dots, N}$ is a $K$-dimensional Markov process.</p> <p><strong>Remark</strong>: If $X_0, X_1, \dots, X_N$ is a Markov process and $n \le N - 2$, then the one-step ahead Markov property implies that for every function $h$, there is a function $f$ such that:</p> \[\mathbb{E}_{n + 1}[h(X_{n + 2})] = f(X_{n + 1})\] <p>Then we can take conditional expectations on both sides based on the information at time $n$, and using iterated conditioning, we get:</p> \[\begin{align*} \mathbb{E}_n [h(X_{n + 2})] &amp;= \mathbb{E}_n \left[\mathbb{E}_{n + 1}[h(X_{n + 2})] \right] = \mathbb{E}_n [f(X_{n + 1})]\\ \mathbb{E}_n [h(X_{n + 2})] &amp;= g(X_n)\\ \mathbb{E}_n [h(X_m)] &amp;= g(X_n)\quad \text{for } 0 \le n \le m \le N \end{align*}\] <p>For our binomial pricing model suppose we have a Markov process $X_0, X_1, \dots, X_N$ under the risk-neutral probability measure $\tilde{\mathbb{P}}$ and we have a derivative security whose payoff $V_N$ at time $N$ is a function $v_N$ of $X_N$ i.e., $V_N = v_N(X_N)$. The difference between $V_N$ and $v_N$ is that the argument of the former sequence of coin tosses, whereas the argument of the latter is a real number.</p> <p>In place of $x$ we substitute the random variable $X_N$ to get:</p> \[V_N(\omega_1 \dots \omega_N) = v_N(X_N(\omega_1 \dots \omega_N)) \text{ for al } \omega_1 \dots \omega_N\] <p>Getting the risk-neutral pricing formula says that the price of this derivative security at earlier times $n$ is:</p> \[\begin{align*} V_n(\omega_1 \dots \omega_n) &amp;= \tilde{\mathbb{E}}_n \left[\frac{V_N}{(1 + r)^N - n} \right] (\omega_1 \dots \omega_n) \quad \text{for all } \omega_1 \dots \omega_n\\ \tilde{\mathbb{E}}_n \left[\frac{V_N}{(1 + r)^{N - n}} \right] &amp;(\omega_1 \dots \omega_n) \\ &amp;= v_n (X_n(\omega_1 \dots \omega_n)) \quad \text{ for all } \omega_1 \dots \omega_n \end{align*}\] <p>Thus we get that the price of the derivative security at time $n$ is a function of $X_n$:</p> \[V_n = v_n(X_n)\] <p>An $N$-period binomial model with derivative security whose payoff at time $N$ is a function $v_N(S_N, M_N)$ of the stock price and the maximum stock price.</p> <p>Take $V_N = (M_N - K)^{+}$. The stock price does not appear in $V_N$ we need to execute the pricing algorithm below because the maximum-to-date process is NOT Markov by itself. Thus, for any $n$ between $0$ and $N$, there is a non-random function $v_n(s, m)$ such that the price of the option at time $n$ is:</p> \[V_n = v_n(S_n, M_n) = \tilde{\mathbb{E}}_n \left[\frac{v_N(S_N, M_N)}{(1 + r)^{N - n}} \right] \Longleftrightarrow V_n = \frac{1}{1 + r} \tilde{\mathbb{E}}_n [V_{n + 1}]\] \[\begin{align*} V_n &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_n [V_{n + 1}]\\ &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_n [v_{n + 1}(S_{n + 1}, M_{n + 1})]\\ &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_n \left[v_{n + 1} \left(S_n \cdot \frac{S_{n + 1}}{S_n}, M_n \vee \left(S_n \cdot \frac{S_{n + 1}}{S_n} \right) \right) \right]\\ \\ v_n(s, m) &amp;= \frac{1}{1 + r} \tilde{\mathbb{E}}_n \left[v_{n + 1} \left(s \cdot \frac{S_{n + 1}}{S_n}, m \vee \left(s \cdot \frac{S_{n + 1}}{S_n} \right) \right) \right]\\ &amp;= \frac{1}{1 + r} [\tilde{p} v_{n + 1} (us, m \vee (us)) + \tilde{q} v_{n + 1} (ds, m \vee (ds))]\\ &amp;= \frac{1}{1 + r} [\tilde{p} v_{n + 1} (us, m \vee (us)) + \tilde{q} v_{n + 1}(ds, m)] \end{align*}\] <p><strong>Theorem</strong> Let $X_0, X_1, \dots, X_N$ be a Markov process under the risk-neutral probability measure $\tilde{\mathbb{P}}$ in the binomial model. Let $V_N(x)$ be a function of the dummy variable $x$ and consider a derivative security whose payoff at time $N$ is $v_N(X_N)$. Then for each $n$ between $0$ and $N$, the price $V_n$ of this derivative security is some function $v_n$ of $X_n$,</p> \[V_n = v_n(X_n),\quad n = 0, 1, \dots, N\] <p>There is a recursive algorithm for computing $v_n$ whose exact formula depends on the underlying Markov process $X_0, X_1, \dots, X_N$. Analogous results hold if the underlying Markov process is multi-dimensional.</p> <h3 id="summary-of-key-results-theorems-and-algorithms">Summary of Key Results, Theorems, and Algorithms</h3> <h4 id="finite-probability-spaces-1">Finite Probability Spaces</h4> <ol> <li> <strong>Definition</strong>: A finite probability space consists of: <ul> <li> <strong>Sample Space</strong> ($\Omega$): A finite set of outcomes.</li> <li> <strong>Probability Measure</strong> ($\mathbb{P}$): Assigns probabilities to outcomes such that $\sum_{\omega \in \Omega} \mathbb{P}(\omega) = 1$.</li> </ul> </li> <li> <strong>Probability of an Event</strong>:</li> </ol> \[\mathbb{P}(A) = \sum_{\omega \in A} \mathbb{P}(\omega)\] <ol> <li> <strong>Key Property</strong>: For disjoint subsets $A, B \subseteq \Omega$:</li> </ol> \[\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\] <ol> <li> <strong>Expectation of a Random Variable</strong>:</li> </ol> \[\mathbb{E}[X] = \sum_{\omega \in \Omega} X(\omega) \mathbb{P}(\omega)\] <ol> <li> <strong>Variance</strong>:</li> </ol> \[\text{Var}(X) = \mathbb{E}\left[(X - \mathbb{E}[X])^2\right]\] <ol> <li> <strong>Jensenâ€™s Inequality</strong>: For a convex function $\phi$ and random variable $X$:</li> </ol> \[\mathbb{E}[\phi(X)] \geq \phi(\mathbb{E}[X])\] <h4 id="conditional-expectations-1">Conditional Expectations</h4> <ol> <li> <p><strong>Conditional Expectation</strong>: \(\tilde{\mathbb{E}}_n[X] = \sum_{\omega_{n+1} \dots \omega_N} \tilde{p}^{\# H}\tilde{q}^{\# T} X(\omega_1 \dots \omega_N)\)</p> </li> <li> <strong>Key Properties</strong>: <ul> <li> <strong>Linearity</strong>: $\mathbb{E}_n[c_1X + c_2Y] = c_1\mathbb{E}_n[X] + c_2\mathbb{E}_n[Y]$</li> <li> <strong>Taking Out What is Known</strong>: If $X$ depends only on the first $n$ coin tosses, $\mathbb{E}_n[XY] = X \cdot \mathbb{E}_n[Y]$.</li> <li> <strong>Iterated Conditioning</strong>: $\mathbb{E}_n[\mathbb{E}_m[X]] = \mathbb{E}_n[X]$ for $n \leq m$.</li> <li> <strong>Independence</strong>: If $X$ depends on tosses $n+1$ to $N$, $\mathbb{E}_n[X] = \mathbb{E}[X]$.</li> </ul> </li> <li> <strong>Risk-Neutral Stock Pricing</strong>: \(S_n = \frac{1}{1 + r} \tilde{\mathbb{E}}_n[S_{n+1}]\)</li> </ol> <h4 id="martingales-1">Martingales</h4> <ol> <li> <p><strong>Definition</strong>: A process $M_n$ is a martingale if: \(M_n = \mathbb{E}_n[M_{n+1}]\)</p> </li> <li> <strong>Properties</strong>: <ul> <li>Expectation of a martingale is constant over time: $\mathbb{E}[M_n] = M_0$.</li> <li>Risk-neutral discounted stock price is a martingale: \(\frac{S_n}{(1 + r)^n} = \tilde{\mathbb{E}}_n\left[\frac{S_{n+1}}{(1 + r)^{n+1}}\right]\)</li> </ul> </li> <li> <p><strong>Wealth Process</strong>: \(X_{n+1} = \Delta_n S_{n+1} + (1 + r)(X_n - \Delta_n S_n)\) The discounted wealth process is also a martingale.</p> </li> <li> <strong>Risk-Neutral Pricing</strong>: \(V_n = \tilde{\mathbb{E}}_n\left[\frac{V_N}{(1 + r)^{N-n}}\right]\)</li> </ol> <h4 id="markov-processes-1">Markov Processes</h4> <ol> <li> <p><strong>Definition</strong>: A process $X_n$ is Markov if: \(\mathbb{E}_n[f(X_{n+1})] = g(X_n)\)</p> </li> <li> <p><strong>Stock Price</strong>: The stock price process is Markov: \(S_{n+1} = \begin{cases} uS_n, &amp; \text{if } \omega_{n+1} = H, \\ dS_n, &amp; \text{if } \omega_{n+1} = T. \end{cases}\)</p> </li> <li> <p><strong>Pricing with Markov Processes</strong>: \(V_n = v_n(S_n)\) where $v_n$ satisfies the recursive relation: \(v_n(s) = \frac{1}{1 + r}[\tilde{p} v_{n+1}(us) + \tilde{q} v_{n+1}(ds)]\)</p> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Kenneth Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams"},svg:{scale:1.1,minScale:.8,matchFontHeight:!1}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-notes",title:"notes",description:"Personal-study notes for quant-finance related learning materials",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"notes-stochastic-calculus-for-finance-i",title:"Stochastic Calculus for Finance I",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance I",section:"Notes",handler:()=>{window.location.href="/notes/course-1/"}},{id:"notes-stochastic-calculus-for-finance-ii",title:"Stochastic Calculus for Finance II",description:"My personal notes for Shreve&#39;s Stochastic Calculus for Finance II",section:"Notes",handler:()=>{window.location.href="/notes/course-2/"}},{id:"notes-chapter-1-no-arbitrage-pricing-model",title:"Chapter 1 - No-Arbitrage Pricing Model",description:"Notes on the No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-no-arbitrage/"}},{id:"notes-chapter-1-exercises",title:"Chapter 1 Exercises",description:"Exercises for Chapter 1 - No-Arbitrage Pricing Model.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-1-exercises/"}},{id:"notes-chapter-2-exercises",title:"Chapter 2 Exercises",description:"Exercises for Chapter 2 - Probability Theory on Coin Toss Space.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-exercises/"}},{id:"notes-chapter-2-probability-theory-on-coin-toss-space",title:"Chapter 2 - Probability Theory on Coin Toss Space",description:"Notes on probability theory applied to coin toss spaces.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-2-probability/"}},{id:"notes-chapter-3-state-prices",title:"Chapter 3 - State Prices",description:"Notes on State Prices in financial models.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-state-prices/"}},{id:"notes-chapter-3-exercises",title:"Chapter 3 Exercises",description:"Exercises for Chapter 3 - State Prices.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-3-exercises/"}},{id:"notes-chapter-4-american-derivative-securities",title:"Chapter 4 - American Derivative Securities",description:"Notes on American derivative securities and their valuation.",section:"Notes",handler:()=>{window.location.href="/notes/course-1/chapter-4-american-derivatives/"}},{id:"notes-chapter-1-general-probability-theory",title:"Chapter 1 - General Probability Theory",description:"Notes on general probability theory and foundational concepts.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-general-probability/"}},{id:"notes-chapter-1-probability-exercises",title:"Chapter 1 - Probability Exercises",description:"Exercises for Chapter 1 - General Probability Theory.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-1-probability-exercises/"}},{id:"notes-chapter-2-information-exercises",title:"Chapter 2 - Information Exercises",description:"Exercises for Chapter 2 - Information and Conditioning.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-exercises/"}},{id:"notes-chapter-2-information-and-conditioning",title:"Chapter 2 - Information and Conditioning",description:"Notes on information theory and conditional probability.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-2-information-conditioning/"}},{id:"notes-chapter-3-brownian-motion-exercises",title:"Chapter 3 - Brownian Motion Exercises",description:"Exercises for Chapter 3 - Brownian Motion.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion-exercises/"}},{id:"notes-chapter-3-brownian-motion",title:"Chapter 3 - Brownian Motion",description:"Notes on Brownian motion and its applications.",section:"Notes",handler:()=>{window.location.href="/notes/course-2/chapter-3-brownian-motion/"}},{id:"projects-the-lagging-indicator-chronicles-a-tale-of-policies-playing-catch-up",title:"The Lagging Indicator Chronicles \u2013 A Tale of Policies Playing Catch-Up",description:"Lag time between state-level policy interventions and change points in COVID-19 outcomes in the United States. Read more at ![this article](https://www.cell.com/patterns/fulltext/S2666-3899(21)00149-5).",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-pm2-5-and-the-great-regulatory-vanishing-act-when-pollution-took-a-free-pass",title:"PM2.5 and the Great Regulatory Vanishing Act - When Pollution Took a Free...",description:"An introduction to the statistical models used to assess the impact of EPA rollbacks on air quality in California. https://enveurope.springeropen.com/articles/10.1186/s12302-021-00489-9",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> </body> </html>